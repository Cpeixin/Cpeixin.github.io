<!-- build time:Sat Apr 04 2020 16:56:20 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta name="renderer" content="webkit"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=no,email=no,adress=no"><meta name="theme-color" content="#000000"><meta http-equiv="window-target" content="_top"><title>数据分析-朴素贝叶斯（下） | 布兰特博客</title><meta name="description" content="朴素贝叶斯分类最适合的场景就是文本分类、情感分析和垃圾邮件识别。其中情感分析和垃圾邮件识别都是通过文本来进行判断。从这里你能看出来，这三个场景本质上都是文本分类，这也是朴素贝叶斯最擅长的地方。所以朴素贝叶斯也常用于自然语言处理 NLP 的工具。今天我带你一起使用朴素贝叶斯做下文档分类的项目，最重要的工具就是 sklearn 这个机器学习神器。sklearn机器学习包sklearn 的全称叫 Sci"><meta property="og:type" content="article"><meta property="og:title" content="数据分析-朴素贝叶斯（下）"><meta property="og:url" content="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/index.html"><meta property="og:site_name" content="布兰特 | 不忘初心"><meta property="og:description" content="朴素贝叶斯分类最适合的场景就是文本分类、情感分析和垃圾邮件识别。其中情感分析和垃圾邮件识别都是通过文本来进行判断。从这里你能看出来，这三个场景本质上都是文本分类，这也是朴素贝叶斯最擅长的地方。所以朴素贝叶斯也常用于自然语言处理 NLP 的工具。今天我带你一起使用朴素贝叶斯做下文档分类的项目，最重要的工具就是 sklearn 这个机器学习神器。sklearn机器学习包sklearn 的全称叫 Sci"><meta property="og:image" content="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/p1.png"><meta property="og:image" content="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/p2.png"><meta property="og:image" content="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/p3.png"><meta property="og:image" content="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/p4.png"><meta property="og:image" content="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/p5.png"><meta property="og:image" content="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/p6.png"><meta property="og:image" content="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/p7.png"><meta property="article:published_time" content="2019-01-21T02:34:38.000Z"><meta property="article:modified_time" content="2020-03-10T14:27:31.518Z"><meta property="article:author" content="Brent"><meta property="article:tag" content="数据分析"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/p1.png"><link rel="canonical" href="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/index.html"><link rel="alternate" href="/atom.xml" title="布兰特 | 不忘初心" type="application/atom+xml"><link rel="icon" href="/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><meta name="generator" content="Hexo 4.2.0"></head><body class="main-center" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="slimContent"><div class="navbar-header"><div class="profile-block text-center"><a id="avatar" href="https://github.com/cpeixin" target="_blank" rel="external nofollow noopener noreferrer"><img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200"></a><h2 id="name" class="hidden-xs hidden-sm">Brent</h2><h3 id="title" class="hidden-xs hidden-sm hidden-md">大数据工程师 &amp; 机器学习</h3><small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Malaysia</small></div><div class="search" id="search-form-wrap"><form class="search-form sidebar-form"><div class="input-group"><input type="text" class="search-form-input form-control" placeholder="Search"> <span class="input-group-btn"><button type="submit" class="search-form-submit btn btn-flat" onclick="return!1"><i class="icon icon-search"></i></button></span></div></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..." x-webkit-speech> <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div></div><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button></div><nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation"><ul class="nav navbar-nav main-nav"><li class="menu-item menu-item-home"><a href="/."><i class="icon icon-home-fill"></i> <span class="menu-title">Home</span></a></li><li class="menu-item menu-item-归档"><a href="/archives"><i class="icon"></i> <span class="menu-title">menu.归档</span></a></li><li class="menu-item menu-item-分类"><a href="/categories"><i class="icon"></i> <span class="menu-title">menu.分类</span></a></li><li class="menu-item menu-item-tags"><a href="/tags"><i class="icon icon-tags"></i> <span class="menu-title">Tags</span></a></li><li class="menu-item menu-item-repository"><a href="/repository"><i class="icon icon-project"></i> <span class="menu-title">Repository</span></a></li><li class="menu-item menu-item-books"><a href="/books"><i class="icon icon-book-fill"></i> <span class="menu-title">Books</span></a></li><li class="menu-item menu-item-links"><a href="/links"><i class="icon icon-friendship"></i> <span class="menu-title">Links</span></a></li><li class="menu-item menu-item-about"><a href="/about"><i class="icon icon-cup-fill"></i> <span class="menu-title">About</span></a></li><li class="menu-item menu-item-archives"><a href="/archives"><i class="icon icon-archives-fill"></i> <span class="menu-title">Archives</span></a></li></ul><ul class="social-links"><li><a href="https://github.com/cpeixin" target="_blank" title="Github" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-github"></i></a></li><li><a href="https://www.weibo.com/u/1970875963" target="_blank" title="Weibo" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-weibo"></i></a></li><li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-twitter"></i></a></li><li><a href="https://www.behance.net/cofess" target="_blank" title="Behance" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-behance"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul></nav></div></header><aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><div class="widget"><h3 class="widget-title">Board</h3><div class="widget-body"><div id="board"><div class="content"><p>记录生活 积累技术 欢迎交流</p></div></div></div></div><div class="widget"><h3 class="widget-title">Categories</h3><div class="widget-body"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据分析</a><span class="category-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">Tags</h3><div class="widget-body"><ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/" rel="tag">Docker</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TabNine/" rel="tag">TabNine</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Thread/" rel="tag">Thread</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kali/" rel="tag">kali</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shadowsock/" rel="tag">shadowsock</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" rel="tag">决策树</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" rel="tag">数据仓库</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag">数据分析</a><span class="tag-list-count">21</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9E%B6%E6%9E%84/" rel="tag">架构</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a><span class="tag-list-count">3</span></li></ul></div></div><div class="widget"><h3 class="widget-title">Tag Cloud</h3><div class="widget-body tagcloud"><a href="/tags/Docker/" style="font-size:13.14px">Docker</a> <a href="/tags/Hadoop/" style="font-size:13.43px">Hadoop</a> <a href="/tags/Linux/" style="font-size:13.14px">Linux</a> <a href="/tags/NLP/" style="font-size:13px">NLP</a> <a href="/tags/TabNine/" style="font-size:13px">TabNine</a> <a href="/tags/Thread/" style="font-size:13.14px">Thread</a> <a href="/tags/kali/" style="font-size:13px">kali</a> <a href="/tags/python/" style="font-size:13.86px">python</a> <a href="/tags/shadowsock/" style="font-size:13px">shadowsock</a> <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size:13px">决策树</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" style="font-size:13.57px">数据仓库</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size:14px">数据分析</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size:13.71px">数据结构</a> <a href="/tags/%E6%9E%B6%E6%9E%84/" style="font-size:13px">架构</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size:13.29px">算法</a></div></div><div class="widget"><h3 class="widget-title">Archive</h3><div class="widget-body"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">21</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a><span class="archive-list-count">13</span></li></ul></div></div><div class="widget"><h3 class="widget-title">Recent Posts</h3><div class="widget-body"><ul class="recent-post-list list-unstyled no-thumbnail"><li><div class="item-inner"><p class="item-category"></p><p class="item-title"><a href="/2020/04/04/repository/" class="title">Repositories</a></p><p class="item-date"><time datetime="2020-04-04T08:33:44.365Z" itemprop="datePublished">2020-04-04</time></p></div></li><li><div class="item-inner"><p class="item-category"></p><p class="item-title"><a href="/2020/04/03/hello-world/" class="title">Hello World</a></p><p class="item-date"><time datetime="2020-04-03T14:53:03.460Z" itemprop="datePublished">2020-04-03</time></p></div></li><li><div class="item-inner"><p class="item-category"></p><p class="item-title"><a href="/2020/03/11/python-Flask-Ajax-%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/" class="title">python Flask &amp; Ajax 数据传输</a></p><p class="item-date"><time datetime="2020-03-11T14:43:01.000Z" itemprop="datePublished">2020-03-11</time></p></div></li><li><div class="item-inner"><p class="item-category"></p><p class="item-title"><a href="/2020/03/10/Python-Flask%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1-%E7%A4%BA%E4%BE%8B/" class="title">Python Flask接口设计-示例</a></p><p class="item-date"><time datetime="2020-03-10T15:08:35.000Z" itemprop="datePublished">2020-03-10</time></p></div></li><li><div class="item-inner"><p class="item-category"></p><p class="item-title"><a href="/2020/01/22/IDEA-install-TabNine/" class="title">IDEA install TabNine</a></p><p class="item-date"><time datetime="2020-01-22T02:26:15.000Z" itemprop="datePublished">2020-01-22</time></p></div></li></ul></div></div></div></aside><main class="main" role="main"><div class="content"><article id="post-数据分析-朴素贝叶斯（下）" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting"><div class="article-header"><h1 class="article-title" itemprop="name">数据分析-朴素贝叶斯（下）</h1><div class="article-meta"><span class="article-date"><i class="icon icon-calendar-check"></i> <a href="/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/" class="article-date"><time datetime="2019-01-21T02:34:38.000Z" itemprop="datePublished">2019-01-21</time></a></span> <span class="article-tag"><i class="icon icon-tags"></i> <a class="article-tag-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag">数据分析</a></span> <span class="article-read hidden-xs"><i class="icon icon-eye-fill" aria-hidden="true"></i> <span id="/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/" class="leancloud_visitors" data-flag-title="数据分析-朴素贝叶斯（下）"><span class="leancloud-visitors-count">0</span></span></span> <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/#comments" class="article-comment-link">Comments</a></span> <span class="post-wordcount hidden-xs" itemprop="wordCount">Word Count: 3.3k(words)</span> <span class="post-readcount hidden-xs" itemprop="timeRequired">Read Count: 12(minutes)</span></div></div><div class="article-entry marked-body" itemprop="articleBody"><p>朴素贝叶斯分类最适合的场景就是文本分类、情感分析和垃圾邮件识别。其中情感分析和垃圾邮件识别都是通过文本来进行判断。从这里你能看出来，这三个场景本质上都是文本分类，这也是朴素贝叶斯最擅长的地方。所以朴素贝叶斯也常用于自然语言处理 NLP 的工具。今天我带你一起使用朴素贝叶斯做下文档分类的项目，最重要的工具就是 sklearn 这个机器学习神器。</p><h3 id="sklearn机器学习包"><a href="#sklearn机器学习包" class="headerlink" title="sklearn机器学习包"></a>sklearn机器学习包</h3><p>sklearn 的全称叫 Scikit-learn，它给我们提供了 3 个朴素贝叶斯分类算法，分别是<strong>高斯朴素贝叶斯（GaussianNB）、多项式朴素贝叶斯（MultinomialNB）和伯努利朴素贝叶斯（BernoulliNB）</strong>。</p><p>这三种算法适合应用在不同的场景下，我们应该根据特征变量的不同选择不同的算法：</p><ul><li><p>高斯朴素贝叶斯：特征变量是连续变量，符合高斯分布，比如说人的身高，物体的长度。</p></li><li><p>多项式朴素贝叶斯：特征变量是离散变量，符合多项分布，在文档分类中特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。</p></li><li><p>伯努利朴素贝叶斯：特征变量是布尔变量，符合 0/1 分布，在文档分类中特征是单词是否出现。</p></li></ul><p>伯努利朴素贝叶斯是以文件为粒度，如果该单词在某文件中出现了即为 1，否则为 0。而多项式朴素贝叶斯是以单词为粒度，会计算在某个文件中的具体次数。而高斯朴素贝叶斯适合处理特征变量是连续变量，且符合正态分布（高斯分布）的情况。比如身高、体重这种自然界的现象就比较适合用高斯朴素贝叶斯来处理。而文本分类是使用多项式朴素贝叶斯或者伯努利朴素贝叶斯。</p><h3 id="TF-IDF-值"><a href="#TF-IDF-值" class="headerlink" title="TF-IDF 值"></a>TF-IDF 值</h3><p>我在多项式朴素贝叶斯中提到了“词的 TF-IDF 值”，如何理解这个概念呢？</p><p>TF-IDF 是一个统计方法，用来评估某个词语对于一个文件集或文档库中的其中一份文件的重要程度。</p><p>TF-IDF 实际上是两个词组 <strong>Term Frequency 和 Inverse Document Frequency</strong> 的总称，两者缩写为 TF 和 IDF，分别代表了词频和逆向文档频率。</p><p><strong>词频 TF</strong> 计算了一个单词在文档中出现的次数，它认为一个单词的重要性和它在文档中出现的次数呈正比。</p><p><strong>逆向文档频率 IDF</strong>，是指一个单词在文档中的区分度。它认为一个单词出现在的文档数越少，就越能通过这个单词把该文档和其他文档区分开。IDF 越大就代表该单词的区分度越大。</p><p>所以 TF-IDF 实际上是词频 TF 和逆向文档频率 IDF 的乘积。这样我们倾向于找到 TF 和 IDF 取值都高的单词作为区分，即这个单词在一个文档中出现的次数多，同时又很少出现在其他文档中。这样的单词适合用于分类。</p><p><strong>TF-IDF 如何计算</strong>首先我们看下词频 TF 和逆向文档概率 IDF 的公式。</p><p><img src="p1.png" alt="p1"></p><p><strong>为什么 IDF 的分母中，单词出现的文档数要加 1 呢？因为有些单词可能不会存在文档中，为了避免分母为 0，统一给单词出现的文档数都加 1。</strong></p><p><strong>TF-IDF=TF*IDF</strong></p><p>你可以看到，TF-IDF 值就是 TF 与 IDF 的乘积, 这样可以更准确地对文档进行分类。比如“我”这样的高频单词，虽然 TF 词频高，但是 IDF 值很低，整体的 TF-IDF 也不高。</p><p>我在这里举个例子。假设一个文件夹里一共有 10 篇文档，其中一篇文档有 1000 个单词，“this”这个单词出现 20 次，“bayes”出现了 5 次。“this”在所有文档中均出现过，而“bayes”只在 2 篇文档中出现过。我们来计算一下这两个词语的 TF-IDF 值。针对“this”，计算 TF-IDF 值：</p><p><img src="p2.png" alt="p2"></p><p>所以 TF-IDF=0.02*(-0.0414)=-8.28e-4。</p><p>针对“bayes”，计算 TF-IDF 值：</p><p><img src="p3.png" alt="p3"></p><p>TF-IDF=0.005*0.5229=2.61e-3。</p><p>很明显“bayes”的 TF-IDF 值要大于“this”的 TF-IDF 值。这就说明用“bayes”这个单词做区分比单词“this”要好。</p><p><strong>如何求 TF-IDF</strong></p><p>在 sklearn 中我们直接使用 TfidfVectorizer 类，它可以帮我们计算单词 TF-IDF 向量的值。</p><p>在这个类中，取 sklearn 计算的对数 log 时，底数是 e，不是 10。下面我来讲下如何创建 TfidfVectorizer 类。</p><p>创建 TfidfVectorizer 的方法是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TfidfVectorizer(stop_words=stop_words, token_pattern=token_pattern)</span><br></pre></td></tr></table></figure><p>我们在创建的时候，有两个构造参数，可以自定义停用词 stop_words 和规律规则 token_pattern。需要注意的是传递的数据结构，停用词 stop_words 是一个列表 List 类型，而过滤规则 token_pattern 是正则表达式。什么是停用词？停用词就是在分类中没有用的词，这些词一般词频 TF 高，但是 IDF 很低，起不到分类的作用。为了节省空间和计算时间，我们把这些词作为停用词 stop words，告诉机器这些词不需要帮我计算。</p><p><img src="p4.png" alt="p4"></p><p>当我们创建好 TF-IDF 向量类型时，可以用 fit_transform 帮我们计算，返回给我们文本矩阵，该矩阵表示了每个单词在每个文档中的 TF-IDF 值。</p><p><img src="p5.png" alt="p5"></p><p>在我们进行 fit_transform 拟合模型后，我们可以得到更多的 TF-IDF 向量属性，比如，我们可以得到词汇的对应关系（字典类型）和向量的 IDF 值，当然也可以获取设置的停用词 stop_words。</p><p><img src="p6.png" alt="p6"></p><h3 id="如何对文档进行分类"><a href="#如何对文档进行分类" class="headerlink" title="如何对文档进行分类"></a>如何对文档进行分类</h3><p>如果我们要对文档进行分类，有两个重要的阶段：</p><p><img src="p7.png" alt="p7"></p><ol><li><p>基于分词的数据准备，包括分词、单词权重计算、去掉停用词；</p></li><li><p>应用朴素贝叶斯分类进行分类，首先通过训练集得到朴素贝叶斯分类器，然后将分类器应用于测试集，并与实际结果做对比，最终得到测试集的分类准确率。</p></li></ol><p>整个流程将分成下面几个模块：</p><ul><li>模块 1：对文档进行分词在准备阶段里，最重要的就是分词。那么如果给文档进行分词呢？英文文档和中文文档所使用的分词工具不同。</li></ul><p>在英文文档中，最常用的是 NTLK 包。NTLK 包中包含了英文的停用词 stop words、分词和标注方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">word_list = nltk.word_tokenize(text) <span class="comment">#分词</span></span><br><span class="line">nltk.pos_tag(word_list) <span class="comment">#标注单词的词性</span></span><br></pre></td></tr></table></figure><p>在中文文档中，最常用的是 jieba 包。jieba 包中包含了中文的停用词 stop words 和分词方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">word_list = jieba.cut (text) <span class="comment">#中文分词</span></span><br></pre></td></tr></table></figure><ul><li>模块 2：加载停用词表</li></ul><p>我们需要自己读取停用词表文件，从网上可以找到中文常用的停用词保存在 stop_words.txt，然后利用 Python 的文件读取函数读取文件，保存在 stop_words 数组中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop_words = [line.strip().decode(<span class="string">'utf-8'</span>) <span class="keyword">for</span> line <span class="keyword">in</span> io.open(<span class="string">'stop_words.txt'</span>).readlines()]</span><br></pre></td></tr></table></figure><ul><li>模块 3：计算单词的权重</li></ul><p>这里我们用到 sklearn 里的 TfidfVectorizer 类，上面我们介绍过它使用的方法。直接创建 TfidfVectorizer 类，然后使用 fit_transform 方法进行拟合，得到 TF-IDF 特征空间 features，你可以理解为选出来的分词就是特征。我们计算这些特征在文档上的特征向量，得到特征空间 features。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">tf = TfidfVectorizer(stop_words=stop_words, max_df=<span class="number">0.5</span>)</span><br><span class="line">features = tf.fit_transform(train_contents)</span><br></pre></td></tr></table></figure><p>这里 max_df 参数用来描述单词在文档中的最高出现率。假设 max_df=0.5，代表一个单词在 50% 的文档中都出现过了，那么它只携带了非常少的信息，因此就不作为分词统计。一般很少设置 min_df，因为 min_df 通常都会很小。</p><ul><li>模块 4：生成朴素贝叶斯分类器</li></ul><p>我们将特征训练集的特征空间 train_features，以及训练集对应的分类 train_labels 传递给贝叶斯分类器 clf，它会自动生成一个符合特征空间和对应分类的分类器。</p><p>这里我们采用的是多项式贝叶斯分类器，其中 alpha 为平滑参数。为什么要使用平滑呢？因为如果一个单词在训练样本中没有出现，这个单词的概率就会被计算为 0。但训练集样本只是整体的抽样情况，我们不能因为一个事件没有观察到，就认为整个事件的概率为 0。为了解决这个问题，我们需要做平滑处理。当 alpha=1 时，使用的是 Laplace 平滑。</p><p>Laplace 平滑就是采用加 1 的方式，来统计没有出现过的单词的概率。这样当训练样本很大的时候，加 1 得到的概率变化可以忽略不计，也同时避免了零概率的问题。</p><p>当 0&lt; alpha &lt;1 时，使用的是 Lidstone 平滑。对于 Lidstone 平滑来说，alpha 越小，迭代次数越多，精度越高。我们可以设置 alpha 为 0.001。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 多项式贝叶斯分类器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB  </span><br><span class="line">clf = MultinomialNB(alpha=<span class="number">0.001</span>).fit(train_features, train_labels)</span><br></pre></td></tr></table></figure><ul><li>模块 5：使用生成的分类器</li></ul><p>做预测首先我们需要得到测试集的特征矩阵。方法是用训练集的分词创建一个 TfidfVectorizer 类，使用同样的 stop_words 和 max_df，然后用这个 TfidfVectorizer 类对测试集的内容进行 fit_transform 拟合，得到测试集的特征矩阵 test_features。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">test_tf = TfidfVectorizer(stop_words=stop_words, max_df=<span class="number">0.5</span>, vocabulary=train_vocabulary)</span><br><span class="line">test_features=test_tf.fit_transform(test_contents)</span><br></pre></td></tr></table></figure><p>然后我们用训练好的分类器对新数据做预测。</p><p>方法是使用 predict 函数，传入测试集的特征矩阵 test_features，得到分类结果 predicted_labels。predict 函数做的工作就是求解所有后验概率并找出最大的那个。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">predicted_labels=clf.predict(test_features)</span><br></pre></td></tr></table></figure><ul><li>模块 6：计算准确率</li></ul><p>计算准确率实际上是对分类模型的评估。我们可以调用 sklearn 中的 metrics 包，在 metrics 中提供了 accuracy_score 函数，方便我们对实际结果和预测的结果做对比，给出模型的准确率。使用方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">print</span> metrics.accuracy_score(test_labels, predicted_labels)</span><br></pre></td></tr></table></figure><h3 id="数据挖掘神器-sklearn"><a href="#数据挖掘神器-sklearn" class="headerlink" title="数据挖掘神器 sklearn"></a>数据挖掘神器 sklearn</h3><p>从数据挖掘的流程来看，一般包括了获取数据、数据清洗、模型训练、模型评估和模型部署这几个过程。</p><p>sklearn 中包含了大量的数据挖掘算法，比如三种朴素贝叶斯算法，我们只需要了解不同算法的适用条件，以及创建时所需的参数，就可以用模型帮我们进行训练。在模型评估中，sklearn 提供了 metrics 包，帮我们对预测结果与实际结果进行评估。在文档分类的项目中，我们针对文档的特点，给出了基于分词的准备流程。一般来说 NTLK 包适用于英文文档，而 jieba 适用于中文文档。我们可以根据文档选择不同的包，对文档提取分词。</p><p>这些分词就是贝叶斯分类中最重要的特征属性。基于这些分词，我们得到分词的权重，即特征矩阵。通过特征矩阵与分类结果，我们就可以创建出朴素贝叶斯分类器，然后用分类器进行预测，最后预测结果与实际结果做对比即可以得到分类器在测试集上的准确率。</p><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>文档共有 4 种类型：女性、体育、文学、校园</p><p>根据下面给定的训练数据和测试数据进行 朴素贝叶斯文本分类实战。</p><p>数据地址：<a href="https://github.com/cystanford/text_classification/tree/master/text%20classification" target="_blank" rel="external nofollow noopener noreferrer">https://github.com/cystanford/text_classification/tree/master/text%20classification</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="comment"># 中文文本分类</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_words</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对文本进行切词</span></span><br><span class="line"><span class="string">    :param file_path: txt文本路径</span></span><br><span class="line"><span class="string">    :return: 用空格分词的字符串</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    text_with_spaces = <span class="string">''</span></span><br><span class="line">    <span class="keyword">with</span> open(file_path, <span class="string">'r'</span>, encoding=<span class="string">'gb18030'</span>, errors=<span class="string">'ignore'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        text = f.read()</span><br><span class="line">        textcut = jieba.cut(text)</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> textcut:</span><br><span class="line">            text_with_spaces += word + <span class="string">' '</span></span><br><span class="line">    <span class="keyword">return</span> text_with_spaces</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">text_category = [<span class="string">'女性'</span>, <span class="string">'体育'</span>, <span class="string">'文学'</span>, <span class="string">'校园'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadfile</span><span class="params">(data_path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    将路径下的所有文件加载</span></span><br><span class="line"><span class="string">    :param file_dir: 保存txt文件目录</span></span><br><span class="line"><span class="string">    :param label: 文档标签</span></span><br><span class="line"><span class="string">    :return: 分词后的文档列表和标签</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    words_list = []</span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">for</span> category <span class="keyword">in</span> text_category:</span><br><span class="line">        file_path = data_path  + category + <span class="string">'/'</span></span><br><span class="line">        file_list = os.listdir(file_path)</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> file_list:</span><br><span class="line">            words_list.append(cut_words(file_path+file))</span><br><span class="line">        labels.append(category)</span><br><span class="line">    <span class="keyword">return</span> words_list, labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stop_words</span><span class="params">(stop_words_path)</span>:</span></span><br><span class="line">    stop_words = open(stop_words_path, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>).read()</span><br><span class="line">    stop_words = stop_words.encode(<span class="string">'utf-8'</span>).decode(<span class="string">'utf-8-sig'</span>)  <span class="comment"># 列表头部\ufeff处理</span></span><br><span class="line">    stop_words = stop_words.split(<span class="string">'\n'</span>)  <span class="comment"># 根据分隔符分隔</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> stop_words</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    train_data_path = <span class="string">'train'</span> + <span class="string">'/'</span></span><br><span class="line">    test_data_path = <span class="string">'test'</span> + <span class="string">'/'</span></span><br><span class="line">    stop_words_path = <span class="string">'stop/stopword.txt'</span></span><br><span class="line">    train_words_list, train_labels = loadfile(train_data_path)</span><br><span class="line"></span><br><span class="line">    test_words_list, test_labels = loadfile(test_data_path)</span><br><span class="line"></span><br><span class="line">    stop_words = get_stop_words(stop_words_path)</span><br><span class="line"></span><br><span class="line">    tf = TfidfVectorizer(stop_words=stop_words, max_df=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    train_features = tf.fit_transform(train_words_list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 上面fit过了，这里transform</span></span><br><span class="line">    test_features = tf.transform(test_words_list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 多项式贝叶斯分类器</span></span><br><span class="line">    <span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"></span><br><span class="line">    clf = MultinomialNB(alpha=<span class="number">0.001</span>).fit(train_features, train_labels)</span><br><span class="line">    predicted_labels = clf.predict(test_features)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    print(<span class="string">'准确率为：'</span>, metrics.accuracy_score(test_labels, predicted_labels))</span><br></pre></td></tr></table></figure></div><div class="article-footer"><blockquote class="mt-2x"><ul class="post-copyright list-unstyled"><li class="post-copyright-link hidden-xs"><strong>本文链接：</strong> <a href="cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/" title="数据分析-朴素贝叶斯（下）" target="_blank" rel="external">cpeixin.cn/2019/01/21/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8B%EF%BC%89/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external nofollow noopener noreferrer">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！</li></ul></blockquote><div class="panel panel-default panel-badger"><div class="panel-body"><figure class="media"><div class="media-left"><a href="https://github.com/cpeixin" target="_blank" class="img-burn thumb-sm visible-lg" rel="external nofollow noopener noreferrer"><img src="/images/avatar.jpg" class="img-rounded w-full" alt></a></div><div class="media-body"><h3 class="media-heading"><a href="https://github.com/cpeixin" target="_blank" rel="external nofollow noopener noreferrer"><span class="text-dark">Brent</span><small class="ml-1x">大数据工程师 &amp; 机器学习</small></a></h3><div>一心九用的工程师</div></div></figure></div></div></div></article><section id="comments"><div id="vcomments"></div></section></div><nav class="bar bar-footer clearfix" data-stick-bottom><div class="bar-inner"><ul class="pager pull-left"><li class="prev"><a href="/2019/01/24/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-SVM-1/" title="数据分析-SVM_1"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;Newer</span></a></li><li class="next"><a href="/2019/01/20/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88%E4%B8%8A%EF%BC%89/" title="数据分析-朴素贝叶斯（上）"><span>Older&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a></li></ul><button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>$</span></button><div class="bar-right"><div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div></div></div></nav><div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog"><div class="modal-dialog" role="document"><div class="modal-content donate"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button><div class="modal-body"><div class="donate-box"><div class="donate-head"><p>Maybe you could buy me a cup of coffee.</p></div><div class="tab-content"><div role="tabpanel" class="tab-pane fade active in" id="alipay"><div class="donate-payimg"><img src="/images/donate/alipayimg.png" alt="Scan Qrcode" title="Scan"></div><p class="text-muted mv">Scan this qrcode</p><p class="text-grey">Open alipay app scan this qrcode, buy me a coffee!</p></div><div role="tabpanel" class="tab-pane fade" id="wechatpay"><div class="donate-payimg"><img src="/images/donate/wechatpayimg.png" alt="Scan Qrcode" title="Scan"></div><p class="text-muted mv">Scan this qrcode</p><p class="text-grey">Open wechat app scan this qrcode, buy me a coffee!</p></div></div><div class="donate-footer"><ul class="nav nav-tabs nav-justified" role="tablist"><li role="presentation" class="active"><a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> alipay</a></li><li role="presentation"><a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> wechat payment</a></li></ul></div></div></div></div></div></div></main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter"><ul class="social-links"><li><a href="https://github.com/cpeixin" target="_blank" title="Github" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-github"></i></a></li><li><a href="https://www.weibo.com/u/1970875963" target="_blank" title="Weibo" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-weibo"></i></a></li><li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-twitter"></i></a></li><li><a href="https://www.behance.net/cofess" target="_blank" title="Behance" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-behance"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul><div class="copyright"><div class="publishby">Theme by <a href="https://github.com/cofess" target="_blank" rel="external nofollow noopener noreferrer">cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank" rel="external nofollow noopener noreferrer">pure</a>.</div></div></footer><script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script><script>window.jQuery||document.write('<script src="js/jquery.min.js"><\/script>')</script><script src="/js/plugin.min.js"></script><script src="/js/application.js"></script><script>!function(T){var n={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"};T.INSIGHT_CONFIG=n}(window)</script><script src="/js/insight.js"></script><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/npm/valine"></script><script type="text/javascript">var GUEST=["nick","mail","link"],meta="nick,mail,link";meta=meta.split(",").filter(function(e){return GUEST.indexOf(e)>-1}),new Valine({el:"#vcomments",verify:!1,notify:!1,appId:"SsxmBzBQ3R2S2zWTv0FrONel-gzGzoHsz",appKey:"w0K528Ye7NhOr07RHrzVzHbW",placeholder:"说点什么呢？",avatar:"mm",meta:meta,pageSize:"10",visitor:!0})</script></body></html><!-- rebuild by neat -->