<!-- build time:Tue Jan 12 2021 23:56:38 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta name="renderer" content="webkit"><meta name="referrer" content="no-referrer"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=no,email=no,adress=no"><meta name="theme-color" content="#000000"><meta http-equiv="window-target" content="_top"><title>数据分析-决策树实战-泰坦尼克号乘客生存预测 | 布兰特 | 不忘初心</title><meta name="description" content="在前面的两篇文章中，我给你讲了决策树算法。决策树算法是经常使用的数据挖掘算法，这是因为决策树就像一个人脑中的决策模型一样，呈现出来非常直观。基于决策树还诞生了很多数据挖掘算法，比如随机森林（Random forest）。今天我来带你用决策树进行项目的实战。决策树分类的应用场景非常广泛，在各行各业都有应用，比如在金融行业可以用决策树做贷款风险评估，医疗行业可以用决策树生成辅助诊断，电商行业可以用决策"><meta property="og:type" content="article"><meta property="og:title" content="数据分析-决策树实战-泰坦尼克号乘客生存预测"><meta property="og:url" content="cpeixin.cn/2018/07/15/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E6%88%98-%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B/index.html"><meta property="og:site_name" content="布兰特 | 不忘初心"><meta property="og:description" content="在前面的两篇文章中，我给你讲了决策树算法。决策树算法是经常使用的数据挖掘算法，这是因为决策树就像一个人脑中的决策模型一样，呈现出来非常直观。基于决策树还诞生了很多数据挖掘算法，比如随机森林（Random forest）。今天我来带你用决策树进行项目的实战。决策树分类的应用场景非常广泛，在各行各业都有应用，比如在金融行业可以用决策树做贷款风险评估，医疗行业可以用决策树生成辅助诊断，电商行业可以用决策"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585397403010-430bb637-799a-49af-af7a-d5a1c9784b03.png#align=left&display=inline&height=598&margin=%5Bobject%20Object%5D&originHeight=598&originWidth=1716&size=0&status=done&style=none&width=1716"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585397784656-cb8448e4-2dd0-4d2b-a0dc-182c9759766e.png#align=left&display=inline&height=940&margin=%5Bobject%20Object%5D&name=p6.png&originHeight=940&originWidth=2308&size=395883&status=done&style=none&width=2308"><meta property="article:published_time" content="2018-07-15T14:12:49.000Z"><meta property="article:modified_time" content="2020-05-01T14:18:39.272Z"><meta property="article:author" content="Brent"><meta property="article:tag" content="Decision Tree"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585397403010-430bb637-799a-49af-af7a-d5a1c9784b03.png#align=left&display=inline&height=598&margin=%5Bobject%20Object%5D&originHeight=598&originWidth=1716&size=0&status=done&style=none&width=1716"><link rel="canonical" href="cpeixin.cn/2018/07/15/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E6%88%98-%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B/index.html"><link rel="alternate" href="/atom.xml" title="布兰特 | 不忘初心" type="application/atom+xml"><link rel="icon" href="/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.3.5/dist/jquery.fancybox.min.css" rel="stylesheet"><meta name="generator" content="Hexo 4.2.0"></head><body class="main-center" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="slimContent"><div class="navbar-header"><div class="profile-block text-center"><a id="avatar" href="https://github.com/cpeixin" target="_blank" rel="external nofollow noopener noreferrer"><img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200"></a><h2 id="name" class="hidden-xs hidden-sm">Brent</h2><h3 id="title" class="hidden-xs hidden-sm hidden-md">大数据工程师 &amp; 机器学习</h3><small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Malaysia</small></div><div class="search" id="search-form-wrap"><form class="search-form sidebar-form"><div class="input-group"><input type="text" class="search-form-input form-control" placeholder="搜索"> <span class="input-group-btn"><button type="submit" class="search-form-submit btn btn-flat" onclick="return!1"><i class="icon icon-search"></i></button></span></div></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech> <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div></div><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button></div><nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation"><ul class="nav navbar-nav main-nav"><li class="menu-item menu-item-home"><a href="/."><i class="icon icon-home-fill"></i> <span class="menu-title">首页</span></a></li><li class="menu-item menu-item-archives"><a href="/archives"><i class="icon icon-archives-fill"></i> <span class="menu-title">归档</span></a></li><li class="menu-item menu-item-categories"><a href="/categories"><i class="icon icon-folder"></i> <span class="menu-title">分类</span></a></li><li class="menu-item menu-item-tags"><a href="/tags"><i class="icon icon-tags"></i> <span class="menu-title">标签</span></a></li><li class="menu-item menu-item-repository"><a href="/repository"><i class="icon icon-project"></i> <span class="menu-title">项目</span></a></li><li class="menu-item menu-item-books"><a href="/books"><i class="icon icon-book-fill"></i> <span class="menu-title">书单</span></a></li><li class="menu-item menu-item-links"><a href="/links"><i class="icon icon-friendship"></i> <span class="menu-title">友链</span></a></li><li class="menu-item menu-item-about"><a href="/about"><i class="icon icon-cup-fill"></i> <span class="menu-title">关于</span></a></li></ul><ul class="social-links"><li><a href="https://github.com/cpeixin" target="_blank" title="Github" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-github"></i></a></li><li><a href="https://www.weibo.com/u/1970875963" target="_blank" title="Weibo" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-weibo"></i></a></li><li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-twitter"></i></a></li><li><a href="https://www.behance.net/cofess" target="_blank" title="Behance" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-behance"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul></nav></div></header><aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><div class="widget"><h3 class="widget-title">公告</h3><div class="widget-body"><div id="board"><div class="content"><p>人处在一种默默奋斗的状态，精神就会从琐碎生活中得到升华</p></div></div></div></div><div class="widget"><h3 class="widget-title">分类</h3><div class="widget-body"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBases/">DataBases</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tools/">Tools</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><span class="category-list-count">111</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7/">工具</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/">开发工具</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">31</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9E%B6%E6%9E%84/">架构</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/">源码系列</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/">计算机组成原理</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a><span class="category-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">标签</h3><div class="widget-body"><ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Apriori/" rel="tag">Apriori</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/COS/" rel="tag">COS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CPU/" rel="tag">CPU</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DMP/" rel="tag">DMP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Decision-Tree/" rel="tag">Decision Tree</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EM/" rel="tag">EM</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ETL/" rel="tag">ETL</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Flink/" rel="tag">Flink</a><span class="tag-list-count">33</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPT-2/" rel="tag">GPT-2</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HBase/" rel="tag">HBase</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HashMap/" rel="tag">HashMap</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IDEA/" rel="tag">IDEA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/K-Means/" rel="tag">K-Means</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KNN/" rel="tag">KNN</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LRU%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95/" rel="tag">LRU淘汰算法</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Naive-Bayes/" rel="tag">Naive Bayes</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OLAP/" rel="tag">OLAP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PageRank/" rel="tag">PageRank</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Parquet/" rel="tag">Parquet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Random-Forest/" rel="tag">Random Forest</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flask/" rel="tag">flask</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flink/" rel="tag">flink</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hdfs/" rel="tag">hdfs</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hive/" rel="tag">hive</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/" rel="tag">java</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/" rel="tag">kafka</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kali/" rel="tag">kali</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mapreduce/" rel="tag">mapreduce</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/" rel="tag">mysql</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paxos/" rel="tag">paxos</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/" rel="tag">redis</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala/" rel="tag">scala</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shadowsock/" rel="tag">shadowsock</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/skipList/" rel="tag">skipList</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sklearn/" rel="tag">sklearn</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/" rel="tag">spark</a><span class="tag-list-count">29</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/yarn/" rel="tag">yarn</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" rel="tag">二分查找</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" rel="tag">二叉树</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" rel="tag">动态规划</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/" rel="tag">单例模式</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E6%BA%AF/" rel="tag">回溯</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A0%86/" rel="tag">堆</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/" rel="tag">布隆过滤器</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%92%E5%BA%8F/" rel="tag">排序</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%A3%E5%88%97%E8%A1%A8/" rel="tag">散列表</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" rel="tag">数据仓库</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/" rel="tag">数据清洗</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" rel="tag">数据采集</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E7%BB%84/" rel="tag">数组</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/" rel="tag">时间序列</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8/" rel="tag">服务器安全</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A0%88/" rel="tag">栈</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="tag">特征工程</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/" rel="tag">用户画像</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/" rel="tag">红黑树</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E8%A1%A8/" rel="tag">线性表</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AF%8D%E5%90%91%E9%87%8F/" rel="tag">词向量</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%92%E5%BD%92/" rel="tag">递归</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" rel="tag">逻辑回归</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E8%A1%A8/" rel="tag">链表</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%98%9F%E5%88%97/" rel="tag">队列</a><span class="tag-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">标签云</h3><div class="widget-body tagcloud"><a href="/tags/Apriori/" style="font-size:13.11px">Apriori</a> <a href="/tags/COS/" style="font-size:13px">COS</a> <a href="/tags/CPU/" style="font-size:13px">CPU</a> <a href="/tags/DMP/" style="font-size:13px">DMP</a> <a href="/tags/Decision-Tree/" style="font-size:13.44px">Decision Tree</a> <a href="/tags/EM/" style="font-size:13.11px">EM</a> <a href="/tags/ETL/" style="font-size:13px">ETL</a> <a href="/tags/Flink/" style="font-size:14px">Flink</a> <a href="/tags/GPT-2/" style="font-size:13px">GPT-2</a> <a href="/tags/HBase/" style="font-size:13.56px">HBase</a> <a href="/tags/HashMap/" style="font-size:13px">HashMap</a> <a href="/tags/Hive/" style="font-size:13px">Hive</a> <a href="/tags/IDEA/" style="font-size:13px">IDEA</a> <a href="/tags/K-Means/" style="font-size:13px">K-Means</a> <a href="/tags/KNN/" style="font-size:13.11px">KNN</a> <a href="/tags/LRU%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95/" style="font-size:13px">LRU淘汰算法</a> <a href="/tags/Naive-Bayes/" style="font-size:13.11px">Naive Bayes</a> <a href="/tags/OLAP/" style="font-size:13px">OLAP</a> <a href="/tags/PageRank/" style="font-size:13.11px">PageRank</a> <a href="/tags/Parquet/" style="font-size:13px">Parquet</a> <a href="/tags/Random-Forest/" style="font-size:13px">Random Forest</a> <a href="/tags/SVM/" style="font-size:13.11px">SVM</a> <a href="/tags/docker/" style="font-size:13.11px">docker</a> <a href="/tags/flask/" style="font-size:13.11px">flask</a> <a href="/tags/flink/" style="font-size:13px">flink</a> <a href="/tags/hdfs/" style="font-size:13.33px">hdfs</a> <a href="/tags/hive/" style="font-size:13.44px">hive</a> <a href="/tags/java/" style="font-size:13px">java</a> <a href="/tags/kafka/" style="font-size:13.67px">kafka</a> <a href="/tags/kali/" style="font-size:13px">kali</a> <a href="/tags/mapreduce/" style="font-size:13.11px">mapreduce</a> <a href="/tags/mysql/" style="font-size:13.22px">mysql</a> <a href="/tags/paxos/" style="font-size:13.11px">paxos</a> <a href="/tags/python/" style="font-size:13.56px">python</a> <a href="/tags/redis/" style="font-size:13.33px">redis</a> <a href="/tags/scala/" style="font-size:13.33px">scala</a> <a href="/tags/shadowsock/" style="font-size:13px">shadowsock</a> <a href="/tags/skipList/" style="font-size:13px">skipList</a> <a href="/tags/sklearn/" style="font-size:13px">sklearn</a> <a href="/tags/spark/" style="font-size:13.89px">spark</a> <a href="/tags/yarn/" style="font-size:13px">yarn</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" style="font-size:13.11px">二分查找</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size:13.22px">二叉树</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size:13px">动态规划</a> <a href="/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/" style="font-size:13px">单例模式</a> <a href="/tags/%E5%9B%9E%E6%BA%AF/" style="font-size:13px">回溯</a> <a href="/tags/%E5%A0%86/" style="font-size:13px">堆</a> <a href="/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/" style="font-size:13px">布隆过滤器</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size:13.78px">排序</a> <a href="/tags/%E6%95%A3%E5%88%97%E8%A1%A8/" style="font-size:13px">散列表</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" style="font-size:13.78px">数据仓库</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/" style="font-size:13px">数据清洗</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" style="font-size:13px">数据采集</a> <a href="/tags/%E6%95%B0%E7%BB%84/" style="font-size:13px">数组</a> <a href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/" style="font-size:13px">时间序列</a> <a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8/" style="font-size:13.11px">服务器安全</a> <a href="/tags/%E6%A0%88/" style="font-size:13px">栈</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size:13px">深度学习</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size:13px">爬虫</a> <a href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" style="font-size:13.33px">特征工程</a> <a href="/tags/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/" style="font-size:13.11px">用户画像</a> <a href="/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/" style="font-size:13px">红黑树</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E8%A1%A8/" style="font-size:13px">线性表</a> <a href="/tags/%E8%AF%8D%E5%90%91%E9%87%8F/" style="font-size:13px">词向量</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size:13px">递归</a> <a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" style="font-size:13px">逻辑回归</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size:13.11px">链表</a> <a href="/tags/%E9%98%9F%E5%88%97/" style="font-size:13px">队列</a></div></div><div class="widget"><h3 class="widget-title">归档</h3><div class="widget-body"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">一月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a><span class="archive-list-count">16</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">九月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a><span class="archive-list-count">22</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">最新文章</h3><div class="widget-body"><ul class="recent-post-list list-unstyled no-thumbnail"><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></p><p class="item-title"><a href="/2021/01/12/Hive-Cli-%E5%90%AF%E5%8A%A8%E5%8D%A1%E6%AD%BB%E7%9A%84%E9%97%AE%E9%A2%98/" class="title">Hive Cli 启动卡死的问题</a></p><p class="item-date"><time datetime="2021-01-12T15:54:22.000Z" itemprop="datePublished">2021-01-12</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/">源码系列</a></p><p class="item-title"><a href="/2020/12/06/MapReduce%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E4%B8%80/" class="title">MapReduce源码解析(一)</a></p><p class="item-date"><time datetime="2020-12-06T10:15:23.000Z" itemprop="datePublished">2020-12-06</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></p><p class="item-title"><a href="/2020/11/29/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E6%96%B0%E6%A8%A1%E5%BC%8F-%E5%AD%98%E7%AE%97%E5%88%86%E7%A6%BB/" class="title">大数据集群新模式-存算分离</a></p><p class="item-date"><time datetime="2020-11-29T15:02:43.000Z" itemprop="datePublished">2020-11-29</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></p><p class="item-title"><a href="/2020/11/21/Flink%E6%B6%88%E8%B4%B9Kafka%E4%BB%A5%E5%8F%8A%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE/" class="title">Flink消费Kafka以及参数设置</a></p><p class="item-date"><time datetime="2020-11-21T10:25:43.000Z" itemprop="datePublished">2020-11-21</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></p><p class="item-title"><a href="/2020/11/19/%E5%85%B3%E4%BA%8EHive%E4%B8%AD%E7%9A%84NULL/" class="title">关于Hive中的NULL</a></p><p class="item-date"><time datetime="2020-11-18T16:35:14.000Z" itemprop="datePublished">2020-11-19</time></p></div></li></ul></div></div></div></aside><main class="main" role="main"><div class="content"><article id="post-数据分析-决策树实战-泰坦尼克号乘客生存预测" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting"><div class="article-header"><h1 class="article-title" itemprop="name">数据分析-决策树实战-泰坦尼克号乘客生存预测</h1><div class="article-meta"><span class="article-date"><i class="icon icon-calendar-check"></i> <a href="/2018/07/15/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E6%88%98-%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B/" class="article-date"><time datetime="2018-07-15T14:12:49.000Z" itemprop="datePublished">2018-07-15</time></a></span> <span class="article-category"><i class="icon icon-folder"></i> <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span> <span class="article-tag"><i class="icon icon-tags"></i> <a class="article-tag-link" href="/tags/Decision-Tree/" rel="tag">Decision Tree</a></span> <span class="article-read hidden-xs"><i class="icon icon-eye-fill" aria-hidden="true"></i> <span id="/2018/07/15/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E6%88%98-%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B/" class="leancloud_visitors" data-flag-title="数据分析-决策树实战-泰坦尼克号乘客生存预测">0</span></span> <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2018/07/15/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E6%88%98-%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B/#comments" class="article-comment-link">评论</a></span> <span class="post-wordcount hidden-xs" itemprop="wordCount">字数统计: 4.2k(字)</span> <span class="post-readcount hidden-xs" itemprop="timeRequired">阅读时长: 17(分)</span></div></div><div class="article-entry marked-body" itemprop="articleBody"><p><br>在前面的两篇文章中，我给你讲了决策树算法。决策树算法是经常使用的数据挖掘算法，这是因为决策树就像一个人脑中的决策模型一样，呈现出来非常直观。<br><br><br>基于决策树还诞生了很多数据挖掘算法，比如随机森林（Random forest）。今天我来带你用决策树进行项目的实战。决策树分类的应用场景非常广泛，在各行各业都有应用，比如在金融行业可以用决策树做贷款风险评估，医疗行业可以用决策树生成辅助诊断，电商行业可以用决策树对销售额进行预测等。<br><br><br>在了解决策树的原理后，今天我们用 sklearn 工具解决一个实际的问题：泰坦尼克号乘客的生存预测。<br><a name="sklearn"></a></p><h3 id="sklearn-中的决策树模型"><a href="#sklearn-中的决策树模型" class="headerlink" title="sklearn 中的决策树模型"></a>sklearn 中的决策树模型</h3><p>首先，我们需要掌握 sklearn 中自带的决策树分类器 DecisionTreeClassifier，方法如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clf = DecisionTreeClassifier(criterion=<span class="string">'entropy'</span>)</span><br></pre></td></tr></table></figure><p><br>到目前为止，sklearn 中只实现了 ID3 与 CART 决策树，所以我们暂时只能使用这两种决策树，在构造 DecisionTreeClassifier 类时，其中有一个参数是 criterion，意为标准。它决定了构造的分类树是采用 ID3 分类树，还是 CART 分类树，对应的取值分别是 entropy 或者 gini</p><ul><li>entropy: 基于信息熵，也就是 ID3 算法，实际结果与 C4.5 相差不大；</li><li>gini：默认参数，基于基尼系数。</li></ul><p><br>CART 算法是基于基尼系数做属性划分的，所以 criterion=gini 时，实际上执行的是 CART 算法。我们通过设置 criterion=’entropy’可以创建一个 ID3 决策树分类器，然后打印下 clf，看下决策树在 sklearn 中是个什么东西？<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DecisionTreeClassifier(class_weight=<span class="literal">None</span>, criterion=<span class="string">'entropy'</span>, max_depth=<span class="literal">None</span>,</span><br><span class="line">            max_features=<span class="literal">None</span>, max_leaf_nodes=<span class="literal">None</span>,</span><br><span class="line">            min_impurity_decrease=<span class="number">0.0</span>, min_impurity_split=<span class="literal">None</span>,</span><br><span class="line">            min_samples_leaf=<span class="number">1</span>, min_samples_split=<span class="number">2</span>,</span><br><span class="line">            min_weight_fraction_leaf=<span class="number">0.0</span>, presort=<span class="literal">False</span>, random_state=<span class="literal">None</span>,</span><br><span class="line">            splitter=<span class="string">'best'</span>)</span><br></pre></td></tr></table></figure><br><br>这里我们看到了很多参数，除了设置 criterion 采用不同的决策树算法外，一般建议使用默认的参数，默认参数不会限制决策树的最大深度，不限制叶子节点数，认为所有分类的权重都相等等。当然你也可以调整这些参数，来创建不同的决策树模型。<br><br>我整理了这些参数代表的含义：<br>![1585397401268-c9ea5ebf-53aa-44e0-8588-13582a240b5d.png](https://cdn.nlark.com/yuque/0/2020/png/1072113/1586919851176-2a57ac36-49da-475d-adc2-dc6f3f2434b3.png#align=left&display=inline&height=930&margin=%5Bobject%20Object%5D&name=1585397401268-c9ea5ebf-53aa-44e0-8588-13582a240b5d.png&originHeight=930&originWidth=620&size=366558&status=done&style=none&width=620)<br><br>在构造决策树分类器后，我们可以使用 fit 方法让分类器进行拟合，使用 predict 方法对新数据进行预测，得到预测的分类结果，也可以使用 score 方法得到分类器的准确率。<br><br>下面这个表格是 fit 方法、predict 方法和 score 方法的作用:<br>![1585397402135-ed1fff6c-1bee-49f9-bf07-9fb87d83e0f3.png](https://cdn.nlark.com/yuque/0/2020/png/1072113/1586919851152-b2b5be44-9293-4e4d-998f-d1acd73a33da.png#align=left&display=inline&height=158&margin=%5Bobject%20Object%5D&name=1585397402135-ed1fff6c-1bee-49f9-bf07-9fb87d83e0f3.png&originHeight=158&originWidth=468&size=27331&status=done&style=none&width=468) <a name="titanic"></a> ### Titanic 乘客生存预测 <a name="-2"></a> #### 问题描述 泰坦尼克海难是著名的十大灾难之一，究竟多少人遇难，各方统计的结果不一。现在我们可以得到部分的数据，具体数据你可以从 GitHub 上下载：[点我](https://github.com/cystanford/Titanic_Data)<br><br>其中数据集格式为 csv，一共有两个文件：<br>train.csv 是训练数据集，包含特征信息和存活与否的标签；<br>test.csv: 测试数据集，只包含特征信息。<br>现在我们需要用决策树分类对训练集进行训练，针对测试集中的乘客进行生存预测，并告知分类器的准确率。在训练集中，包括了以下字段，它们具体为：<br>![1585397401155-e052cf89-fe96-49b3-b3fe-37539d7a67ae.png](https://cdn.nlark.com/yuque/0/2020/png/1072113/1586919895980-6bd3d51e-cf8d-4a92-a444-f540fcba423a.png#align=left&display=inline&height=370&margin=%5Bobject%20Object%5D&name=1585397401155-e052cf89-fe96-49b3-b3fe-37539d7a67ae.png&originHeight=370&originWidth=466&size=41457&status=done&style=none&width=466) <a name="-3"></a> #### 生存预测的关键流程 我们要对训练集中乘客的生存进行预测，这个过程可以划分为两个重要的阶段：<br>![](https://cdn.nlark.com/yuque/0/2020/png/1072113/1585397402088-8ce15112-7300-4b68-b34c-0bc6a0c960c0.png#align=left&display=inline&height=1470&margin=%5Bobject%20Object%5D&originHeight=1470&originWidth=3202&size=0&status=done&style=none&width=3202)<br>**准备阶段**：我们首先需要对训练集、测试集的数据进行探索，分析数据质量，并对数据进行清洗，然后通过特征选择对数据进行降维，方便后续分类运算；<br><br>**分类阶段**：首先通过训练集的特征矩阵、分类结果得到决策树分类器，然后将分类器应用于测试集。然后我们对决策树分类器的准确性进行分析，并对决策树模型进行可视化。<br>下面，我分别对这些模块进行介绍。<br><br>**模块 1**：数据探索<br>数据探索这部分虽然对分类器没有实质作用，但是不可忽略。我们只有足够了解这些数据的特性，才能帮助我们做数据清洗、特征选择。<br>那么如何进行数据探索呢？这里有一些函数你需要了解：<br>使用 info() 了解数据表的基本情况：行数、列数、每列的数据类型、数据完整度；<br>使用 describe() 了解数据表的统计情况：总数、平均值、标准差、最小值、最大值等；<br>使用 describe(include=[‘O’]) 查看字符串类型（非数字）的整体情况；<br>使用 head 查看前几行数据（默认是前 5 行）；<br>使用 tail 查看后几行数据（默认是最后 5 行）。<br>我们可以使用 Pandas 便捷地处理这些问题：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train.csv'</span>)</span><br><span class="line"></span><br><span class="line">print(train_data.info())</span><br><span class="line">print(<span class="string">"==========================================="</span>)</span><br><span class="line">print(train_data.describe())</span><br><span class="line"></span><br><span class="line">print(<span class="string">"==========================================="</span>)</span><br><span class="line"></span><br><span class="line">print(train_data.describe(include=[<span class="string">'O'</span>]))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"==========================================="</span>)</span><br><span class="line"></span><br><span class="line">print(train_data.head())</span><br><span class="line"></span><br><span class="line">print(<span class="string">"==========================================="</span>)</span><br><span class="line"></span><br><span class="line">print(train_data.tail())</span><br></pre></td></tr></table></figure><p><br>运行结果：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">891</span> entries, <span class="number">0</span> to <span class="number">890</span></span><br><span class="line">Data columns (total <span class="number">12</span> columns):</span><br><span class="line">PassengerId    <span class="number">891</span> non-null int64</span><br><span class="line">Survived       <span class="number">891</span> non-null int64</span><br><span class="line">Pclass         <span class="number">891</span> non-null int64</span><br><span class="line">Name           <span class="number">891</span> non-null object</span><br><span class="line">Sex            <span class="number">891</span> non-null object</span><br><span class="line">Age            <span class="number">714</span> non-null float64</span><br><span class="line">SibSp          <span class="number">891</span> non-null int64</span><br><span class="line">Parch          <span class="number">891</span> non-null int64</span><br><span class="line">Ticket         <span class="number">891</span> non-null object</span><br><span class="line">Fare           <span class="number">891</span> non-null float64</span><br><span class="line">Cabin          <span class="number">204</span> non-null object</span><br><span class="line">Embarked       <span class="number">889</span> non-null object</span><br><span class="line">dtypes: float64(<span class="number">2</span>), int64(<span class="number">5</span>), object(<span class="number">5</span>)</span><br><span class="line">memory usage: <span class="number">83.7</span>+ KB</span><br><span class="line"><span class="literal">None</span></span><br><span class="line">===========================================</span><br><span class="line">       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare</span><br><span class="line">count   <span class="number">891.000000</span>  <span class="number">891.000000</span>  <span class="number">891.000000</span>  ...  <span class="number">891.000000</span>  <span class="number">891.000000</span>  <span class="number">891.000000</span></span><br><span class="line">mean    <span class="number">446.000000</span>    <span class="number">0.383838</span>    <span class="number">2.308642</span>  ...    <span class="number">0.523008</span>    <span class="number">0.381594</span>   <span class="number">32.204208</span></span><br><span class="line">std     <span class="number">257.353842</span>    <span class="number">0.486592</span>    <span class="number">0.836071</span>  ...    <span class="number">1.102743</span>    <span class="number">0.806057</span>   <span class="number">49.693429</span></span><br><span class="line">min       <span class="number">1.000000</span>    <span class="number">0.000000</span>    <span class="number">1.000000</span>  ...    <span class="number">0.000000</span>    <span class="number">0.000000</span>    <span class="number">0.000000</span></span><br><span class="line"><span class="number">25</span>%     <span class="number">223.500000</span>    <span class="number">0.000000</span>    <span class="number">2.000000</span>  ...    <span class="number">0.000000</span>    <span class="number">0.000000</span>    <span class="number">7.910400</span></span><br><span class="line"><span class="number">50</span>%     <span class="number">446.000000</span>    <span class="number">0.000000</span>    <span class="number">3.000000</span>  ...    <span class="number">0.000000</span>    <span class="number">0.000000</span>   <span class="number">14.454200</span></span><br><span class="line"><span class="number">75</span>%     <span class="number">668.500000</span>    <span class="number">1.000000</span>    <span class="number">3.000000</span>  ...    <span class="number">1.000000</span>    <span class="number">0.000000</span>   <span class="number">31.000000</span></span><br><span class="line">max     <span class="number">891.000000</span>    <span class="number">1.000000</span>    <span class="number">3.000000</span>  ...    <span class="number">8.000000</span>    <span class="number">6.000000</span>  <span class="number">512.329200</span></span><br><span class="line"></span><br><span class="line">[<span class="number">8</span> rows x <span class="number">7</span> columns]</span><br><span class="line">===========================================</span><br><span class="line">                            Name   Sex  Ticket    Cabin Embarked</span><br><span class="line">count                        <span class="number">891</span>   <span class="number">891</span>     <span class="number">891</span>      <span class="number">204</span>      <span class="number">889</span></span><br><span class="line">unique                       <span class="number">891</span>     <span class="number">2</span>     <span class="number">681</span>      <span class="number">147</span>        <span class="number">3</span></span><br><span class="line">top     Wick, Miss. Mary Natalie  male  <span class="number">347082</span>  B96 B98        S</span><br><span class="line">freq                           <span class="number">1</span>   <span class="number">577</span>       <span class="number">7</span>        <span class="number">4</span>      <span class="number">644</span></span><br><span class="line">===========================================</span><br><span class="line">   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked</span><br><span class="line"><span class="number">0</span>            <span class="number">1</span>         <span class="number">0</span>       <span class="number">3</span>  ...   <span class="number">7.2500</span>   NaN         S</span><br><span class="line"><span class="number">1</span>            <span class="number">2</span>         <span class="number">1</span>       <span class="number">1</span>  ...  <span class="number">71.2833</span>   C85         C</span><br><span class="line"><span class="number">2</span>            <span class="number">3</span>         <span class="number">1</span>       <span class="number">3</span>  ...   <span class="number">7.9250</span>   NaN         S</span><br><span class="line"><span class="number">3</span>            <span class="number">4</span>         <span class="number">1</span>       <span class="number">1</span>  ...  <span class="number">53.1000</span>  C123         S</span><br><span class="line"><span class="number">4</span>            <span class="number">5</span>         <span class="number">0</span>       <span class="number">3</span>  ...   <span class="number">8.0500</span>   NaN         S</span><br><span class="line"></span><br><span class="line">[<span class="number">5</span> rows x <span class="number">12</span> columns]</span><br><span class="line">===========================================</span><br><span class="line">     PassengerId  Survived  Pclass  ...   Fare Cabin  Embarked</span><br><span class="line"><span class="number">886</span>          <span class="number">887</span>         <span class="number">0</span>       <span class="number">2</span>  ...  <span class="number">13.00</span>   NaN         S</span><br><span class="line"><span class="number">887</span>          <span class="number">888</span>         <span class="number">1</span>       <span class="number">1</span>  ...  <span class="number">30.00</span>   B42         S</span><br><span class="line"><span class="number">888</span>          <span class="number">889</span>         <span class="number">0</span>       <span class="number">3</span>  ...  <span class="number">23.45</span>   NaN         S</span><br><span class="line"><span class="number">889</span>          <span class="number">890</span>         <span class="number">1</span>       <span class="number">1</span>  ...  <span class="number">30.00</span>  C148         C</span><br><span class="line"><span class="number">890</span>          <span class="number">891</span>         <span class="number">0</span>       <span class="number">3</span>  ...   <span class="number">7.75</span>   NaN         Q</span><br><span class="line"></span><br><span class="line">[<span class="number">5</span> rows x <span class="number">12</span> columns]</span><br></pre></td></tr></table></figure><p><br><strong>模块 2：数据清洗</strong><br>通过数据探索，我们发现 Age 和 Cabin 这三个字段的数据有所缺失。其中 Age 为年龄字段，是数值型，我们可以通过平均值进行补齐；具体实现的代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data[<span class="string">'Age'</span>].fillna(train_data[<span class="string">'Age'</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">'Age'</span>].fillna(test_data[<span class="string">'Age'</span>].mean(),inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><br>Cabin 为船舱，有大量的缺失值。在训练集和测试集中的缺失率分别为 77% 和 78%，无法补齐；Embarked 为登陆港口，有少量的缺失值，我们可以把缺失值补齐。首先观察下 Embarked 字段的取值，方法如下：<br>首先观察下 Embarked 字段的取值，方法如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(train_data[<span class="string">'Embarked'</span>].value_counts())</span><br></pre></td></tr></table></figure><p><br>结果如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">S    <span class="number">644</span></span><br><span class="line">C    <span class="number">168</span></span><br><span class="line">Q     <span class="number">77</span></span><br></pre></td></tr></table></figure><p><br>我们发现一共就 3 个登陆港口，其中 S 港口人数最多，占到了 72%，因此我们将其余缺失的 Embarked 数值均设置为 S：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data[<span class="string">'Embarked'</span>].fillna(<span class="string">'S'</span>, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><br><strong>模块 3：特征选择</strong><br>特征选择是分类器的关键。特征选择不同，得到的分类器也不同。那么我们该选择哪些特征做生存的预测呢？通过数据探索我们发现，PassengerId 为乘客编号，对分类没有作用，可以放弃；Name 为乘客姓名，对分类没有作用，可以放弃；<strong>Cabin 字段缺失值太多，可以放弃；</strong> Ticket 字段为船票号码，杂乱无章且无规律，可以放弃。<br><br><br>其余的字段包括：Pclass、Sex、Age、SibSp、Parch 和 Fare，这些属性分别表示了乘客的船票等级、性别、年龄、亲戚数量以及船票价格，可能会和乘客的生存预测分类有关系。具体是什么关系，我们可以交给分类器来处理。因此我们先将 Pclass、Sex、Age 等这些其余的字段作特征，放到特征向量 features 里。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征选择</span></span><br><span class="line">features = [<span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>, <span class="string">'Embarked'</span>]</span><br><span class="line">train_features = train_data[features]</span><br><span class="line">train_labels = train_data[<span class="string">'Survived'</span>]</span><br><span class="line">test_features = test_data[features]</span><br></pre></td></tr></table></figure><p><br>特征值里有一些是字符串，这样不方便后续的运算，需要转成数值类型，比如 Sex 字段，有 male 和 female 两种取值。我们可以把它变成 Sex=male 和 Sex=female 两个字段，数值用 0 或 1 来表示。同理 Embarked 有 S、C、Q 三种可能，我们也可以改成 Embarked=S、Embarked=C 和 Embarked=Q 三个字段，数值用 0 或 1 来表示。<br><br><br>那该如何操作呢?我们可以使用 sklearn 特征选择中的 DictVectorizer 类，用它将可以处理符号化的对象，将符号转成数字 0/1 进行表示。具体方法如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line">dvec=DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line">train_features=dvec.fit_transform(train_features.to_dict(orient=<span class="string">'record'</span>))</span><br></pre></td></tr></table></figure><p><br>你会看到代码中使用了 fit_transform 这个函数，它可以将特征向量转化为特征值矩阵。然后我们看下 dvec 在转化后的特征属性是怎样的，即查看 dvec 的 feature_names_ 属性值，方法如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(dvec.feature_names_)</span><br><span class="line">[<span class="string">'Age'</span>, <span class="string">'Embarked=C'</span>, <span class="string">'Embarked=Q'</span>, <span class="string">'Embarked=S'</span>, <span class="string">'Fare'</span>, <span class="string">'Parch'</span>, <span class="string">'Pclass'</span>, <span class="string">'Sex=female'</span>, <span class="string">'Sex=male'</span>, <span class="string">'SibSp'</span>]</span><br></pre></td></tr></table></figure><p><br>你可以看到原本是一列的 Embarked，变成了“Embarked=C”“Embarked=Q”“Embarked=S”三列。Sex 列变成了“Sex=female”“Sex=male”两列。这样 train_features 特征矩阵就包括 10 个特征值（列），以及 891 个样本（行），即 891 行，10 列的特征矩阵。<br><br><br><strong>模块 4：决策树模型</strong><br>刚才我们已经讲了如何使用 sklearn 中的决策树模型。现在我们使用 ID3 算法，即在创建 DecisionTreeClassifier 时，设置 criterion=‘entropy’，然后使用 fit 进行训练，将特征值矩阵和分类标识结果作为参数传入，得到决策树分类器。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="comment"># 构造ID3决策树</span></span><br><span class="line">clf = DecisionTreeClassifier(criterion=<span class="string">'entropy'</span>)</span><br><span class="line"><span class="comment"># 决策树训练</span></span><br><span class="line">clf.fit(train_features, train_labels)</span><br></pre></td></tr></table></figure><p><br><strong>模块 5：模型预测 &amp; 评估</strong><br>在预测中，我们首先需要得到测试集的特征值矩阵，然后使用训练好的决策树 clf 进行预测，得到预测结果 pred_labels：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_features=dvec.transform(test_features.to_dict(orient=<span class="string">'record'</span>))</span><br><span class="line"><span class="comment"># 决策树预测</span></span><br><span class="line">pred_labels = clf.predict(test_features)</span><br></pre></td></tr></table></figure><p><br>在模型评估中，决策树提供了 score 函数可以直接得到准确率，但是我们并不知道真实的预测结果，所以无法用预测值和真实的预测结果做比较。我们只能使用训练集中的数据进行模型评估，可以使用决策树自带的 score 函数计算下得到的结果：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 得到决策树准确率</span></span><br><span class="line">acc_decision_tree = round(clf.score(train_features, train_labels), <span class="number">6</span>)</span><br><span class="line">print(<span class="string">u'score准确率为 %.4lf'</span> % acc_decision_tree)</span><br></pre></td></tr></table></figure><p><br>运行结果：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score准确率为 <span class="number">0.9820</span></span><br></pre></td></tr></table></figure><p><br>你会发现你刚用训练集做训练，再用训练集自身做准确率评估自然会很高。但这样得出的准确率并不能代表决策树分类器的准确率。这是为什么呢？<br><br><br>因为我们没有测试集的实际结果，因此无法用测试集的预测结果与实际结果做对比(<strong>test.csv数据中没有Survived</strong>)。如果我们使用 score 函数对训练集的准确率进行统计，正确率会接近于 100%（如上结果为 98.2%），无法对分类器的在实际环境下做准确率的评估。<br><br><br>那么有什么办法，来统计决策树分类器的准确率呢？这里可以使用 K 折交叉验证的方式，交叉验证是一种常用的验证分类准确率的方法，原理是拿出大部分样本进行训练，少量的用于分类器的验证。<br>K 折交叉验证，就是做 K 次交叉验证，每次选取 K 分之一的数据作为验证，其余作为训练。轮流 K 次，取平均值。<br><strong>K 折交叉验证的原理是这样的：</strong></p><ol><li>将数据集平均分割成 K 个等份；<br></li><li>使用 1 份数据作为测试数据，其余作为训练数据；<br></li><li>计算测试准确率；<br></li><li>使用不同的测试集，重复 2、3 步骤。<br></li></ol><p><br>在 sklearn 的 model_selection 模型选择中提供了 cross_val_score 函数。cross_val_score 函数中的参数 cv 代表对原始数据划分成多少份，也就是我们的 K 值，一般建议 K 值取 10，因此我们可以设置 CV=10，我们可以对比下 score 和 cross_val_score 两种函数的正确率的评估结果：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="comment"># 使用K折交叉验证 统计决策树准确率</span></span><br><span class="line">print(<span class="string">u'cross_val_score准确率为 %.4lf'</span> % np.mean(cross_val_score(clf, train_features, train_labels, cv=<span class="number">10</span>)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cross_val_score准确率为 <span class="number">0.7835</span></span><br></pre></td></tr></table></figure><p><br>你可以看到，score 函数的准确率为 0.9820，cross_val_score 准确率为 0.7835。这里很明显，<strong>对于不知道测试集实际结果的，要使用 K 折交叉验证才能知道模型的准确率。</strong><br><strong>模块 6：决策树可视化</strong><br>sklearn 的决策树模型对我们来说，还是比较抽象的。我们可以使用 Graphviz 可视化工具帮我们把决策树呈现出来。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585397403010-430bb637-799a-49af-af7a-d5a1c9784b03.png#align=left&display=inline&height=598&margin=%5Bobject%20Object%5D&originHeight=598&originWidth=1716&size=0&status=done&style=none&width=1716" alt><br>安装 Graphviz 库需要下面的几步：<br>安装 graphviz 工具，这里是它的下载地址；<a href="http://www.graphviz.org/download/" target="_blank" rel="external nofollow noopener noreferrer">http://www.graphviz.org/download/</a><br>将 Graphviz 添加到环境变量 PATH 中；<br>需要 Graphviz 库，如果没有可以使用 pip install graphviz 进行安装。<br>这样你就可以在程序里面使用 Graphviz 对决策树模型进行呈现，最后得到一个决策树可视化的 PDF 文件，可视化结果文件 Source.gv.pdf 你可以在 GitHub 上下载：<a href="https://github.com/cystanford/Titanic_Data" target="_blank" rel="external nofollow noopener noreferrer">https://github.com/cystanford/Titanic_Data</a><br><strong><br></strong>决策树模型使用技巧总结<strong><br>今天我用泰坦尼克乘客生存预测案例把决策树模型的流程跑了一遍。在实战中，你需要注意一下几点：特征选择是分类模型好坏的关键。选择什么样的特征，以及对应的特征值矩阵，决定了分类模型的好坏。<br></strong><br><strong>通常情况下，特征值不都是数值类型，可以使用 DictVectorizer 类进行转化</strong>；模型准确率需要考虑是否有测试集的实际结果可以做对比，<strong>当测试集没有真实结果可以对比时，需要使用 K 折交叉验证 cross_val_score</strong>；<br>Graphviz 可视化工具可以很方便地将决策模型呈现出来，帮助你更好理解决策树的构建。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585397784656-cb8448e4-2dd0-4d2b-a0dc-182c9759766e.png#align=left&display=inline&height=940&margin=%5Bobject%20Object%5D&name=p6.png&originHeight=940&originWidth=2308&size=395883&status=done&style=none&width=2308" alt="p6.png"><br>我上面讲了泰坦尼克乘客生存预测的六个关键模块，请你用 sklearn 中的决策树模型独立完成这个项目，对测试集中的乘客是否生存进行预测，并给出模型准确率评估。数据从 GitHub 上下载即可。<br>最后给你留一个思考题吧，我在构造特征向量时使用了 DictVectorizer 类，使用 fit_transform 函数将特征向量转化为特征值矩阵。DictVectorizer 类同时也提供 transform 函数，那么这两个函数有什么区别?<br><strong>项目完整代码</strong><br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"></span><br><span class="line">train_data = pd.read_csv(<span class="string">'train.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'test.csv'</span>)</span><br><span class="line"></span><br><span class="line">train_data[<span class="string">'Age'</span>].fillna(train_data[<span class="string">'Age'</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">'Age'</span>].fillna(test_data[<span class="string">'Age'</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">'Fare'</span>].fillna(test_data[<span class="string">'Fare'</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">将空值用此列最多值来补齐</span></span><br><span class="line"><span class="string">index 获取索引值。 [num] 下标获取返回值 ，ascending=True 降序排列</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">train_data[<span class="string">'Embarked'</span>].fillna(train_data[<span class="string">'Embarked'</span>].value_counts().index[<span class="number">0</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">'Embarked'</span>].fillna(test_data[<span class="string">'Embarked'</span>].value_counts().index[<span class="number">0</span>], inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">features = [<span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>, <span class="string">'Embarked'</span>]</span><br><span class="line"></span><br><span class="line">train_features = train_data[features]</span><br><span class="line">train_labels = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line">test_features = test_data[features]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dvec=DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line">train_features=dvec.fit_transform(train_features.to_dict(orient=<span class="string">'record'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造ID3决策树</span></span><br><span class="line">clf = DecisionTreeClassifier(criterion=<span class="string">'entropy'</span>)</span><br><span class="line"><span class="comment"># 决策树训练</span></span><br><span class="line">clf.fit(train_features, train_labels)</span><br><span class="line"></span><br><span class="line">test_features=dvec.transform(test_features.to_dict(orient=<span class="string">'record'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策树预测</span></span><br><span class="line"><span class="comment"># pred_labels = clf.predict(test_features)</span></span><br><span class="line"><span class="comment"># # 得到决策树准确率</span></span><br><span class="line"><span class="comment"># acc_decision_tree = round(clf.score(train_features, train_labels), 6)</span></span><br><span class="line"><span class="comment"># print(u'score准确率为 %.4lf' % acc_decision_tree)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="comment"># 使用K折交叉验证 统计决策树准确率</span></span><br><span class="line">print(<span class="string">u'cross_val_score准确率为 %.4lf'</span> % np.mean(cross_val_score(clf, train_features, train_labels, cv=<span class="number">10</span>)))</span><br></pre></td></tr></table></figure></div><div class="article-footer"><blockquote class="mt-2x"><ul class="post-copyright list-unstyled"><li class="post-copyright-link hidden-xs"><strong>本文链接：</strong> <a href="cpeixin.cn/2018/07/15/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E6%88%98-%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B/" title="数据分析-决策树实战-泰坦尼克号乘客生存预测" target="_blank" rel="external">cpeixin.cn/2018/07/15/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E6%88%98-%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external nofollow noopener noreferrer">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！</li></ul></blockquote><div class="panel panel-default panel-badger"><div class="panel-body"><figure class="media"><div class="media-left"><a href="https://github.com/cpeixin" target="_blank" class="img-burn thumb-sm visible-lg" rel="external nofollow noopener noreferrer"><img src="/images/avatar.jpg" class="img-rounded w-full" alt></a></div><div class="media-body"><h3 class="media-heading"><a href="https://github.com/cpeixin" target="_blank" rel="external nofollow noopener noreferrer"><span class="text-dark">Brent</span><small class="ml-1x">大数据工程师 &amp; 机器学习</small></a></h3><div>一心九用的工程师</div></div></figure></div></div></div></article><section id="comments"><div id="vcomments"></div></section></div><nav class="bar bar-footer clearfix" data-stick-bottom><div class="bar-inner"><ul class="pager pull-left"><li class="prev"><a href="/2018/07/15/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-EM%E8%81%9A%E7%B1%BB/" title="数据分析 - EM聚类"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a></li><li class="next"><a href="/2018/07/14/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%86%B3%E7%AD%96%E6%A0%91%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E6%B5%81%E5%A4%B1%E9%A2%84%E8%AD%A6/" title="数据分析-决策树项目-用户流失预警"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a></li></ul><button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button><div class="bar-right"><div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div></div></div></nav><div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog"><div class="modal-dialog" role="document"><div class="modal-content donate"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button><div class="modal-body"><div class="donate-box"><div class="donate-head"><p>感谢您的支持，我会继续努力的!</p></div><div class="tab-content"><div role="tabpanel" class="tab-pane fade active in" id="alipay"><div class="donate-payimg"><img src="/images/donate/alipayimg.png" alt="扫码支持" title="扫一扫"></div><p class="text-muted mv">扫码打赏，你说多少就多少</p><p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p></div><div role="tabpanel" class="tab-pane fade" id="wechatpay"><div class="donate-payimg"><img src="/images/donate/wechatpayimg.png" alt="扫码支持" title="扫一扫"></div><p class="text-muted mv">扫码打赏，你说多少就多少</p><p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p></div></div><div class="donate-footer"><ul class="nav nav-tabs nav-justified" role="tablist"><li role="presentation" class="active"><a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a></li><li role="presentation"><a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a></li></ul></div></div></div></div></div></div></main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter"><ul class="social-links"><li><a href="https://github.com/cpeixin" target="_blank" title="Github" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-github"></i></a></li><li><a href="https://www.weibo.com/u/1970875963" target="_blank" title="Weibo" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-weibo"></i></a></li><li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-twitter"></i></a></li><li><a href="https://www.behance.net/cofess" target="_blank" title="Behance" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-behance"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul><div class="copyright"><div class="publishby">Theme by <a href="https://github.com/cofess" target="_blank" rel="external nofollow noopener noreferrer">cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank" rel="external nofollow noopener noreferrer">pure</a>.</div></div></footer><script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script><script>window.jQuery||document.write('<script src="js/jquery.min.js"><\/script>')</script><script src="/js/plugin.min.js"></script><script src="/js/application.js"></script><script>!function(T){var N={TRANSLATION:{POSTS:"文章",PAGES:"页面",CATEGORIES:"分类",TAGS:"标签",UNTITLED:"(未命名)"},ROOT_URL:"/",CONTENT_URL:"/content.json"};T.INSIGHT_CONFIG=N}(window)</script><script src="/js/insight.js"></script><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/npm/valine"></script><script type="text/javascript">var GUEST=["nick","mail","link"],meta="nick,mail,link";meta=meta.split(",").filter(function(e){return GUEST.indexOf(e)>-1}),new Valine({el:"#vcomments",verify:!1,notify:!1,appId:"SsxmBzBQ3R2S2zWTv0FrONel-gzGzoHsz",appKey:"w0K528Ye7NhOr07RHrzVzHbW",placeholder:"说点什么呢？",avatar:"mm",meta:meta,pageSize:"10",visitor:!0})</script><script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.3.5/dist/jquery.fancybox.min.js"></script><script>$(document).ready(function(){$("article img").not("[hidden]").not(".panel-body img").each(function(){var a=$(this),t=a.attr("alt"),n=a.parent("a");if(n.length<1){var e=this.getAttribute("src"),r=e.lastIndexOf("?");-1!=r&&(e=e.substring(0,r)),n=a.wrap('<a href="'+e+'"></a>').parent("a")}n.attr("data-fancybox","images"),t&&n.attr("data-caption",t)}),$().fancybox({selector:'[data-fancybox="images"]',hash:!1,loop:!1})})</script></body></html><script type="text/javascript" src="//cdn.jsdelivr.net/gh/ygbhf/clicklove/clicklove.js"></script><!-- rebuild by neat -->