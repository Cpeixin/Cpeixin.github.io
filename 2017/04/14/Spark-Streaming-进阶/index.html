<!-- build time:Mon Sep 07 2020 11:28:41 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta name="renderer" content="webkit"><meta name="referrer" content="no-referrer"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=no,email=no,adress=no"><meta name="theme-color" content="#000000"><meta http-equiv="window-target" content="_top"><title>Spark Streaming 进阶 | 布兰特 | 不忘初心</title><meta name="description" content="初始化要初始化Spark Streaming程序，必须创建StreamingContext对象，该对象是所有Spark Streaming功能的主要入口点。1234val conf: SparkConf &#x3D; new SparkConf()      .setAppName(&quot;your application name&quot;)      .setMaster(&quot;local[2]&quot;)val ssc &#x3D; n"><meta property="og:type" content="article"><meta property="og:title" content="Spark Streaming 进阶"><meta property="og:url" content="cpeixin.cn/2017/04/14/Spark-Streaming-%E8%BF%9B%E9%98%B6/index.html"><meta property="og:site_name" content="布兰特 | 不忘初心"><meta property="og:description" content="初始化要初始化Spark Streaming程序，必须创建StreamingContext对象，该对象是所有Spark Streaming功能的主要入口点。1234val conf: SparkConf &#x3D; new SparkConf()      .setAppName(&quot;your application name&quot;)      .setMaster(&quot;local[2]&quot;)val ssc &#x3D; n"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588609852097-a38e022b-3b30-4c80-82af-8d12d4a46956.png#align=left&display=inline&height=686&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-05-05%20%E4%B8%8A%E5%8D%8812.27.17.png&originHeight=1546&originWidth=1682&size=296766&status=done&style=none&width=746"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1588610651758-1d54c2f4-37ea-4f1e-8bc2-60e8b60fdd1f.jpeg#align=left&display=inline&height=288&margin=%5Bobject%20Object%5D&name=unnamed.jpg&originHeight=288&originWidth=512&size=31660&status=done&style=none&width=512"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588613943907-38f28345-6d32-42d5-89f8-9ca55a5c9d2b.png#align=left&display=inline&height=1234&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-05-05%20%E4%B8%8A%E5%8D%881.32.05.png&originHeight=1234&originWidth=1744&size=353252&status=done&style=none&width=1744"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588614987803-8e53bf9f-3d0b-4379-88cb-f35e3470fb38.png#align=left&display=inline&height=712&margin=%5Bobject%20Object%5D&name=0_zE-5D45Z7yImkO7f.png&originHeight=712&originWidth=940&size=149111&status=done&style=none&width=940"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588695018994-673c3a6d-b239-481a-9cf2-5e5f2a9c2eb2.png#align=left&display=inline&height=388&margin=%5Bobject%20Object%5D&originHeight=388&originWidth=994&size=0&status=done&style=none&width=994"><meta property="og:image" content="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588696141503-b1ea229d-974a-4dc6-bfa6-2cfe6f8753a9.png#align=left&display=inline&height=419&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-05-06%20%E4%B8%8A%E5%8D%8812.23.11.png&originHeight=900&originWidth=1604&size=217631&status=done&style=none&width=746"><meta property="article:published_time" content="2017-04-14T14:22:12.000Z"><meta property="article:modified_time" content="2020-05-05T16:34:55.494Z"><meta property="article:author" content="Brent"><meta property="article:tag" content="spark"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588609852097-a38e022b-3b30-4c80-82af-8d12d4a46956.png#align=left&display=inline&height=686&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-05-05%20%E4%B8%8A%E5%8D%8812.27.17.png&originHeight=1546&originWidth=1682&size=296766&status=done&style=none&width=746"><link rel="canonical" href="cpeixin.cn/2017/04/14/Spark-Streaming-%E8%BF%9B%E9%98%B6/index.html"><link rel="alternate" href="/atom.xml" title="布兰特 | 不忘初心" type="application/atom+xml"><link rel="icon" href="/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.3.5/dist/jquery.fancybox.min.css" rel="stylesheet"><meta name="generator" content="Hexo 4.2.0"></head><body class="main-center" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="slimContent"><div class="navbar-header"><div class="profile-block text-center"><a id="avatar" href="https://github.com/cpeixin" target="_blank" rel="external nofollow noopener noreferrer"><img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200"></a><h2 id="name" class="hidden-xs hidden-sm">Brent</h2><h3 id="title" class="hidden-xs hidden-sm hidden-md">大数据工程师 &amp; 机器学习</h3><small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Malaysia</small></div><div class="search" id="search-form-wrap"><form class="search-form sidebar-form"><div class="input-group"><input type="text" class="search-form-input form-control" placeholder="搜索"> <span class="input-group-btn"><button type="submit" class="search-form-submit btn btn-flat" onclick="return!1"><i class="icon icon-search"></i></button></span></div></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech> <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div></div><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button></div><nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation"><ul class="nav navbar-nav main-nav"><li class="menu-item menu-item-home"><a href="/."><i class="icon icon-home-fill"></i> <span class="menu-title">首页</span></a></li><li class="menu-item menu-item-archives"><a href="/archives"><i class="icon icon-archives-fill"></i> <span class="menu-title">归档</span></a></li><li class="menu-item menu-item-categories"><a href="/categories"><i class="icon icon-folder"></i> <span class="menu-title">分类</span></a></li><li class="menu-item menu-item-tags"><a href="/tags"><i class="icon icon-tags"></i> <span class="menu-title">标签</span></a></li><li class="menu-item menu-item-repository"><a href="/repository"><i class="icon icon-project"></i> <span class="menu-title">项目</span></a></li><li class="menu-item menu-item-books"><a href="/books"><i class="icon icon-book-fill"></i> <span class="menu-title">书单</span></a></li><li class="menu-item menu-item-links"><a href="/links"><i class="icon icon-friendship"></i> <span class="menu-title">友链</span></a></li><li class="menu-item menu-item-about"><a href="/about"><i class="icon icon-cup-fill"></i> <span class="menu-title">关于</span></a></li></ul><ul class="social-links"><li><a href="https://github.com/cpeixin" target="_blank" title="Github" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-github"></i></a></li><li><a href="https://www.weibo.com/u/1970875963" target="_blank" title="Weibo" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-weibo"></i></a></li><li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-twitter"></i></a></li><li><a href="https://www.behance.net/cofess" target="_blank" title="Behance" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-behance"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul></nav></div></header><aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><div class="widget"><h3 class="widget-title">公告</h3><div class="widget-body"><div id="board"><div class="content"><p>人处在一种默默奋斗的状态，精神就会从琐碎生活中得到升华</p></div></div></div></div><div class="widget"><h3 class="widget-title">分类</h3><div class="widget-body"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBases/">DataBases</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tools/">Tools</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><span class="category-list-count">95</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7/">工具</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/">开发工具</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">31</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9E%B6%E6%9E%84/">架构</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a><span class="category-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">标签</h3><div class="widget-body"><ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Apriori/" rel="tag">Apriori</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Decision-Tree/" rel="tag">Decision Tree</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EM/" rel="tag">EM</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ETL/" rel="tag">ETL</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Flink/" rel="tag">Flink</a><span class="tag-list-count">29</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPT-2/" rel="tag">GPT-2</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HBase/" rel="tag">HBase</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HashMap/" rel="tag">HashMap</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IDEA/" rel="tag">IDEA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/K-Means/" rel="tag">K-Means</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KNN/" rel="tag">KNN</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LRU%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95/" rel="tag">LRU淘汰算法</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Naive-Bayes/" rel="tag">Naive Bayes</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OLAP/" rel="tag">OLAP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PageRank/" rel="tag">PageRank</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Parquet/" rel="tag">Parquet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Random-Forest/" rel="tag">Random Forest</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flask/" rel="tag">flask</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flink/" rel="tag">flink</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hdfs/" rel="tag">hdfs</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hive/" rel="tag">hive</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/" rel="tag">kafka</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kali/" rel="tag">kali</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mapreduce/" rel="tag">mapreduce</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/" rel="tag">mysql</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paxos/" rel="tag">paxos</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/" rel="tag">redis</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala/" rel="tag">scala</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shadowsock/" rel="tag">shadowsock</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/skipList/" rel="tag">skipList</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sklearn/" rel="tag">sklearn</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/" rel="tag">spark</a><span class="tag-list-count">26</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/yarn/" rel="tag">yarn</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" rel="tag">二分查找</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" rel="tag">二叉树</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" rel="tag">动态规划</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/" rel="tag">单例模式</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E6%BA%AF/" rel="tag">回溯</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A0%86/" rel="tag">堆</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/" rel="tag">布隆过滤器</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8E%92%E5%BA%8F/" rel="tag">排序</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%A3%E5%88%97%E8%A1%A8/" rel="tag">散列表</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" rel="tag">数据仓库</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/" rel="tag">数据清洗</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" rel="tag">数据采集</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E7%BB%84/" rel="tag">数组</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/" rel="tag">时间序列</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8/" rel="tag">服务器安全</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A0%88/" rel="tag">栈</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="tag">特征工程</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/" rel="tag">用户画像</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/" rel="tag">红黑树</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E8%A1%A8/" rel="tag">线性表</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AF%8D%E5%90%91%E9%87%8F/" rel="tag">词向量</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%92%E5%BD%92/" rel="tag">递归</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" rel="tag">逻辑回归</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E8%A1%A8/" rel="tag">链表</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%98%9F%E5%88%97/" rel="tag">队列</a><span class="tag-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">标签云</h3><div class="widget-body tagcloud"><a href="/tags/Apriori/" style="font-size:13.13px">Apriori</a> <a href="/tags/Decision-Tree/" style="font-size:13.5px">Decision Tree</a> <a href="/tags/EM/" style="font-size:13.13px">EM</a> <a href="/tags/ETL/" style="font-size:13px">ETL</a> <a href="/tags/Flink/" style="font-size:14px">Flink</a> <a href="/tags/GPT-2/" style="font-size:13px">GPT-2</a> <a href="/tags/HBase/" style="font-size:13.13px">HBase</a> <a href="/tags/HashMap/" style="font-size:13px">HashMap</a> <a href="/tags/IDEA/" style="font-size:13px">IDEA</a> <a href="/tags/K-Means/" style="font-size:13px">K-Means</a> <a href="/tags/KNN/" style="font-size:13.13px">KNN</a> <a href="/tags/LRU%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95/" style="font-size:13px">LRU淘汰算法</a> <a href="/tags/Naive-Bayes/" style="font-size:13.13px">Naive Bayes</a> <a href="/tags/OLAP/" style="font-size:13px">OLAP</a> <a href="/tags/PageRank/" style="font-size:13.13px">PageRank</a> <a href="/tags/Parquet/" style="font-size:13px">Parquet</a> <a href="/tags/Random-Forest/" style="font-size:13px">Random Forest</a> <a href="/tags/SVM/" style="font-size:13.13px">SVM</a> <a href="/tags/docker/" style="font-size:13.13px">docker</a> <a href="/tags/flask/" style="font-size:13.13px">flask</a> <a href="/tags/flink/" style="font-size:13px">flink</a> <a href="/tags/hdfs/" style="font-size:13.38px">hdfs</a> <a href="/tags/hive/" style="font-size:13.38px">hive</a> <a href="/tags/kafka/" style="font-size:13.63px">kafka</a> <a href="/tags/kali/" style="font-size:13px">kali</a> <a href="/tags/mapreduce/" style="font-size:13px">mapreduce</a> <a href="/tags/mysql/" style="font-size:13.25px">mysql</a> <a href="/tags/paxos/" style="font-size:13.13px">paxos</a> <a href="/tags/python/" style="font-size:13.63px">python</a> <a href="/tags/redis/" style="font-size:13.38px">redis</a> <a href="/tags/scala/" style="font-size:13.38px">scala</a> <a href="/tags/shadowsock/" style="font-size:13px">shadowsock</a> <a href="/tags/skipList/" style="font-size:13px">skipList</a> <a href="/tags/sklearn/" style="font-size:13px">sklearn</a> <a href="/tags/spark/" style="font-size:13.88px">spark</a> <a href="/tags/yarn/" style="font-size:13px">yarn</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" style="font-size:13.13px">二分查找</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size:13.25px">二叉树</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size:13px">动态规划</a> <a href="/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/" style="font-size:13px">单例模式</a> <a href="/tags/%E5%9B%9E%E6%BA%AF/" style="font-size:13px">回溯</a> <a href="/tags/%E5%A0%86/" style="font-size:13px">堆</a> <a href="/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/" style="font-size:13px">布隆过滤器</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size:13.75px">排序</a> <a href="/tags/%E6%95%A3%E5%88%97%E8%A1%A8/" style="font-size:13px">散列表</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" style="font-size:13.75px">数据仓库</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/" style="font-size:13px">数据清洗</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" style="font-size:13px">数据采集</a> <a href="/tags/%E6%95%B0%E7%BB%84/" style="font-size:13px">数组</a> <a href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/" style="font-size:13px">时间序列</a> <a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8/" style="font-size:13.13px">服务器安全</a> <a href="/tags/%E6%A0%88/" style="font-size:13px">栈</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size:13px">深度学习</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size:13px">爬虫</a> <a href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" style="font-size:13.38px">特征工程</a> <a href="/tags/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/" style="font-size:13.13px">用户画像</a> <a href="/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/" style="font-size:13px">红黑树</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E8%A1%A8/" style="font-size:13px">线性表</a> <a href="/tags/%E8%AF%8D%E5%90%91%E9%87%8F/" style="font-size:13px">词向量</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size:13px">递归</a> <a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" style="font-size:13px">逻辑回归</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size:13.13px">链表</a> <a href="/tags/%E9%98%9F%E5%88%97/" style="font-size:13px">队列</a></div></div><div class="widget"><h3 class="widget-title">归档</h3><div class="widget-body"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a><span class="archive-list-count">16</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">九月 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a><span class="archive-list-count">22</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">五月 2017</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">一月 2017</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">14</span></li></ul></div></div><div class="widget"><h3 class="widget-title">最新文章</h3><div class="widget-body"><ul class="recent-post-list list-unstyled no-thumbnail"><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></p><p class="item-title"><a href="/2020/08/30/Redis%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AF%B9%E5%BA%94%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" class="title">Redis常用数据类型对应的数据结构</a></p><p class="item-date"><time datetime="2020-08-30T06:47:56.000Z" itemprop="datePublished">2020-08-30</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a></p><p class="item-title"><a href="/2020/08/30/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95-Paxos%EF%BC%882%EF%BC%89/" class="title">分布式一致性算法 - Paxos（2）</a></p><p class="item-date"><time datetime="2020-08-30T05:10:05.000Z" itemprop="datePublished">2020-08-30</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a></p><p class="item-title"><a href="/2020/08/29/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95-Paxos%EF%BC%881%EF%BC%89/" class="title">分布式一致性算法 - Paxos（1）</a></p><p class="item-date"><time datetime="2020-08-28T16:54:44.000Z" itemprop="datePublished">2020-08-29</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></p><p class="item-title"><a href="/2020/08/01/Redis%E4%B8%BA%E4%BB%80%E4%B9%88%E9%AB%98%E6%95%88/" class="title">Redis为什么高效</a></p><p class="item-date"><time datetime="2020-08-01T08:08:08.000Z" itemprop="datePublished">2020-08-01</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></p><p class="item-title"><a href="/2020/07/21/HBase-RowKey%E8%AE%BE%E8%AE%A1/" class="title">HBase RowKey设计</a></p><p class="item-date"><time datetime="2020-07-21T01:42:33.000Z" itemprop="datePublished">2020-07-21</time></p></div></li></ul></div></div></div></aside><main class="main" role="main"><div class="content"><article id="post-Spark-Streaming-进阶" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting"><div class="article-header"><h1 class="article-title" itemprop="name">Spark Streaming 进阶</h1><div class="article-meta"><span class="article-date"><i class="icon icon-calendar-check"></i> <a href="/2017/04/14/Spark-Streaming-%E8%BF%9B%E9%98%B6/" class="article-date"><time datetime="2017-04-14T14:22:12.000Z" itemprop="datePublished">2017-04-14</time></a></span> <span class="article-category"><i class="icon icon-folder"></i> <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span> <span class="article-tag"><i class="icon icon-tags"></i> <a class="article-tag-link" href="/tags/spark/" rel="tag">spark</a></span> <span class="article-read hidden-xs"><i class="icon icon-eye-fill" aria-hidden="true"></i> <span id="/2017/04/14/Spark-Streaming-%E8%BF%9B%E9%98%B6/" class="leancloud_visitors" data-flag-title="Spark Streaming 进阶">0</span></span> <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2017/04/14/Spark-Streaming-%E8%BF%9B%E9%98%B6/#comments" class="article-comment-link">评论</a></span> <span class="post-wordcount hidden-xs" itemprop="wordCount">字数统计: 4.1k(字)</span> <span class="post-readcount hidden-xs" itemprop="timeRequired">阅读时长: 18(分)</span></div></div><div class="article-entry marked-body" itemprop="articleBody"><p><a name="ExtFo"></a></p><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>要初始化Spark Streaming程序，必须创建<strong>StreamingContext</strong>对象，该对象是所有Spark Streaming功能的主要入口点。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">      .setAppName(<span class="string">"your application name"</span>)</span><br><span class="line">      .setMaster(<span class="string">"local[2]"</span>)</span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br></pre></td></tr></table></figure><p>maven依赖：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spark-streaming_2<span class="number">.11</span>&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p><br>该appName参数是您的应用程序在集群UI上显示的名称。 master是<a href="https://spark.apache.org/docs/latest/submitting-applications.html#master-urls" target="_blank" rel="external nofollow noopener noreferrer">Spark，Mesos，Kubernetes或YARN群集URL</a>或特殊的“ local [<em>]”字符串，以本地模式运行。实际工作中，程序部署、运行在集群上，所以并不希望master在程序中进行硬编码，而是在提交<a href="https://spark.apache.org/docs/latest/submitting-applications.html" target="_blank" rel="external nofollow noopener noreferrer">程序的spark-submit</a> –master *</em> 命令中来指定。如果只是本地IDEA运行，则可指定 local。<br><br><br>在初始化的代码中，我们要设置每个批处理的时间间隔，上面代码中 Seconds(5)，也就是5秒划分一个批次。我们打开源码，可以看到，StreamingContext（）第二个参数还有其他选择，最终都是将时间转换成毫秒。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588609852097-a38e022b-3b30-4c80-82af-8d12d4a46956.png#align=left&display=inline&height=686&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-05-05%20%E4%B8%8A%E5%8D%8812.27.17.png&originHeight=1546&originWidth=1682&size=296766&status=done&style=none&width=746" alt="屏幕快照 2020-05-05 上午12.27.17.png"><br>**<br><a name="PLMNT"></a></p><h3 id="Dstream"><a href="#Dstream" class="headerlink" title="Dstream"></a>Dstream</h3><p><a name="CWAn0"></a></p><h3><a href="#" class="headerlink"></a><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1588610651758-1d54c2f4-37ea-4f1e-8bc2-60e8b60fdd1f.jpeg#align=left&display=inline&height=288&margin=%5Bobject%20Object%5D&name=unnamed.jpg&originHeight=288&originWidth=512&size=31660&status=done&style=none&width=512" alt="unnamed.jpg"></h3><p><br>DStream由一系列连续的RDD表示，这是Spark对不可变的分布式数据集的抽象。DStream中的每个RDD都包含来自特定间隔的数据。<br><br><br>这里，我们来看一下下面的代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.<span class="type">ConsumerRecord</span></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.<span class="type">StringDeserializer</span></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">InputDStream</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">KafkaUtils</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">streaming_case</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 设置日志级别</span></span><br><span class="line">  <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">ERROR</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">      .setAppName(<span class="string">"Kafka Streaming"</span>)</span><br><span class="line">      .setMaster(<span class="string">"local[2]"</span>)</span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">10</span>))</span><br><span class="line">    ssc.checkpoint(<span class="string">"/Users/cpeixin/IdeaProjects/code_warehouse/spark_streaming/src/main/scala/streaming/"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>] = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>](</span><br><span class="line">      <span class="string">"bootstrap.servers"</span> -&gt; <span class="string">"localhost:9092"</span>,</span><br><span class="line">      <span class="string">"key.deserializer"</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">      <span class="string">"value.deserializer"</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">      <span class="string">"group.id"</span> -&gt; <span class="string">"kafka_spark_streaming"</span>,</span><br><span class="line">      <span class="string">"auto.offset.reset"</span> -&gt; <span class="string">"earliest"</span>, <span class="comment">// earliest</span></span><br><span class="line">      <span class="string">"enable.auto.commit"</span> -&gt; (<span class="literal">false</span>: java.lang.<span class="type">Boolean</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> topics = <span class="type">Array</span>(<span class="string">"weibo_keyword"</span>)</span><br><span class="line">    <span class="keyword">val</span> kafkaStream: <span class="type">InputDStream</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = <span class="type">KafkaUtils</span></span><br><span class="line">      .createDirectStream[<span class="type">String</span>, <span class="type">String</span>](ssc, <span class="type">PreferConsistent</span>, <span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](topics, kafkaParams))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    kafkaStream.foreachRDD((x: <span class="type">RDD</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]]) =&gt;println(x))</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">change_data</span></span>(string_data: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> json_data: <span class="type">JSONObject</span> = <span class="type">JSON</span>.parseObject(string_data)</span><br><span class="line">    <span class="keyword">val</span> date_time: <span class="type">String</span> = json_data.get(<span class="string">"datetime"</span>).toString</span><br><span class="line">    <span class="keyword">val</span> keywordList: <span class="type">String</span> = json_data.get(<span class="string">"keywordList"</span>).toString</span><br><span class="line">    keywordList</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KafkaRDD[0] at createDirectStream at streaming_case.scala:39</span><br></pre></td></tr></table></figure><p>上面的代码，在42行foreachRDD的中，我们打印DStream中的RDD，结果中我们看到，第一个批次中，只有一个RDD，这里我想说的是，在上面的这种读取数据代码中，一个 batch Interval中，DStream 只有一个RDD，当一个新的时间窗口（batchInterval)开始时，此时产生一个空的block，此后在这个窗口内接受到的数据都会累加到这个block上，当这个时间窗口结束时，停止累加，这个block对应的数据就是这个时间窗口对应的RDD包含的数据</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588613943907-38f28345-6d32-42d5-89f8-9ca55a5c9d2b.png#align=left&display=inline&height=1234&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-05-05%20%E4%B8%8A%E5%8D%881.32.05.png&originHeight=1234&originWidth=1744&size=353252&status=done&style=none&width=1744" alt="屏幕快照 2020-05-05 上午1.32.05.png"><br>这里我们还可以深入 slideDuration：Duration来看，和后面要讲的窗口函数windiw（）中，RDD的区别。</p><p><a name="OrnMC"></a></p><h3 id="batch-interval"><a href="#batch-interval" class="headerlink" title="batch interval"></a>batch interval</h3><p><br>关于Spark Streaming的批处理时间设置是非常重要的，Spark Streaming在不断接收数据的同时，需要处理数据的时间，所以如果设置过段的批处理时间，会造成数据堆积，即未完成的batch数据越来越多，从而发生阻塞。<br>另外值得注意的是，batchDuration本身也不能设置为小于500ms，这会导致Spark Streaming进行频繁地提交作业，造成额外的开销，减少整个系统的吞吐量；相反如果将batchDuration时间设置得过长，又会影响整个系统的吞吐量。<br><br><br>如何设置一个合理的批处理时间，需要根据应用本身、集群资源情况，以及关注和监控Spark Streaming系统的运行情况来调整，重点关注Spark Web UI监控界面中的Total Delay，来进行调整。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588614987803-8e53bf9f-3d0b-4379-88cb-f35e3470fb38.png#align=left&display=inline&height=712&margin=%5Bobject%20Object%5D&name=0_zE-5D45Z7yImkO7f.png&originHeight=712&originWidth=940&size=149111&status=done&style=none&width=940" alt="0_zE-5D45Z7yImkO7f.png"><br><a name="WU4vH"></a></p><h3 id="CheckPoint"><a href="#CheckPoint" class="headerlink" title="CheckPoint"></a>CheckPoint</h3><p><br>我们所编写的实时计算程序大多数都是24小时全天候生产环境运行的，因此必须对与应用程序逻辑无关的故障（例如，系统故障，JVM崩溃等）具有弹性。为此，Spark Streaming需要将足够的信息检查点指向容错存储系统，以便可以从故障中恢复。检查点有两种类型的数据。</p><ul><li>元数据检查点-将定义流计算的信息保存到HDFS等容错存储中。这用于从运行流应用程序的驱动程序的节点的故障中恢复。元数据包括：<ul><li>配置 用于创建流应用程序的配置。</li><li>DStream操作 -定义流应用程序的DStream操作集。</li><li>不完整的批次 -作业排队但尚未完成的批次。</li></ul></li><li>数据检查点 将生成的RDD保存到可靠的存储中。在一些有状态转换中，这需要跨多个批次合并数据，这是必需的。在此类转换中，生成的RDD依赖于先前批次的RDD，这导致依赖项链的长度随时间不断增加。为了避免恢复时间的这种无限制的增加（与依赖关系链成比例），有状态转换的中间RDD定期 检查点到可靠的存储（例如HDFS）以切断依赖关系链。</li></ul><p><br>总而言之，metadata checkpointing主要还是从drvier失败中恢复，而Data Checkpoing用于对有状态的transformation操作进行checkpointing</p><p>Checkpoint和persist从根本上是不一样的：<br>1、Cache or persist:<br>Cache or persist保存了RDD的血统关系，假如有部分cache的数据丢失可以根据血缘关系重新生成。<br>2、Checkpoint<br>会将RDD数据写到hdfs这种安全的文件系统里面，并且抛弃了RDD血缘关系的记录。即使persist存储到了磁盘里面，在driver停掉之后会被删除，而checkpoint可以被下次启动使用。<br><br><br><strong>何时启用检查点</strong><br>必须为具有以下任一要求的应用程序启用检查点：</p><ul><li><em>有状态转换的用法</em> -如果在应用程序中使用<code>updateStateByKey</code>或<code>reduceByKeyAndWindow</code>（带有反函数），则必须提供检查点目录以允许定期进行RDD检查点。</li><li><em>从运行应用程序的驱动程序故障中恢复</em> -元数据检查点用于恢复进度信息。</li></ul><p>注意，没有前述状态转换的简单流应用程序可以在不启用检查点的情况下运行。在这种情况下，从驱动程序故障中恢复也将是部分的（某些已接收但未处理的数据可能会丢失）。这通常是可以接受的，并且许多都以这种方式运行Spark Streaming应用程序。预计将来会改善对非Hadoop环境的支持。<br><strong><br></strong>如何配置检查点**<br>可以通过在容错，可靠的文件系统（例如，HDFS，S3等）中设置目录来启用检查点，将检查点信息保存到该目录中。这是通过使用完成的<code>streamingContext.checkpoint(checkpointDirectory)</code>。这将允许您使用前面提到的有状态转换。此外，如果要使应用程序从驱动程序故障中恢复，则应重写流应用程序以具有以下行为。</p><ul><li>程序首次启动时，它将创建一个新的StreamingContext，设置所有流，然后调用start（）。</li><li>失败后重新启动程序时，它将根据检查点目录中的检查点数据重新创建StreamingContext。</li></ul><p><br>代码如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">functionToCreateContext</span></span>(): <span class="type">StreamingContext</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(...)   <span class="comment">// new context</span></span><br><span class="line">  <span class="keyword">val</span> lines = ssc.socketTextStream(...) <span class="comment">// create DStreams</span></span><br><span class="line">  ...</span><br><span class="line">  ssc.checkpoint(checkpointDirectory)   <span class="comment">// set checkpoint directory</span></span><br><span class="line">  ssc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Get StreamingContext from checkpoint data or create a new one</span></span><br><span class="line"><span class="keyword">val</span> context = <span class="type">StreamingContext</span>.getOrCreate(checkpointDirectory, functionToCreateContext _)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Do additional setup on context that needs to be done,</span></span><br><span class="line"><span class="comment">// irrespective of whether it is being started or restarted</span></span><br><span class="line">context. ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// Start the context</span></span><br><span class="line">context.start()</span><br><span class="line">context.awaitTermination()</span><br></pre></td></tr></table></figure><p>请注意，RDD的检查点会导致保存到可靠存储的成本。这可能会导致RDD获得检查点的那些批次的处理时间增加。因此，需要仔细设置检查点的间隔。在小批量（例如1秒）时，每批检查点可能会大大降低操作吞吐量。相反，检查点太不频繁会导致沿袭和任务规模增加，这可能会产生不利影响。对于需要RDD检查点的有状态转换，默认间隔为批处理间隔的倍数，至少应为10秒。可以使用设置 dstream.checkpoint(checkpointInterval)。通常，DStream的5-10个滑动间隔的检查点间隔是一个很好的尝试设置。<br><br><br><strong>checkpoint时机</strong><br>在spark Streaming中，JobGenerator用于生成每个batch对应的jobs，它有一个定时器，定时器 的周期即初始化StreamingContext时设置batchDuration。这个周期一到，JobGenerator将调用generateJobs方法来生成并提交jobs，这之后调用doCheckpoint方法来进行checkpoint。doCheckpoint方法中，会判断 当前时间与streaming application start的时间只差是否是 checkpoint duration的倍数，只有在是的情况下才进行checkpoint。<br><br><br>具体应用实例：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">package</span> org.apache.spark.examples.streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.<span class="type">File</span></span><br><span class="line"><span class="keyword">import</span> java.nio.charset.<span class="type">Charset</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.google.common.io.<span class="type">Files</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.broadcast.<span class="type">Broadcast</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>, <span class="type">Time</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.util.&#123;<span class="type">IntParam</span>, <span class="type">LongAccumulator</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Use this singleton to get or register a Broadcast variable.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordBlacklist</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> instance: <span class="type">Broadcast</span>[<span class="type">Seq</span>[<span class="type">String</span>]] = <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getInstance</span></span>(sc: <span class="type">SparkContext</span>): <span class="type">Broadcast</span>[<span class="type">Seq</span>[<span class="type">String</span>]] = &#123;</span><br><span class="line">    <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">      synchronized &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="keyword">val</span> wordBlacklist = <span class="type">Seq</span>(<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>)</span><br><span class="line">          instance = sc.broadcast(wordBlacklist)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    instance</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Use this singleton to get or register an Accumulator.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DroppedWordsCounter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> instance: <span class="type">LongAccumulator</span> = <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getInstance</span></span>(sc: <span class="type">SparkContext</span>): <span class="type">LongAccumulator</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">      synchronized &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">          instance = sc.longAccumulator(<span class="string">"WordsInBlacklistCounter"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    instance</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">RecoverableNetworkWordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createContext</span></span>(ip: <span class="type">String</span>, port: <span class="type">Int</span>, outputPath: <span class="type">String</span>, checkpointDirectory: <span class="type">String</span>)</span><br><span class="line">    : <span class="type">StreamingContext</span> = &#123;</span><br><span class="line">    <span class="comment">// If you do not see this printed, that means the StreamingContext has been loaded</span></span><br><span class="line">    <span class="comment">// from the new checkpoint</span></span><br><span class="line">    println(<span class="string">"Creating new context"</span>)</span><br><span class="line">    <span class="keyword">val</span> outputFile = <span class="keyword">new</span> <span class="type">File</span>(outputPath)</span><br><span class="line">    <span class="keyword">if</span> (outputFile.exists()) outputFile.delete()</span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"RecoverableNetworkWordCount"</span>)</span><br><span class="line">    <span class="comment">// Create the context with a 1 second batch size</span></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">1</span>))</span><br><span class="line">    ssc.checkpoint(checkpointDirectory)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create a socket stream on target ip:port and count the</span></span><br><span class="line">    <span class="comment">// words in input stream of \n delimited text (eg. generated by 'nc')</span></span><br><span class="line">    <span class="keyword">val</span> lines = ssc.socketTextStream(ip, port)</span><br><span class="line">    <span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">    <span class="keyword">val</span> wordCounts = words.map((_, <span class="number">1</span>)).reduceByKey(_ + _)</span><br><span class="line">    wordCounts.foreachRDD &#123; (rdd: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)], time: <span class="type">Time</span>) =&gt;</span><br><span class="line">      <span class="comment">// Get or register the blacklist Broadcast</span></span><br><span class="line">      <span class="keyword">val</span> blacklist = <span class="type">WordBlacklist</span>.getInstance(rdd.sparkContext)</span><br><span class="line">      <span class="comment">// Get or register the droppedWordsCounter Accumulator</span></span><br><span class="line">      <span class="keyword">val</span> droppedWordsCounter = <span class="type">DroppedWordsCounter</span>.getInstance(rdd.sparkContext)</span><br><span class="line">      <span class="comment">// Use blacklist to drop words and use droppedWordsCounter to count them</span></span><br><span class="line">      <span class="keyword">val</span> counts = rdd.filter &#123; <span class="keyword">case</span> (word, count) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (blacklist.value.contains(word)) &#123;</span><br><span class="line">          droppedWordsCounter.add(count)</span><br><span class="line">          <span class="literal">false</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;.collect().mkString(<span class="string">"["</span>, <span class="string">", "</span>, <span class="string">"]"</span>)</span><br><span class="line">      <span class="keyword">val</span> output = <span class="string">s"Counts at time <span class="subst">$time</span> <span class="subst">$counts</span>"</span></span><br><span class="line">      println(output)</span><br><span class="line">      println(<span class="string">s"Dropped <span class="subst">$&#123;droppedWordsCounter.value&#125;</span> word(s) totally"</span>)</span><br><span class="line">      println(<span class="string">s"Appending to <span class="subst">$&#123;outputFile.getAbsolutePath&#125;</span>"</span>)</span><br><span class="line">      <span class="type">Files</span>.append(output + <span class="string">"\n"</span>, outputFile, <span class="type">Charset</span>.defaultCharset())</span><br><span class="line">    &#125;</span><br><span class="line">    ssc</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (args.length != <span class="number">4</span>) &#123;</span><br><span class="line">      <span class="type">System</span>.err.println(<span class="string">s"Your arguments were <span class="subst">$&#123;args.mkString("[", ", ", "]")&#125;</span>"</span>)</span><br><span class="line">      <span class="type">System</span>.err.println(</span><br><span class="line">        <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">          |Usage: RecoverableNetworkWordCount &lt;hostname&gt; &lt;port&gt; &lt;checkpoint-directory&gt;</span></span><br><span class="line"><span class="string">          |     &lt;output-file&gt;. &lt;hostname&gt; and &lt;port&gt; describe the TCP server that Spark</span></span><br><span class="line"><span class="string">          |     Streaming would connect to receive data. &lt;checkpoint-directory&gt; directory to</span></span><br><span class="line"><span class="string">          |     HDFS-compatible file system which checkpoint data &lt;output-file&gt; file to which the</span></span><br><span class="line"><span class="string">          |     word counts will be appended</span></span><br><span class="line"><span class="string">          |</span></span><br><span class="line"><span class="string">          |In local mode, &lt;master&gt; should be 'local[n]' with n &gt; 1</span></span><br><span class="line"><span class="string">          |Both &lt;checkpoint-directory&gt; and &lt;output-file&gt; must be absolute paths</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span>.stripMargin</span><br><span class="line">      )</span><br><span class="line">      <span class="type">System</span>.exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(ip, <span class="type">IntParam</span>(port), checkpointDirectory, outputPath) = args</span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="type">StreamingContext</span>.getOrCreate(checkpointDirectory,</span><br><span class="line">      () =&gt; createContext(ip, port, outputPath, checkpointDirectory))</span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a name="YocCX"></a></p><h3 id="-1"><a href="#-1" class="headerlink"></a></h3><p><a name="6zf89"></a></p><h3 id="UpdateStateByKey"><a href="#UpdateStateByKey" class="headerlink" title="UpdateStateByKey"></a>UpdateStateByKey</h3><p>流处理主要有3种应用场景：无状态操作、window操作、状态操作。updateStateByKey就是典型的状态操作。</p><p>下面是针对updateStateByKey举的实例，主要功能是针对流数据中的关键词进行统计，并且是根据历史状态持续统计。<br></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.<span class="type">ConsumerRecord</span></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.<span class="type">StringDeserializer</span></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">InputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">KafkaUtils</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">streaming_updatastatebykey</span> </span>&#123;</span><br><span class="line">  <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">ERROR</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">      .setAppName(<span class="string">"Kafka Streaming"</span>)</span><br><span class="line">      .setMaster(<span class="string">"local[2]"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">2</span>))</span><br><span class="line">    ssc.checkpoint(<span class="string">"/Users/cpeixin/IdeaProjects/code_warehouse/spark_streaming/src/main/scala/streaming/"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>] = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>](</span><br><span class="line">      <span class="string">"bootstrap.servers"</span> -&gt; <span class="string">"localhost:9092"</span>,</span><br><span class="line">      <span class="string">"key.deserializer"</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">      <span class="string">"value.deserializer"</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">      <span class="string">"group.id"</span> -&gt; <span class="string">"kafka_spark_streaming"</span>,</span><br><span class="line">      <span class="string">"auto.offset.reset"</span> -&gt; <span class="string">"latest"</span>, <span class="comment">// earliest</span></span><br><span class="line">      <span class="string">"enable.auto.commit"</span> -&gt; (<span class="literal">false</span>: java.lang.<span class="type">Boolean</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> topics = <span class="type">Array</span>(<span class="string">"weibo_keyword"</span>)</span><br><span class="line">    <span class="keyword">val</span> kafkaStream: <span class="type">InputDStream</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = <span class="type">KafkaUtils</span></span><br><span class="line">      .createDirectStream[<span class="type">String</span>, <span class="type">String</span>](ssc, <span class="type">PreferConsistent</span>, <span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](topics, kafkaParams))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordcount_dstream: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = kafkaStream</span><br><span class="line">      .map((x: <span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]) =&gt; &#123;</span><br><span class="line">        change_data(x.value())</span><br><span class="line">      &#125;)</span><br><span class="line">      .flatMap((_: <span class="type">String</span>).split(<span class="string">","</span>))</span><br><span class="line">      .map((x: <span class="type">String</span>) =&gt; (x, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sum_dstream: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordcount_dstream.updateStateByKey((seq: <span class="type">Seq</span>[<span class="type">Int</span>], state: <span class="type">Option</span>[<span class="type">Int</span>]) =&gt; &#123;</span><br><span class="line">      <span class="keyword">var</span> sum: <span class="type">Int</span> = state.getOrElse(<span class="number">0</span>)+seq.sum</span><br><span class="line">      <span class="type">Option</span>(sum)</span><br><span class="line">    &#125;)</span><br><span class="line">    </span><br><span class="line">    sum_dstream.foreachRDD((keywordFormat_rdd: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)]) =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> sort_rdd: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = keywordFormat_rdd.map((x: (<span class="type">String</span>, <span class="type">Int</span>)) =&gt; &#123;(x._2, x._1)&#125;).sortByKey().top(<span class="number">10</span>)</span><br><span class="line">      sort_rdd.foreach(println)</span><br><span class="line">      println(<span class="string">"===================="</span>)</span><br><span class="line">    &#125;)</span><br><span class="line">    </span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">change_data</span></span>(string_data: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> json_data: <span class="type">JSONObject</span> = <span class="type">JSON</span>.parseObject(string_data)</span><br><span class="line">    <span class="keyword">val</span> date_time: <span class="type">String</span> = json_data.get(<span class="string">"datetime"</span>).toString</span><br><span class="line">    <span class="keyword">val</span> keywordList: <span class="type">String</span> = json_data.get(<span class="string">"keywordList"</span>).toString</span><br><span class="line">    keywordList</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>打印统计信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">(8,剪头)</span><br><span class="line">(5,黑人抬棺队长称将环游世界)</span><br><span class="line">(5,黑人)</span><br><span class="line">(5,队长)</span><br><span class="line">(5,环游世界)</span><br><span class="line">(4,野餐)</span><br><span class="line">(4,这野餐也太实在了吧)</span><br><span class="line">(3,郑钧低空飞行)</span><br><span class="line">(3,郑钧)</span><br><span class="line">(3,森林)</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">(8,剪头)</span><br><span class="line">(7,森林)</span><br><span class="line">(7,挪威)</span><br><span class="line">(7,伍佰 挪威的森林)</span><br><span class="line">(7,伍佰)</span><br><span class="line">(6,肤色)</span><br><span class="line">(6,状态)</span><br><span class="line">(6,今年夏天的肤色状态)</span><br><span class="line">(6,今年夏天)</span><br><span class="line">(5,黑人抬棺队长称将环游世界)</span><br></pre></td></tr></table></figure><p>注意：类似updateStateByKey和mapWithState等有状态转换算子，程序中必须要指定checkpoint检查点。<br><a name="6RtNM"></a></p><h3 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h3><p>Spark Streaming还提供了_窗口计算_，可让您在数据的滑动窗口上应用转换。下图说明了此滑动窗口。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588695018994-673c3a6d-b239-481a-9cf2-5e5f2a9c2eb2.png#align=left&display=inline&height=388&margin=%5Bobject%20Object%5D&originHeight=388&originWidth=994&size=0&status=done&style=none&width=994" alt><br>如该图所示，每当窗口_滑动_在源DSTREAM，落入窗口内的源RDDS被组合及操作以产生RDDS的窗DSTREAM。在这种特定情况下，该操作将应用于数据的最后3个时间单位，并以2个时间单位滑动。这表明任何窗口操作都需要指定两个参数。</p><ul><li><em>窗口长度</em> - _窗口_的持续时间。</li><li><em>滑动间隔</em> -进行窗口操作的间隔。</li></ul><p>这两个参数必须是源DStream的批处理间隔的倍数<br><br><br>下面给出实例代码，描述的场景是每10秒统计一次过去30秒期间，关键词出现次数的top 5<br></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> streaming</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.<span class="type">ConsumerRecord</span></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.<span class="type">StringDeserializer</span></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;<span class="type">DStream</span>, <span class="type">InputDStream</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">KafkaUtils</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Duration</span>, <span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">streaming_window</span> </span>&#123;</span><br><span class="line">  <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">ERROR</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">      .setAppName(<span class="string">"spark streaming window"</span>)</span><br><span class="line">      .setMaster(<span class="string">"local[2]"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>] = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>](</span><br><span class="line">      <span class="string">"bootstrap.servers"</span> -&gt; <span class="string">"localhost:9092"</span>,</span><br><span class="line">      <span class="string">"key.deserializer"</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">      <span class="string">"value.deserializer"</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">      <span class="string">"group.id"</span> -&gt; <span class="string">"kafka_spark_streaming"</span>,</span><br><span class="line">      <span class="string">"auto.offset.reset"</span> -&gt; <span class="string">"latest"</span>, <span class="comment">// earliest</span></span><br><span class="line">      <span class="string">"enable.auto.commit"</span> -&gt; (<span class="literal">false</span>: java.lang.<span class="type">Boolean</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> topics = <span class="type">Array</span>(<span class="string">"weibo_keyword"</span>)</span><br><span class="line">    <span class="keyword">val</span> kafkaStream: <span class="type">InputDStream</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = <span class="type">KafkaUtils</span></span><br><span class="line">      .createDirectStream[<span class="type">String</span>, <span class="type">String</span>](sc, <span class="type">PreferConsistent</span>, <span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](topics, kafkaParams))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordcount_dstream: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = kafkaStream</span><br><span class="line">      .map((x: <span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]) =&gt; &#123;</span><br><span class="line">        get_data(x.value())</span><br><span class="line">      &#125;)</span><br><span class="line">      .flatMap((_: <span class="type">String</span>).split(<span class="string">","</span>))</span><br><span class="line">      .map((x: <span class="type">String</span>) =&gt; (x, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> window_dstream: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordcount_dstream.reduceByKeyAndWindow((x: <span class="type">Int</span>,y: <span class="type">Int</span>)=&gt;x+y,<span class="type">Seconds</span>(<span class="number">30</span>), <span class="type">Seconds</span>(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> result: <span class="type">DStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = window_dstream.transform((rdd: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)]) =&gt;&#123;</span><br><span class="line">      <span class="keyword">val</span> top3: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = rdd.map((x: (<span class="type">String</span>, <span class="type">Int</span>)) =&gt;(x._2,x._1)).sortByKey(ascending = <span class="literal">false</span>).map((x: (<span class="type">Int</span>, <span class="type">String</span>)) =&gt;(x._2,x._1)).take(<span class="number">5</span>)</span><br><span class="line">      sc.sparkContext.makeRDD(top3)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    result.print()</span><br><span class="line"></span><br><span class="line">    sc.start()</span><br><span class="line">    sc.awaitTermination()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_data</span></span>(string_data: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> json_data: <span class="type">JSONObject</span> = <span class="type">JSON</span>.parseObject(string_data)</span><br><span class="line">    <span class="keyword">val</span> date_time: <span class="type">String</span> = json_data.get(<span class="string">"datetime"</span>).toString</span><br><span class="line">    <span class="keyword">val</span> keywordList: <span class="type">String</span> = json_data.get(<span class="string">"keywordList"</span>).toString</span><br><span class="line">    keywordList</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">-------------------------------------------</span><br><span class="line">Time: 1588694330000 ms</span><br><span class="line">-------------------------------------------</span><br><span class="line">(台版,6)</span><br><span class="line">(黑人,6)</span><br><span class="line">(台版101模仿黑人抬棺,6)</span><br><span class="line">(训练,2)</span><br><span class="line">(听起来很厉害的专业术语,2)</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 1588694340000 ms</span><br><span class="line">-------------------------------------------</span><br><span class="line">(野餐,10)</span><br><span class="line">(野餐还没拍好照就被牛吃了,10)</span><br><span class="line">(台版,6)</span><br><span class="line">(黑人,6)</span><br><span class="line">(台版101模仿黑人抬棺,6)</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 1588694350000 ms</span><br><span class="line">-------------------------------------------</span><br><span class="line">(姐姐,10)</span><br><span class="line">(野餐,10)</span><br><span class="line">(野餐还没拍好照就被牛吃了,10)</span><br><span class="line">(乘风破浪的姐姐们,10)</span><br><span class="line">(台版,6)</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 1588694360000 ms</span><br><span class="line">-------------------------------------------</span><br><span class="line">(姐姐,10)</span><br><span class="line">(野餐,10)</span><br><span class="line">(野餐还没拍好照就被牛吃了,10)</span><br><span class="line">(乘风破浪的姐姐们,10)</span><br><span class="line">(叶冲太难了,9)</span><br></pre></td></tr></table></figure><p><br>transform操作，应用在DStream上时，可以用于执行任意的RDD到RDD的转换操作；<br>它可以用于实现，DStream API中所没有提供的操作；比如说，DStream API中，并没有提供将一个DStream中的每个batch，与一个特定的RDD进行join的操作。但是我们自己就可以使用transform操作来实现该功能。<br><br><br>这里看 reduceByKeyAndWindow（）函数的第二个参数和第三个参数，分别代表的意义就是，窗口的长度和窗口滑动间隔。<br><br><br>这里还需要知道一点，Dstream中的RDD也可以调用persist()方法保存在内存当中，但是基于window和state的操作，reduceByWindow,reduceByKeyAndWindow,updateStateByKey等它们已经在源码中默认persist了<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1588696141503-b1ea229d-974a-4dc6-bfa6-2cfe6f8753a9.png#align=left&display=inline&height=419&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-05-06%20%E4%B8%8A%E5%8D%8812.23.11.png&originHeight=900&originWidth=1604&size=217631&status=done&style=none&width=746" alt="屏幕快照 2020-05-06 上午12.23.11.png"><br></p><p><a name="aHC0q"></a></p><h3 id="-2"><a href="#-2" class="headerlink"></a></h3><p>**</p></div><div class="article-footer"><blockquote class="mt-2x"><ul class="post-copyright list-unstyled"><li class="post-copyright-link hidden-xs"><strong>本文链接：</strong> <a href="cpeixin.cn/2017/04/14/Spark-Streaming-%E8%BF%9B%E9%98%B6/" title="Spark Streaming 进阶" target="_blank" rel="external">cpeixin.cn/2017/04/14/Spark-Streaming-%E8%BF%9B%E9%98%B6/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external nofollow noopener noreferrer">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！</li></ul></blockquote><div class="panel panel-default panel-badger"><div class="panel-body"><figure class="media"><div class="media-left"><a href="https://github.com/cpeixin" target="_blank" class="img-burn thumb-sm visible-lg" rel="external nofollow noopener noreferrer"><img src="/images/avatar.jpg" class="img-rounded w-full" alt></a></div><div class="media-body"><h3 class="media-heading"><a href="https://github.com/cpeixin" target="_blank" rel="external nofollow noopener noreferrer"><span class="text-dark">Brent</span><small class="ml-1x">大数据工程师 &amp; 机器学习</small></a></h3><div>一心九用的工程师</div></div></figure></div></div></div></article><section id="comments"><div id="vcomments"></div></section></div><nav class="bar bar-footer clearfix" data-stick-bottom><div class="bar-inner"><ul class="pager pull-left"><li class="prev"><a href="/2017/04/22/Spark-Streaming-ELK-HBase/" title="Spark Streaming + ELK + HBase"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a></li><li class="next"><a href="/2017/04/10/Spark-Streaming-%E8%AE%B2%E8%A7%A3/" title="Spark Streaming 讲解"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a></li></ul><button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button><div class="bar-right"><div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div></div></div></nav><div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog"><div class="modal-dialog" role="document"><div class="modal-content donate"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button><div class="modal-body"><div class="donate-box"><div class="donate-head"><p>感谢您的支持，我会继续努力的!</p></div><div class="tab-content"><div role="tabpanel" class="tab-pane fade active in" id="alipay"><div class="donate-payimg"><img src="/images/donate/alipayimg.png" alt="扫码支持" title="扫一扫"></div><p class="text-muted mv">扫码打赏，你说多少就多少</p><p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p></div><div role="tabpanel" class="tab-pane fade" id="wechatpay"><div class="donate-payimg"><img src="/images/donate/wechatpayimg.png" alt="扫码支持" title="扫一扫"></div><p class="text-muted mv">扫码打赏，你说多少就多少</p><p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p></div></div><div class="donate-footer"><ul class="nav nav-tabs nav-justified" role="tablist"><li role="presentation" class="active"><a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a></li><li role="presentation"><a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a></li></ul></div></div></div></div></div></div></main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter"><ul class="social-links"><li><a href="https://github.com/cpeixin" target="_blank" title="Github" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-github"></i></a></li><li><a href="https://www.weibo.com/u/1970875963" target="_blank" title="Weibo" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-weibo"></i></a></li><li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-twitter"></i></a></li><li><a href="https://www.behance.net/cofess" target="_blank" title="Behance" data-toggle="tooltip" data-placement="top" rel="external nofollow noopener noreferrer"><i class="icon icon-behance"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul><div class="copyright"><div class="publishby">Theme by <a href="https://github.com/cofess" target="_blank" rel="external nofollow noopener noreferrer">cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank" rel="external nofollow noopener noreferrer">pure</a>.</div></div></footer><script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script><script>window.jQuery||document.write('<script src="js/jquery.min.js"><\/script>')</script><script src="/js/plugin.min.js"></script><script src="/js/application.js"></script><script>!function(T){var N={TRANSLATION:{POSTS:"文章",PAGES:"页面",CATEGORIES:"分类",TAGS:"标签",UNTITLED:"(未命名)"},ROOT_URL:"/",CONTENT_URL:"/content.json"};T.INSIGHT_CONFIG=N}(window)</script><script src="/js/insight.js"></script><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/npm/valine"></script><script type="text/javascript">var GUEST=["nick","mail","link"],meta="nick,mail,link";meta=meta.split(",").filter(function(e){return GUEST.indexOf(e)>-1}),new Valine({el:"#vcomments",verify:!1,notify:!1,appId:"SsxmBzBQ3R2S2zWTv0FrONel-gzGzoHsz",appKey:"w0K528Ye7NhOr07RHrzVzHbW",placeholder:"说点什么呢？",avatar:"mm",meta:meta,pageSize:"10",visitor:!0})</script><script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.3.5/dist/jquery.fancybox.min.js"></script><script>$(document).ready(function(){$("article img").not("[hidden]").not(".panel-body img").each(function(){var a=$(this),t=a.attr("alt"),n=a.parent("a");if(n.length<1){var e=this.getAttribute("src"),r=e.lastIndexOf("?");-1!=r&&(e=e.substring(0,r)),n=a.wrap('<a href="'+e+'"></a>').parent("a")}n.attr("data-fancybox","images"),t&&n.attr("data-caption",t)}),$().fancybox({selector:'[data-fancybox="images"]',hash:!1,loop:!1})})</script></body></html><script type="text/javascript" src="//cdn.jsdelivr.net/gh/ygbhf/clicklove/clicklove.js"></script><!-- rebuild by neat -->