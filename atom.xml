<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>布兰特 | 不忘初心</title>
  
  <subtitle>人处在一种默默奋斗的状态，精神就会从琐碎生活中得到升华</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="cpeixin.cn/"/>
  <updated>2020-04-04T17:13:00.080Z</updated>
  <id>cpeixin.cn/</id>
  
  <author>
    <name>Brent</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>python Flask &amp; Ajax 数据传输</title>
    <link href="cpeixin.cn/2020/03/11/python-Flask-Ajax-%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/"/>
    <id>cpeixin.cn/2020/03/11/python-Flask-Ajax-%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/</id>
    <published>2020-03-11T14:43:01.000Z</published>
    <updated>2020-04-04T17:13:00.080Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>帮朋友写个小工具，没想到还要搞定JS，大学毕业后就没有写过JS，真的是难为我了😂</p><p>忙活三个小时，终于把前端和后端打通了～～</p><p>前端demo：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Title<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"http://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 发送数据，表单方式 （注意：后端接收数据对应代码不同）--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"&#123;&#123; url_for('send_message') &#125;&#125;"</span> <span class="attr">method</span>=<span class="string">"post"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">textarea</span> <span class="attr">name</span> =<span class="string">"domain"</span> <span class="attr">rows</span>=<span class="string">"30"</span> <span class="attr">cols</span>=<span class="string">"100"</span> <span class="attr">placeholder</span>=<span class="string">"请输入需要查询的域名,如cq5999.com"</span>&gt;</span><span class="tag">&lt;/<span class="name">textarea</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&lt;input id="submit" type="submit" value="发送"&gt;--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">id</span>=<span class="string">"btn-bq"</span> <span class="attr">data-toggle</span>=<span class="string">"modal"</span> <span class="attr">data-target</span>=<span class="string">"#myModal"</span>&gt;</span>查询<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 发送数据，input方式 （注意：后端接收数据对应代码不同） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"send_content"</span>&gt;</span>向后台发送消息：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"send_content"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"send_content"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"send"</span> <span class="attr">type</span>=<span class="string">"button"</span> <span class="attr">value</span>=<span class="string">"发送"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"recv_content"</span>&gt;</span>从后台接收消息：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"recv_content"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"recv_content"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- input方式 对应的js代码，如用表单方式请注释掉 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 发送 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span></span><br><span class="line"><span class="javascript">    $(<span class="string">"#send"</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> message = $(<span class="string">"#send_content"</span>).val()</span></span><br><span class="line">        alert(message)</span><br><span class="line"><span class="javascript">        $.ajax(&#123;</span></span><br><span class="line"><span class="actionscript">            url:<span class="string">"/send_message"</span>,</span></span><br><span class="line"><span class="actionscript">            type:<span class="string">"POST"</span>,</span></span><br><span class="line">            data:&#123;</span><br><span class="line">                message:message</span><br><span class="line">            &#125;,</span><br><span class="line"><span class="actionscript">            dataType: <span class="string">'json'</span>,</span></span><br><span class="line"><span class="actionscript">            success:<span class="function"><span class="keyword">function</span> <span class="params">(data)</span> </span>&#123;</span></span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 接收 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span></span><br><span class="line"><span class="javascript">    $(<span class="string">"#send"</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">        $.getJSON(<span class="string">"/change_to_json"</span>,<span class="function"><span class="keyword">function</span> (<span class="params">data</span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">            $(<span class="string">"#recv_content"</span>).val(data.message) <span class="comment">//将后端数据显示在前端</span></span></span><br><span class="line"><span class="javascript">            <span class="built_in">console</span>.log(<span class="string">"传到前端的数据的类型："</span> + <span class="keyword">typeof</span> (data.message))</span></span><br><span class="line"><span class="javascript">            $(<span class="string">"#send_content"</span>).val(<span class="string">""</span>)<span class="comment">//发送的输入框清空</span></span></span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>后端demo:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, render_template, request, jsonify</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">"index_v6.html"</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/send_message', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send_message</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> message_get</span><br><span class="line">    message_get = <span class="string">""</span></span><br><span class="line"></span><br><span class="line">    message_get = request.form[<span class="string">"domain"</span>].split(<span class="string">'\n'</span>)</span><br><span class="line">    <span class="comment"># message_get = request.form['message'] #input提交</span></span><br><span class="line">    print(<span class="string">"收到前端发过来的信息：%s"</span> % message_get)</span><br><span class="line">    print(<span class="string">"收到数据的类型为："</span> + str(type(message_get)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"收到消息"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/change_to_json', methods=['GET'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_to_json</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">global</span> message_get</span><br><span class="line">    message_json = &#123;</span><br><span class="line">        <span class="string">"message"</span>: message_get</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jsonify(message_json)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app.run(host=<span class="string">'0.0.0.0'</span>, port=<span class="number">80</span>,debug=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;帮朋友写个小工具，没想到还要搞定JS，大学毕业后就没有写过JS，真的是难为我了😂&lt;/p&gt;&lt;p&gt;忙活三个小时，终于把前端和后端打通了～～&lt;/p&gt;
      
    
    </summary>
    
    
      <category term="python" scheme="cpeixin.cn/categories/python/"/>
    
    
      <category term="flask" scheme="cpeixin.cn/tags/flask/"/>
    
  </entry>
  
  <entry>
    <title>Python Flask接口设计-示例</title>
    <link href="cpeixin.cn/2020/03/10/Python-Flask%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1-%E7%A4%BA%E4%BE%8B/"/>
    <id>cpeixin.cn/2020/03/10/Python-Flask%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1-%E7%A4%BA%E4%BE%8B/</id>
    <published>2020-03-10T15:08:35.000Z</published>
    <updated>2020-04-04T17:12:52.356Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p><a name="LHF1q"></a></p><h3 id="Get-请求"><a href="#Get-请求" class="headerlink" title="Get 请求"></a>Get 请求</h3><p><strong><strong>开发一个只接受get方法的接口，接受参数为name和age，并返回相应内容。</strong></strong><br><strong><br>**</strong>方法 1:****</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> redirect</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> jsonify</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route("/test_1.0", methods=["GET"])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="comment"># 默认返回内容</span></span><br><span class="line">  return_dict = &#123;<span class="string">'return_code'</span>: <span class="string">'200'</span>, <span class="string">'return_info'</span>: <span class="string">'处理成功'</span>, <span class="string">'result'</span>: <span class="literal">False</span>&#125;</span><br><span class="line">  <span class="comment"># 判断入参是否为空</span></span><br><span class="line">  <span class="keyword">if</span> request.args <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    return_dict[<span class="string">'return_code'</span>] = <span class="string">'5004'</span></span><br><span class="line">    return_dict[<span class="string">'return_info'</span>] = <span class="string">'请求参数为空'</span></span><br><span class="line">    <span class="keyword">return</span> json.dumps(return_dict, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">  <span class="comment"># 获取传入的params参数</span></span><br><span class="line">  get_data = request.args.to_dict()</span><br><span class="line">  name = get_data.get(<span class="string">'name'</span>)</span><br><span class="line">  age = get_data.get(<span class="string">'age'</span>)</span><br><span class="line">  <span class="comment"># 对参数进行操作</span></span><br><span class="line">  return_dict[<span class="string">'result'</span>] = tt(name, age)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> json.dumps(return_dict, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 功能函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tt</span><span class="params">(name, age)</span>:</span></span><br><span class="line">  result_str = <span class="string">"%s今年%s岁"</span> % (name, age)</span><br><span class="line">  <span class="keyword">return</span> result_str</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  app.run(host=<span class="string">'0.0.0.0'</span>, port=<span class="number">80</span>)</span><br></pre></td></tr></table></figure><p>此种方式对应的request请求方式：</p><ol><li>拼接请求链接, 直接请求：<a href="http://0.0.0.0/test_1.0?name=ccc&age=18" target="_blank" rel="external nofollow noopener noreferrer">http://0.0.0.0/test_1.0?name=ccc&amp;age=18</a></li><li>request 请求中带有参数，如下图</li></ol><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583826674613-bc99538a-988e-4386-b8e6-9eb9fce1862f.png#align=left&display=inline&height=610&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%883.47.43.png&originHeight=610&originWidth=1424&size=98593&status=done&style=none&width=1424" alt="屏幕快照 2020-03-10 下午3.47.43.png"></p><p>方法 2:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@app.route('/api/banWordSingle/&lt;string:word&gt;', methods=['GET'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">banWordSingleStart</span><span class="params">(word)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> getWordStatus(word)</span><br></pre></td></tr></table></figure><p>此方法 与 方法 1 中的拼接链接相似，但是不用输入关键字</p><p>请求链接：<a href="http://0.0.0.0/test_1.0?name=ccc&age=18" target="_blank" rel="external nofollow noopener noreferrer">http://0.0.0.0</a>/api/banWordSingle/输入词</p><p><a name="vJdOc"></a></p><h3 id="Post-请求"><a href="#Post-请求" class="headerlink" title="Post 请求"></a>Post 请求</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> redirect</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> jsonify</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route("/test_1.0", methods=["POST"])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="comment"># 默认返回内容</span></span><br><span class="line">  return_dict = &#123;<span class="string">'return_code'</span>: <span class="string">'200'</span>, <span class="string">'return_info'</span>: <span class="string">'处理成功'</span>, <span class="string">'result'</span>: <span class="literal">False</span>&#125;</span><br><span class="line">  <span class="comment"># 判断入参是否为空</span></span><br><span class="line">  <span class="keyword">if</span> request.args <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    return_dict[<span class="string">'return_code'</span>] = <span class="string">'5004'</span></span><br><span class="line">    return_dict[<span class="string">'return_info'</span>] = <span class="string">'请求参数为空'</span></span><br><span class="line">    <span class="keyword">return</span> json.dumps(return_dict, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">  <span class="comment"># 获取传入的params参数</span></span><br><span class="line">  get_data = request.args.to_dict()</span><br><span class="line">  name = get_data.get(<span class="string">'name'</span>)</span><br><span class="line">  age = get_data.get(<span class="string">'age'</span>)</span><br><span class="line">  <span class="comment"># 对参数进行操作</span></span><br><span class="line">  return_dict[<span class="string">'result'</span>] = tt(name, age)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> json.dumps(return_dict, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 功能函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tt</span><span class="params">(name, age)</span>:</span></span><br><span class="line">  result_str = <span class="string">"%s今年%s岁"</span> % (name, age)</span><br><span class="line">  <span class="keyword">return</span> result_str</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  app.run(host=<span class="string">'0.0.0.0'</span>, port=<span class="number">8080</span>)</span><br></pre></td></tr></table></figure><p>请求方式：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583831085097-3a858ae4-259d-408d-a162-6a4ed8c5e291.png#align=left&display=inline&height=692&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%885.00.28.png&originHeight=692&originWidth=1438&size=99272&status=done&style=none&width=1438" alt="屏幕快照 2020-03-10 下午5.00.28.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;LHF1q&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h3 id=&quot;Get-请求&quot;&gt;&lt;a href=&quot;#Get-请求&quot; class=&quot;headerl
      
    
    </summary>
    
    
      <category term="python" scheme="cpeixin.cn/categories/python/"/>
    
    
      <category term="flask" scheme="cpeixin.cn/tags/flask/"/>
    
  </entry>
  
  <entry>
    <title>IDEA install TabNine</title>
    <link href="cpeixin.cn/2020/01/22/IDEA-install-TabNine/"/>
    <id>cpeixin.cn/2020/01/22/IDEA-install-TabNine/</id>
    <published>2020-01-22T02:26:15.000Z</published>
    <updated>2020-04-04T11:06:48.223Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>TabNine是我目前遇到过最好的智能补全工具</p><p>TabNine基于GPT-2的插件</p><p>安装<br>IDEA编译器，找到plugins</p><p>Windows pycharm：File&gt;settings&gt;plugins;<br>Mac pycharm：performence&gt;plugins&gt;marketplace or plugins&gt;Install JetBrains Plugins</p><p>查找 TabNine, 点击 install, 随后 restart</p><p>重启后：Help&gt;Edit Custom Properties…&gt;Create;</p><p>在跳出来的idea.properties中输入（注：英文字符） TabNine::config</p><p>随即会自动弹出TabNine激活页面；</p><p>激活<br>点击Activation Key下面的here；</p><p>输入你的邮箱号；</p><p>复制粘贴邮件里面的API Key到Activation Key下面；（得到的 key 可以在各种编译器中共用）</p><p>等待自动安装，观察页面（最下面有log可以看当前进度）；</p><p>激活完成后TabNine Cloud为Enabled状态，你也可以在安装进度完成后刷新页面手动选择Enabled；</p><p>确认激活完成，重启pycharm即可；</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;TabNine是我目前遇到过最好的智能补全工具&lt;/p&gt;&lt;p&gt;TabNine基于GPT-2的插件&lt;/p&gt;&lt;p&gt;安装&lt;br&gt;IDEA编译器，找到pl
      
    
    </summary>
    
    
      <category term="开发工具" scheme="cpeixin.cn/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="IDEA" scheme="cpeixin.cn/tags/IDEA/"/>
    
  </entry>
  
  <entry>
    <title>GPT-2 Chinese 自动生成文章 - 环境准备</title>
    <link href="cpeixin.cn/2020/01/01/GPT-2-Chinese-%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E6%96%87%E7%AB%A0-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"/>
    <id>cpeixin.cn/2020/01/01/GPT-2-Chinese-%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E6%96%87%E7%AB%A0-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</id>
    <published>2020-01-01T14:28:43.000Z</published>
    <updated>2020-04-05T14:30:42.875Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p><a name="R14AA"></a></p><h2 id="Google-Colab"><a href="#Google-Colab" class="headerlink" title="Google Colab"></a>Google Colab</h2><p>Colaboratory 是一个 Google 研究项目，旨在帮助传播机器学习培训和研究成果。它是一个 Jupyter 笔记本环境，不需要进行任何设置就可以使用，并且完全在云端运行。<br>Colaboratory 笔记本存储在 Google 云端硬盘中，并且可以共享，就如同您使用 Google 文档或表格一样。Colaboratory 可免费使用。<br>利用Colaboratory ，可以方便的使用Keras,TensorFlow,PyTorch等框架进行深度学习应用的开发。</p><p>缺点是最多只能运行12小时，时间一到就会清空VM上所有数据。这包括我们安装的软件，包括我们下载的数据，存放的计算结果， 所以最好不要直接在colab上进行文件的修改，以防保存不及时而造成丢失</p><p><strong>免费！ 免费！免费！</strong><br>**<br><a name="dpofS"></a></p><h3 id="谷歌云盘"><a href="#谷歌云盘" class="headerlink" title="谷歌云盘"></a>谷歌云盘</h3><p>当登录账号进入<a href="https://drive.google.com/drive/my-drive" target="_blank" rel="external nofollow noopener noreferrer">谷歌云盘</a>时，系统会给予15G免费空间大小。由于Colab需要依靠谷歌云盘，故需要在云盘上新建一个文件夹，来存放你的代码或者数据。</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583723531238-28bbbd81-69e8-472d-b048-1ac67166a201.png#align=left&display=inline&height=612&name=image.png&originHeight=612&originWidth=1268&size=104029&status=done&style=none&width=1268" alt="image.png"></p><p><a name="EHdj9"></a></p><h3 id="引入Colab"><a href="#引入Colab" class="headerlink" title="引入Colab"></a>引入Colab</h3><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583723706098-527d9fff-e46e-4dd1-b92a-0640b0d61555.png#align=left&display=inline&height=674&name=image.png&originHeight=674&originWidth=1125&size=104056&status=done&style=none&width=1125" alt="image.png"></p><p><a name="kykCO"></a></p><h3 id="设置GPU环境"><a href="#设置GPU环境" class="headerlink" title="设置GPU环境"></a>设置GPU环境</h3><p>打开colab后，我们要设置运行环境。”修改”—&gt;”笔记本设置”</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583723911273-f07371f9-e982-44b2-af34-b3781f294879.png#align=left&display=inline&height=739&name=image.png&originHeight=739&originWidth=1191&size=94677&status=done&style=none&width=1191" alt="image.png"></p><p><a name="f4U2h"></a></p><h3 id="挂载和切换工作目录"><a href="#挂载和切换工作目录" class="headerlink" title="挂载和切换工作目录"></a>挂载和切换工作目录</h3><p>from google.colab import drive<br>drive.mount(‘/content/drive’)<br>import os<br>os.chdir(‘/content/drive/My Drive/code/GPT2-Chinese’)</p><p>其中： My Drive 代表你的google网盘根目录</p><pre><code>code/GPT2-Chinese 代表网盘中你的程序文件目录</code></pre><p><a name="MyewB"></a></p><h3 id="在Colab中运行任务"><a href="#在Colab中运行任务" class="headerlink" title="在Colab中运行任务"></a>在Colab中运行任务</h3><p>下图是我google drive中的文件结构， 在项目文件中，创建一个.ipynb文件，来执行你的所有操作。</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583724861033-5a15ce65-bdfa-4a01-bc58-b821c026353a.png#align=left&display=inline&height=758&name=image.png&originHeight=758&originWidth=1832&size=234841&status=done&style=none&width=1832" alt="image.png"></p><p><a name="GZDbL"></a></p><h3 id="ipynb文件内容"><a href="#ipynb文件内容" class="headerlink" title=".ipynb文件内容"></a>.ipynb文件内容</h3><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583725009190-fa5ecec2-f7d1-4b4f-b3ed-da7655dad2f9.png#align=left&display=inline&height=586&name=image.png&originHeight=586&originWidth=1636&size=54530&status=done&style=none&width=1636" alt="image.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;R14AA&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 id=&quot;Google-Colab&quot;&gt;&lt;a href=&quot;#Google-Colab&quot; cl
      
    
    </summary>
    
    
      <category term="NLP" scheme="cpeixin.cn/categories/NLP/"/>
    
    
      <category term="GPT-2" scheme="cpeixin.cn/tags/GPT-2/"/>
    
  </entry>
  
  <entry>
    <title>架构思想</title>
    <link href="cpeixin.cn/2019/12/20/%E6%9E%B6%E6%9E%84%E6%80%9D%E6%83%B3/"/>
    <id>cpeixin.cn/2019/12/20/%E6%9E%B6%E6%9E%84%E6%80%9D%E6%83%B3/</id>
    <published>2019-12-20T02:26:15.000Z</published>
    <updated>2020-04-04T11:23:45.206Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p><a name="-2"></a></p><h2><a href="#" class="headerlink"></a></h2><p>关于什么是架构，一种比较通俗的说法是 “最高层次的规划，难以改变的决定”，这些规划和决定奠定了事物未来发展的方向和最终的蓝图。<br><br><br>从这个意义上说，人生规划也是一种架构。选什么学校、学什么专业、进什么公司、找什么对象，过什么样的生活，都是自己人生的架构。<br><br><br>具体到软件架构，维基百科是这样定义的：“有关软件整体结构与组件的抽象描述，用于指导大型软件系统各个方面的设计”。系统的各个重要组成部分及其关系构成了系统的架构，这些组成部分可以是具体的功能模块，也可以是非功能的设计与决策，他们相互关系组成一个整体，共同构成了软件系统的架构。<br><br><br>架构其实就是把复杂的问题抽象化、简单化，可能你会觉得“说起来容易但做起来难”，如何能快速上手。可以多观察，根据物质决定意识，借助生活真实场景（用户故事，要很多故事）来还原这一系列问题，抓住并提取核心特征。<br><a name="-3"></a></p><h4 id="架构思想"><a href="#架构思想" class="headerlink" title="架构思想"></a>架构思想</h4><p>CPU运算速度&gt;&gt;&gt;&gt;&gt;内存的读写速度&gt;&gt;&gt;&gt;磁盘读写速度</p><ul><li><p>满足业务发展需求是最高准则</p></li><li><p>业务建模，抽象和枚举是两种方式，需要平衡，不能走极端</p></li><li><p>模型要能更真实的反应事物的本质，不是名词概念的堆砌，不能过度设计</p></li><li><p>基础架构最关键的是分离不同业务领域、不同技术领域，让整个系统具有持续优化的能力。</p></li><li><p>分离基础服务、业务规则、业务流程，选择合适的工具外化业务规则和业务流程</p></li><li><p>分离业务组件和技术组件，高类聚，低耦合 - 业务信息的执行可以分散，但业务信息的管理要尽量集中</p></li><li><p>不要让软件的逻辑架构与最后物理部署绑死 - 选择合适的技术而不是高深的技术，随着业务的发展调整使用的技术</p></li><li><p>好的系统架构需要合适的组织架构去保障 - 团队成员思想的转变，漫长而艰难</p></li><li><p>业务架构、系统架构、数据模型<br><a name="-4"></a></p><h4 id="面对一块新业务，如何系统架构？"><a href="#面对一块新业务，如何系统架构？" class="headerlink" title="面对一块新业务，如何系统架构？"></a>面对一块新业务，如何系统架构？</h4></li><li><p>业务分析：输出业务架构图，这个系统里有多少个业务模块，从前台用户到底层一共有多少层。</p></li><li><p>系统划分：根据业务架构图输出系统架构图，需要思考的是这块业务划分成多少个系统，可能一个系统能支持多个业务。基于什么原则将一个系统拆分成多个系统？又基于什么原则将两个系统合并成一个系统？</p></li><li><p>系统分层：系统是几层架构，基于什么原则将一个系统进行分层，分成多少层？</p></li><li><p>模块化：系统里有多少个模块，哪些需要模块化？基于什么原则将一类代码变成一个模块。<br><a name="-5"></a></p><h4 id="如何模块化"><a href="#如何模块化" class="headerlink" title="如何模块化"></a>如何模块化</h4></li><li><p>基于水平切分。把一个系统按照业务类型进行水平切分成多个模块，比如权限管理模块，用户管理模块，各种业务模块等。</p></li><li><p>基于垂直切分。把一个系统按照系统层次进行垂直切分成多个模块，如DAO层，SERVICE层，业务逻辑层。</p></li><li><p>基于单一职责。将代码按照职责抽象出来形成一个一个的模块。将系统中同一职责的代码放在一个模块里。比如我们开发的系统要对接多个渠道的数据，每个渠道的对接方式和数据解析方式不一样，为避免不同渠道代码的相互影响，我们把各个渠道的代码放在各自的模块里。</p></li><li><p>基于易变和不易变。将不易变的代码抽象到一个模块里，比如系统的比较通用的功能。将易变的代码放在另外一个或多个模块里，比如业务逻辑。因为易变的代码经常修改，会很不稳定，分开之后易变代码在修改时候，不会将BUG传染给不变的代码。<br><a name="-6"></a></p><h4 id="提升系统的稳定性"><a href="#提升系统的稳定性" class="headerlink" title="提升系统的稳定性"></a>提升系统的稳定性</h4></li><li><p>流控</p></li></ul><p>双11期间，对于一些重要的接口（比如帐号的查询接口，店铺首页）做流量控制，超过阈值直接返回失败。<br>另外对于一些不重要的业务也可以考虑采用降级方案，大促—&gt;邮件系统。根据28原则，提前将大卖家约1W左右在缓存中预热，并设置起止时间，活动期间内这部分大卖家不发交易邮件提醒，以减轻SA邮件服务器的压力。</p><ul><li>容灾</li></ul><p>最大程度保证主链路的可用性，比如我负责交易的下单，而下单过程中有优惠的业务逻辑，此时需要考虑UMP系统挂掉，不会影响用户下单（后面可以通过修改价格弥补），采用的方式是，如果优惠挂掉，重新渲染页面，并增加ump屏蔽标记，下单时会自动屏蔽ump的代码逻辑。<br>另外还会记录ump系统不可用次数，一定时间内超过阈值，系统会自动报警。</p><ul><li>稳定性</li></ul><p>第三方系统可能会不稳定，存在接口超时或宕机，为了增加系统的健壮性，调用接口时设置超时时间以及异常捕获处理。</p><ul><li>容量规划</li></ul><p>做好容量规划、系统间强弱依赖关系梳理。<br>如：冷热数据不同处理，早期的订单采用oracle存储，随着订单的数量越来越多，查询缓慢，考虑数据迁移，引入历史表，将已归档的记录迁移到历史表中。当然最好的方法是分库分表。<br><a name="-7"></a></p><h4 id="分布式架构"><a href="#分布式架构" class="headerlink" title="分布式架构"></a>分布式架构</h4><ul><li><p>分布式系统</p></li><li><p>分布式缓存</p></li><li><p>分布式数据<br><a name="api"></a></p><h4 id="API-和乐高积木有什么相似之处？"><a href="#API-和乐高积木有什么相似之处？" class="headerlink" title="API 和乐高积木有什么相似之处？"></a>API 和乐高积木有什么相似之处？</h4><p>相信我们大多数人在儿童时期都喜欢玩乐高积木。乐高积木的真正乐趣和吸引力在于，尽管包装盒外面都带有示意图片，但你最终都可以随心所欲得搭出各种样子或造型。<br>对 API 的最佳解释就是它们像乐高积木一样。我们可以用创造性的方式来组合它们，而不用在意它们原本的设计和实现意图。<br>你可以发现很多 API 和乐高积木的相似之处：</p></li><li><p>标准化：通用、标准化的组件，作为基本的构建块（building blocks）；<br></p></li><li><p>可用性：强调可用性，附有文档或使用说明；<br></p></li><li><p>可定制：为不同功能使用不同的API；<br></p></li><li><p>创造性：能够组合不同的 API 来创造混搭的结果；</p></li></ul><p><br>乐高和 API 都有超简单的界面/接口，并且借助这样简单的界面/接口，它可以非常直观、容易、快速得构建。<br>虽然乐高和 API 一样可能附带示意图片或使用文档，大概描述了推荐玩法或用途，但真正令人兴奋的结果或收获恰恰是通过创造力产生的。<br><br><br>让我们仔细地思考下上述的提法。在很多情况下，API 的使用者构建出了 API 的构建者超出预期的服务或产品，API 使用者想要的，和 API 构建者认为使用者想要的，这二者之间通常有个断层。事实也确实如此，在 IoT 领域，我们使用 API 创造出了一些非常有创造性的使用场景。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;-2&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;关于什么
      
    
    </summary>
    
    
      <category term="架构" scheme="cpeixin.cn/categories/%E6%9E%B6%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>kali中文设置</title>
    <link href="cpeixin.cn/2019/12/01/kali%E4%B8%AD%E6%96%87%E8%AE%BE%E7%BD%AE/"/>
    <id>cpeixin.cn/2019/12/01/kali%E4%B8%AD%E6%96%87%E8%AE%BE%E7%BD%AE/</id>
    <published>2019-12-01T02:26:15.000Z</published>
    <updated>2020-04-04T11:06:21.313Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>更新源</p><p><a href="https://blog.csdn.net/qq_38333291/article/details/89764967" target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/qq_38333291/article/details/89764967</a></p><p>设置编码和中文字体安装</p><p><a href="http://www.linuxdiyf.com/linux/20701.html" target="_blank" rel="external nofollow noopener noreferrer">http://www.linuxdiyf.com/linux/20701.html</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;更新源&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq_38333291/article/details/897
      
    
    </summary>
    
    
      <category term="Linux" scheme="cpeixin.cn/categories/Linux/"/>
    
    
      <category term="kali" scheme="cpeixin.cn/tags/kali/"/>
    
  </entry>
  
  <entry>
    <title>分布式下的数据hash分布</title>
    <link href="cpeixin.cn/2019/11/19/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AEhash%E5%88%86%E5%B8%83/"/>
    <id>cpeixin.cn/2019/11/19/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AEhash%E5%88%86%E5%B8%83/</id>
    <published>2019-11-19T15:05:08.000Z</published>
    <updated>2020-04-04T11:24:04.737Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;!-- rebuild by neat --&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>我的服务器被黑了（二）</title>
    <link href="cpeixin.cn/2019/09/09/%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E9%BB%91%E4%BA%86%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>cpeixin.cn/2019/09/09/%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E9%BB%91%E4%BA%86%EF%BC%88%E4%BA%8C%EF%BC%89/</id>
    <published>2019-09-09T02:26:15.000Z</published>
    <updated>2020-04-04T12:00:14.168Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>苦逼的周一开始了，苦逼的工作开始了，坐到工位上，上班气正在逐渐的减弱，但是当我发现，我的三台服务器又被那些无情的小黑人们盯上了的时候，我的怒气值达到了顶点，同时还感觉有点丢脸，哈哈哈。<br><br><br>由于这三台服务器属于我个人的，没有经过运维兄弟的照顾，所以在安全方面，基本上没有防护。<br>这次是怎么发现的呢，是因为我服务器上的爬虫突然停止了，我带着疑问去看了下系统日志。于是敲下了下面的命令<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">journalctl -xe</span><br></pre></td></tr></table></figure><p><br>映入眼帘的是满屏的扫描和ssh尝试登陆<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Failed password <span class="keyword">for</span> invalid user admin <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Received disconnect <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span>:<span class="number">11</span>: Bye Bye [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Disconnected <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span> [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Failed password <span class="keyword">for</span> invalid user ansible <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Received disconnect <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span>:<span class="number">11</span>: Bye Bye [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Disconnected <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span> [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span> port <span class="number">45157</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: error: maximum authentication attempts exceeded <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span> port <span class="number">45157</span> ssh2 [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: Disconnecting: Too many authentication failures [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: PAM <span class="number">5</span> more authentication failures; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: PAM service(sshd) ignoring max retries; <span class="number">6</span> &gt; <span class="number">3</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">52</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">310</span>]: pam_unix(sshd:auth): authentication failure; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">52</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">310</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: error: maximum authentication attempts exceeded <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2 [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Disconnecting: Too many authentication failures [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: PAM <span class="number">5</span> more authentication failures; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: PAM service(sshd) ignoring max retries; <span class="number">6</span> &gt; <span class="number">3</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">54</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">314</span>]: pam_unix(sshd:auth): authentication failure; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">54</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">314</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">lines <span class="number">1105</span><span class="number">-1127</span>/<span class="number">1127</span> (END)</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">49</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Failed password <span class="keyword">for</span> invalid user admin <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Received disconnect <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span>:<span class="number">11</span>: Bye Bye [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Disconnected <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span> [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Failed password <span class="keyword">for</span> invalid user ansible <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Received disconnect <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span>:<span class="number">11</span>: Bye Bye [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Disconnected <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span> [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span> port <span class="number">45157</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: error: maximum authentication attempts exceeded <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span> port <span class="number">45157</span> ssh2 [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: Disconnecting: Too many authentication failures [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: PAM <span class="number">5</span> more authentication failures; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: PAM service(sshd) ignoring max retries; <span class="number">6</span> &gt; <span class="number">3</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">52</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">310</span>]: pam_unix(sshd:auth): authentication failure; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">52</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">310</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: error: maximum authentication attempts exceeded <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2 [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Disconnecting: Too many authentication failures [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: PAM <span class="number">5</span> more authentication failures; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: PAM service(sshd) ignoring max retries; <span class="number">6</span> &gt; <span class="number">3</span></span><br></pre></td></tr></table></figure><p><br>看到这里，感觉自己家的鸡，随时都要被偷走呀。。。。这还了得。于是马上开始了加固防护<br>对待这种情况，就是要禁止root用户远程登录，使用新建普通用户，进行远程登录，还有重要的一点，修改默认22端口。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@*** ~]<span class="comment"># useradd one             #创建用户</span></span><br><span class="line">[root@*** ~]<span class="comment"># passwd one              #设置密码</span></span><br></pre></td></tr></table></figure><p><br>输入新用户密码<br>首先确保文件 /etc/sudoers 中<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%wheel    ALL=(ALL)    ALL</span><br><span class="line">```  </span><br><span class="line">没有被注释</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```linux</span><br><span class="line">usermod -g wheel onerocket</span><br></pre></td></tr></table></figure><p><br>设置只有指定用户组才能使用su命令切换到root用户<br><br><br>在linux中，有一个默认的管理组 wheel。在实际生产环境中，即使我们有系统管理员root的权限，也不推荐用root用户登录。一般情况下用普通用户登录就可以了，在需要root权限执行一些操作时，再su登录成为root用户。但是，任何人只要知道了root的密码，就都可以通过su命令来登录为root用户，这无疑为系统带来了安全隐患。所以，将普通用户加入到wheel组，被加入的这个普通用户就成了管理员组内的用户。然后设置只有wheel组内的成员可以使用su命令切换到root用户。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /bin/bash</span></span><br><span class="line"><span class="comment"># Function: 修改配置文件，使得只有wheel组的用户可以使用 su 权限</span></span><br><span class="line">sed -i <span class="string">'/pam_wheel.so use_uid/c\auth            required        pam_wheel.so use_uid '</span> /etc/pam.d/su</span><br><span class="line">n=`cat /etc/login.defs | grep SU_WHEEL_ONLY | wc -l`</span><br><span class="line"><span class="keyword">if</span> [ $n -eq <span class="number">0</span> ];then</span><br><span class="line">echo SU_WHEEL_ONLY yes &gt;&gt; /etc/login.defs</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p><br>打开SSHD的配置文件<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure><p><br>查找“#PermitRootLogin yes”，将前面的“#”去掉，短尾“yes”改为“no”（不同版本可能区分大小写），并保存文件。<br><br><br>修改sshd默认端口<br>虽然更改端口无法在根本上抵御端口扫描，但是，可以在一定程度上提高防御。<br>打开sshd配置文件<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure><p><br>找到#Port 22 删掉注释<br><br><br><em>服务器端口最大可以开到65536</em><br><br><br>同时再添加一个Port 61024 （随意设置）<br><br><br>Port 22<br>Port 61024<br><br><br>重启sshd服务<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service sshd restart      <span class="comment">#centos6系列</span></span><br><span class="line">systemctl restart sshd  <span class="comment">#centos7系列</span></span><br><span class="line">firewall-cmd --add-port=<span class="number">61024</span>/tcp</span><br></pre></td></tr></table></figure><p><br>测试，使用新用户，新端口进行登录<br><br><br>如果登陆成功后，再将Port22注释掉，重启sshd服务。<br>到这里，关于远程登录的防护工作，就做好了。<br>最后，告诫大家，亲身体验，没有防护裸奔的服务器，真的太容易被抓肉鸡了！！！！！</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;苦逼的周一开始了，苦逼的工作开始了，坐到工位上，上班气正在逐渐的减弱，但是当我发现，我的三台服务器又被那些无情的小黑人们盯上了的时候，我的怒气值
      
    
    </summary>
    
    
      <category term="Linux" scheme="cpeixin.cn/categories/Linux/"/>
    
    
      <category term="服务器安全" scheme="cpeixin.cn/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>我的服务器被黑了</title>
    <link href="cpeixin.cn/2019/08/24/%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E9%BB%91%E4%BA%86/"/>
    <id>cpeixin.cn/2019/08/24/%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E9%BB%91%E4%BA%86/</id>
    <published>2019-08-24T02:26:15.000Z</published>
    <updated>2020-04-04T12:00:09.871Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p><a name="-2"></a></p><h1 id="服务器自述"><a href="#服务器自述" class="headerlink" title="服务器自述"></a>服务器自述</h1><p>我是一台8核，16G内存，4T的Linux (centOS 7)服务器… 还有两台和我一起被买来的苦主，我们一同长大，配置一样，都是从香港被贩卖到国外，我们三个组成了分布式爬虫框架，另两位苦主分别负责异步爬取连接，多进程爬取连接和scrapy-redis分布式爬取解析。<br><br><br>而我比较清闲，只负责存储. 网页链接放在我的redis中，而解析好的文章信息放在我的MySQL中。然而故事的开始，就是在安装redis的那天，主人的粗心大意，为了节省时间，从而让他今天花费了小半天来对我进行维修！！😢<br><a name="-3"></a></p><h1 id="为什么黑我的服务器"><a href="#为什么黑我的服务器" class="headerlink" title="为什么黑我的服务器"></a>为什么黑我的服务器</h1><p>这样一台配置的服务器，一个月的价格大概在1000RMB一个月，怎么说呢… 这个价格的服务器对于个人用户搭建自己玩的环境还是有些小贵的。例如我现在写博客，也是托管在GitHub上的，我也可以租用一台服务器来托管的博客，但是目前我的这种级别，也是要考虑到投入产出比是否合适，哈哈哈。<br><br><br>但是对于，服务器上运行的任务和服务产出的价值要远远大于服务器价值的时候，这1000多RMB就可以忽略不计了。同时，还有黑衣人，他们需要大量的服务器，来运行同样的程序，产出的价值他们也无法衡量，有可能很多有可能很少。。<br><br><br>那么这时候，他们为了节约成本，降低成本，就会用一些黑色的手法，例如渗透，sql注入，根据漏洞扫描等方法来 抓“肉鸡”，抓到大量的可侵入的服务器，然后在你的服务器上的某一个角落，放上他的程序，一直在运行，一直在运行，占用着你的cpu,占用着你的带宽…<br><br><br>那么上面提到的黑衣人，就有那么一类角色，“矿工”！！！！<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585404954445-f30a25a0-5939-4773-b5d9-8bb6a7c53b02.png#align=left&display=inline&height=892&name=1.png&originHeight=892&originWidth=1244&size=1778564&status=done&style=none&width=1244" alt="1.png"><br><br><br>曾经，我也专注过区块链，我也短暂的迷失在数字货币的浪潮中，但是没有吃到红利👀👀👀 就是这些数字世界的矿工，利用我服务器的漏洞黑了我的服务器<br><a name="-4"></a></p><h1 id="如何发现被黑"><a href="#如何发现被黑" class="headerlink" title="如何发现被黑"></a>如何发现被黑</h1><p>回到这篇博客的正题，我是如何发现，我的服务器被黑了呢？？<br><br><br>最近我在做scrapy分布式爬虫方面的工作，准备了三台服务器，而这台被黑的服务器是我用来做存储的，其中用到了redis和mysql。其中引发这件事情的就是redis，我在安装redis的时候，可以说责任完全在我，我为了安装节约时间，以后使用方便等，做了几个很错误的操作<br><br><br>1.关闭了Linux防火墙<br><br><br>2.没有设置redis访问密码<br><br><br>3.没有更改redis默认端口<br><br><br>4.开放了任意IP可以远程连接<br><br><br>以上四个很傻的操作,都是因为以前所用的redis都是有公司运维同事进行安装以及安全策略方面的配置，以至我这一次没有注意到安装方面。<br><br><br>当我的爬虫程序已经平稳的运行了两天了，我就开始放心了，静静地看着spider疯狂的spider,可是就是在随后，redis服务出现异常，首先是我本地客户端连接不上远程redis-server，我有想过是不是网络不稳定的问题。在我重启redis后，恢复正常，又平稳的运行了一天。<br><br><br>但是接下来redis频繁出问题，我就想，是不是爬虫爬取了大量的网页链接，对redis造成了阻塞。于是，我开启了对redis.conf，还有程序端的connect两方面360度的优化，然并卵。。。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -i tcp:<span class="number">6379</span></span><br></pre></td></tr></table></figure><p><br>使用上面的命令后，发现redis服务正常运行，6379端口也是开启的。我陷入了深深地迷惑。。。。。<br><br><br>但是这时其实就应该看出一些端倪了，因为正常占用 6379 端口的进程名是 ： redis-ser 。但是现在占用 6379 端口的进程名是 ：xmrig-no (忘记截图了)，但是这时我也没有多想<br>直到我运行：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top</span><br></pre></td></tr></table></figure><p><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585404912911-97736d80-2ee3-455d-a948-6d134f4e2663.png#align=left&display=inline&height=534&name=2.png&originHeight=534&originWidth=3338&size=980508&status=done&style=none&width=3338" alt="2.png"><br>发现了占用 6379 端口的进程全名称xmrig…，我才恍然大悟，我的端口被占用了。我在google上一查，才发现。。我被黑了<br><a name="-5"></a></p><h1 id="做了哪些急救工作"><a href="#做了哪些急救工作" class="headerlink" title="做了哪些急救工作"></a>做了哪些急救工作</h1><p>这时，感觉自己开始投入了一场对抗战<br><br><br>1.首先查找植入程序的位置。<br>在/tmp/目录下，一般植入程序都会放在 /tmp 临时目录下，其实回过头一想，放在这里，也是挺妙的。<br><br><br>2.删除清理可疑文件<br><br><br>杀死进程<br><br><br>删除了正在运行的程序文件还有安装包<br>3.查看所有用户的定时任务<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/passwd |cut -f <span class="number">1</span> -d:crontab -uXXX -l</span><br></pre></td></tr></table></figure><p><br>4.开启防火墙<br><br><br>仅开放会使用到的端口<br>5.修改redis默认端口<br><br><br>redis.conf中的port<br>6.添加redis授权密码<br><br><br>redis.conf中的requirepass<br>7.修改绑定远程绑定ip<br><br><br>redis.conf中的bind<br>最后重启redis服务！<br><a name="-6"></a></p><h1 id="从中学到了什么"><a href="#从中学到了什么" class="headerlink" title="从中学到了什么"></a>从中学到了什么</h1><p>明明是自己被黑了，但是在补救的过程中，却得到了写程序给不了的满足感。感觉因为这件事情，上帝给我打开了另一扇窗户～～～<br>最后说下，这个木马是怎么进来的呢，查了一下原来是利用Redis端口漏洞进来的，它可以对未授权访问redis的服务器登录，定时下载并执行脚本，脚本运行，挖矿，远程调用等。所以除了执行上述操作，linux服务器中的用户权限，服务权限精细化，防止再次被入侵。<br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;-2&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h1 id=&quot;服务器自述&quot;&gt;&lt;a href=&quot;#服务器自述&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
    
      <category term="Linux" scheme="cpeixin.cn/categories/Linux/"/>
    
    
      <category term="服务器安全" scheme="cpeixin.cn/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>python爬虫 - 动态爬取</title>
    <link href="cpeixin.cn/2019/06/12/python%E7%88%AC%E8%99%AB%E4%B9%8B%E5%8A%A8%E6%80%81%E7%88%AC%E5%8F%96/"/>
    <id>cpeixin.cn/2019/06/12/python%E7%88%AC%E8%99%AB%E4%B9%8B%E5%8A%A8%E6%80%81%E7%88%AC%E5%8F%96/</id>
    <published>2019-06-12T15:26:15.000Z</published>
    <updated>2020-04-04T17:11:17.062Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>我们的目的是抓取拉勾网Python分类下全国到目前为止展示出来的所有招聘信息，首先在浏览器点击进去看看吧。如果你足够小心或者网速比较慢，那么你会发现，在点击Python分类之后跳到的新页面上，招聘信息出现时间是晚于页面框架出现时间的。到这里，我们几乎可以肯定，招聘信息并不在页面HTML源码中，我们可以通过按下”command+option+u”(在Windows和Linux上的快捷键是”ctrl+u”)来查看网页源码，果然在源码中没有出现页面展示的招聘信息。<br><br><br>到这一步，我看到的大多数教程都会教，使用什么什么库，如何如何模拟浏览器环境，通过怎样怎样的方式完成网页的渲染，然后得到里面的信息…永远记住，对于爬虫程序，模拟浏览器往往是下下策，只有实在没有办法了，才去考虑模拟浏览器环境，因为那样的内存开销实在是很大，而且效率非常低。<br><br><br>那么我们怎么处理呢？经验是，这样的情况，大多是是浏览器会在请求和解析HTML之后，根据js的“指示”再发送一次请求，得到页面展示的内容，然后通过js渲染之后展示到界面。好消息是，这样的请求往往得到的内容是json格式的，所以我们非但不会加重爬虫的任务，反而可能会省去解析HTML的功夫。<br><br><br>那个，继续打开Chrome的开发者工具，当我们点击“下一页”之后，浏览器发送了如下请求：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585401843101-98e57df8-c124-4923-aa9f-7c42ce2288b6.png#align=left&display=inline&height=1300&originHeight=1300&originWidth=3356&size=0&status=done&style=none&width=3356" alt><br><br><br>注意观察”positionAjax.json”这个请求，它的Type是”xhr”，全称叫做”XMLHttpRequest”，XMLHttpRequest对象可以在不向服务器提交整个页面的情况下，实现局部更新网页。那么，现在它的可能性最大了，我们单击它之后好好观察观察吧：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585401843056-e12f0f79-905f-4420-abfd-fb85625767ac.png#align=left&display=inline&height=1150&originHeight=1150&originWidth=2266&size=0&status=done&style=none&width=2266" alt><br><br><br>点击之后我们在右下角发现了如上详情，其中几个tab的内容表示：<br>Headers：请求和响应的详细信息<br>Preview：响应体格式化之后的显示<br>Response：响应体原始内容<br>Cookies：Cookies<br>Timing：时间开销<br><br><br>通过对内容的观察，返回的确实是一个json字符串，内容包括本页每一个招聘信息，到这里至少我们已经清楚了，确实不需要解析HTML就可以拿到拉钩招聘的信息了。那么，请求该如何模拟呢？我们切换到Headers这一栏，留意三个地方：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585401842263-072689cf-5dea-4f8b-b103-0758d9c5e52e.png#align=left&display=inline&height=262&originHeight=262&originWidth=1276&size=0&status=done&style=none&width=1276" alt><br><br><br>上面的截图展示了这次请求的请求方式、请求地址等信息。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585401843887-cf8bff5f-4570-4ad4-8681-f0f3eae929b3.png#align=left&display=inline&height=884&originHeight=884&originWidth=2652&size=0&status=done&style=none&width=2652" alt><br><br><br>上面的截图展示了这次请求的请求头，一般来讲，其中我们需要关注的是Cookie / Host / Origin / Referer / User-Agent / X-Requested-With等参数。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585401843009-4797a28d-3070-421e-a45c-86781d7f580d.png#align=left&display=inline&height=188&originHeight=188&originWidth=848&size=0&status=done&style=none&width=848" alt><br><br><br>上面这张截图展示了这次请求的提交数据，根据观察，kd表示我们查询的关键字，pn表示当前页码。<br><br><br>那么，我们的爬虫需要做的事情，就是按照页码不断向这个接口发送请求，并解析其中的json内容，将我们需要的值存储下来就好了。这里有两个问题：什么时候结束，以及如何的到json中有价值的内容。<br><br><br>我们回过头重新观察一下返回的json，格式化之后的层级关系如下：<br><br><br>很容易发现，content下的hasNextPage即为是否存在下一页，而content下的result是一个list，其中的每项则是一条招聘信息。在Python中，json字符串到对象的映射可以通过json这个库完成：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">json_obj = json.loads(<span class="string">"&#123;'key': 'value'&#125;"</span>)  <span class="comment"># 字符串到对象</span></span><br><span class="line">json_str = json.dumps(json_obj)            <span class="comment"># 对象到字符串</span></span><br></pre></td></tr></table></figure><p><br>json字符串的”[ ]“映射到Python的类型是list，”{ }”映射到Python则是dict。到这里，分析过程已经完全结束，可以愉快的写代码啦。具体代码这里不再给出，希望你可以自己独立完成，如果在编写过程中存在问题，可以联系我获取帮助。<br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;我们的目的是抓取拉勾网Python分类下全国到目前为止展示出来的所有招聘信息，首先在浏览器点击进去看看吧。如果你足够小心或者网速比较慢，那么你会
      
    
    </summary>
    
    
      <category term="python" scheme="cpeixin.cn/categories/python/"/>
    
    
      <category term="爬虫" scheme="cpeixin.cn/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>shadowsock-vps搭建VPN</title>
    <link href="cpeixin.cn/2019/04/19/shadowsock-vps%E6%90%AD%E5%BB%BAVPN/"/>
    <id>cpeixin.cn/2019/04/19/shadowsock-vps%E6%90%AD%E5%BB%BAVPN/</id>
    <published>2019-04-19T15:26:15.000Z</published>
    <updated>2020-04-04T17:11:07.011Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p><a name="-1"></a></p><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>还有10天左右就要回国了，由于职业的需要，对Google的依赖的越来越大的，那么回国后怎么才能‘科学上网’呢？之前在国内的时候，有使用过Lantern，稳定性和速度都还是不错了，可惜后来被和谐了。所以今天准备尝试搭建VPN，自己独立使用，一边搭建一边将过程记录下来。<br><a name="-2"></a></p><h1 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h1><p>VPS: VPS（Virtual Private Server 虚拟专用服务器）技术，将一台服务器分割成多个虚拟专享服务器的优质服务。实现VPS的技术分为容器 [1] 技术，和虚拟化技术 [2] 。在容器或虚拟机中，每个VPS都可分配独立公网IP地址、独立操作系统、实现不同VPS间磁盘空间、内存、CPU资源、进程和系统配置的隔离，为用户和应用程序模拟出“独占”使用计算资源的体验。VPS可以像独立服务器一样，重装操作系统，安装程序，单独重启服务器。<br><br><br>VPS为使用者提供了管理配置的自由，可用于企业虚拟化，也可以用于IDC资源租用。<br><br><br>VPN: VPN的学名叫虚拟专用网，洋文叫“Virtual Private Network”。维基百科的介绍在“这里”。本来这玩意儿主要是用于商业公司，为了让那些不在公司里的员工（比如出差在外的）能够方便地访问公司的内部网络。为了防止黑客冒充公司的员工，从外部访问公司的内部网络，VPN 软件都会提供强大的加密功能。而这个加密功能，也就让它顺便成为翻墙的利器。<br><a name="-3"></a></p><h1 id="科学上网原理"><a href="#科学上网原理" class="headerlink" title="科学上网原理"></a>科学上网原理</h1><p>VPN浏览外网的原理<br><br><br>使用 VPN 通常需要先安装客户端软件。当你运行 VPN 客户端，它会尝试联到 VPN 服务器（这点跟加密代理类似）。一旦和 VPN 服务器建立连接，VPN 客户端就会在你的系统中建立了一个虚拟局域网。而且，你的系统中也会多出一个虚拟网卡（在 Windows 下，可以用 ipconfig /all 命令，看到这多出来的网卡）。这样一来，你的系统中就有不止一块网卡。这就引出一个问题：那些访问网络的程序，它的数据流应该通过哪个网卡进出？<br>为了解决此问题，VPN 客户端通常会修改你系统的路由表，让那些数据流，优先从虚拟的网卡进出。由于虚拟的网卡是通往 VPN 服务器的，当数据流到达 VPN 服务器之后，VPN 服务器再帮你把数据流转向到真正的目的地。<br><br><br>前面说了，VPN 为了保证安全，都采用强加密的方式传输数据。这样一来，GFW 就无法分析你的网络数据流，进行敏感词过滤。所以，使用墙外的VPN服务器，无形中就能达到翻墙的效果。<br><a name="-4"></a></p><h1 id="方案选择"><a href="#方案选择" class="headerlink" title="方案选择"></a>方案选择</h1><p>VPN是一个大类，其中有很多实现的方法，防火长城现在将 VPN 屏蔽的已经所剩无几，后来大家看到了SSH，使用SSH的sock5很稳定，但是特征也十分明显，防火长城可以对其直接进行定向干扰。<br><br><br>而除了VPN，对于翻墙大家仍然有很多方法，比如Shadowsocks 、Lantern、VPNGate 等等，而实际上无论哪种方式，他们本身都需要一台服务器作为中间人进行消息传递。而VPS虚拟专用服务器就十分适合担当这个角色，并且由于VPS平时就作为商品在各类云服务器平台上售卖，自行购买并搭建相当方便，唯一需要的就是人们对于服务器的操作技术。<br><br><br><strong>而这次选择的方案是：VPS+Shadowsocks</strong><br>**<br>Shadowsocks特点：<br><br><br>省电，在电量查看里几乎看不到它的身影；<br><br><br>支持开机自启动，且断网无影响，无需手动重连，方便网络不稳定或者3G&amp;Wi-Fi频繁切换的小伙伴；<br><br><br>可使用自己的服务器，安全和速度的保证；<br><br><br>支持区分国内外流量，传统VPN在翻出墙外后访问国内站点会变慢；<br><br><br>可对应用设置单独代理，5.0之后的系统无需root。<br><br><br>Shadowsocks 目前不容易被封杀主要是因为：<br>建立在socks5协议之上，socks5是运用很广泛的协议，所以没办法直接封杀socks5协议<br>使用socks5协议建立连接，而没有使用VPN中的服务端身份验证和密钥协商过程。而是在服务端和客户端直接写死密钥和加密算法。所以防火墙很难找到明显的特征，因为这就是个普通的socks5协议。<br><br><br>Shadowsock搭建也比较简单，所以很多人自己架设VPS搭建，个人使用流量也很小，没法通过流量监控方式封杀。<br>自定义加密方式和密钥。因为加密主要主要是防止被检测，所以要选择安全系数高的加密方式。之前RC4会很容易被破解，而导致被封杀。所以现在推荐使用AES加密。而在客户端和服务端自定义密钥，泄露的风险相对较小。<br>所以如果是自己搭建的Shadosocks被封的概率很小，但是如果是第三方的Shadeowsocks，密码是server定的，你的数据很可能遭受到中间人攻击。<br><a name="-5"></a></p><h1 id="开工"><a href="#开工" class="headerlink" title="开工"></a>开工</h1><p><a name="vps"></a></p><h2 id="购买vps"><a href="#购买vps" class="headerlink" title="购买vps"></a>购买vps</h2><p>首先我们需要购买一台境外的服务器，接着我们在这台云服务器里面安装代理服务，那么以后我们上网的时候就可以通过它来中转，轻松畅快的畅游全网了。<br>购买VPS,我选择了<a href="https://www.vultr.com/" target="_blank" rel="external nofollow noopener noreferrer">vultr</a>，大家用过都说好，购买的过程也很方便。<br><br><br>第一步：选择离中国较近国家的服务器。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400540784-be727007-a613-4b5b-a3d5-9b5fbf9734a7.png#align=left&display=inline&height=1468&name=step1.png&originHeight=1468&originWidth=3066&size=659813&status=done&style=none&width=3066" alt="step1.png"><br><br><br><br><br>第二步：选择服务器配置和系统<br><br><br>这里，系统选择的是CentOS 7,配置的话，如果只是自己浏览网页的话，选择最低配置就好。其他的选项可以略过。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400556831-e2446e46-8c7e-4292-97a8-b89e6d983c9c.png#align=left&display=inline&height=1594&name=step2.png&originHeight=1594&originWidth=2792&size=669959&status=done&style=none&width=2792" alt="step2.png"><br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235703-e6afdea2-828f-42a0-a955-67960c8710bc.png#align=left&display=inline&height=1812&originHeight=1812&originWidth=2600&size=0&status=done&style=none&width=2600" alt><br><br><br>第三步：支付和部署<br><br><br>支付可以选择支付宝支付，非常方便。购买成功后，点击Server中的“+”号，来部署你刚刚选择的服务器。<br>第四步：登陆服务器<br><br><br>查看服务器详情 Server Details,根据提供的服务器信息，登陆服务器。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235150-95a87ca7-8392-404e-a5d9-c4a606b8ae7e.png#align=left&display=inline&height=1166&originHeight=1166&originWidth=2728&size=0&status=done&style=none&width=2728" alt><br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235639-e36e0afa-200d-49ad-a324-350004d08d09.png#align=left&display=inline&height=1232&originHeight=1232&originWidth=2612&size=0&status=done&style=none&width=2612" alt><br><br><br>我是使用Mac本身终端ssh到服务器上的，因为Mac上多数的SSH客户端要么收费，要么不好用，要么安装过程非常繁琐。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p <span class="number">22</span> root@ip</span><br></pre></td></tr></table></figure><p><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235316-408c45f7-df95-4c8c-9428-9f476c6c7190.png#align=left&display=inline&height=244&originHeight=244&originWidth=1304&size=0&status=done&style=none&width=1304" alt><br><a name="shadowsocks"></a></p><h2 id="搭建shadowsocks服务器"><a href="#搭建shadowsocks服务器" class="headerlink" title="搭建shadowsocks服务器"></a>搭建shadowsocks服务器</h2><p>连接到你的 vultr 服务器之后，接下来就可以使用几个命令让你快速搭建一个属于自己的 ss 服务器：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install wget</span><br></pre></td></tr></table></figure><p><br>接着执行安装shadowsocks：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget –no-check-certificate -O shadowsocks.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh</span><br></pre></td></tr></table></figure><p><br>获取 <a href="http://shadowsocks.sh/" target="_blank" rel="external nofollow noopener noreferrer">shadowsocks.sh</a> 读取权限：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x shadowsocks.sh</span><br></pre></td></tr></table></figure><p><br>设置你的 ss 密码和端口号：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./shadowsocks.sh <span class="number">2</span>&gt;&amp;<span class="number">1</span> | tee shadowsocks.log</span><br></pre></td></tr></table></figure><p><br>接下来后就可以设置密码和端口号了<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400236071-267db22c-ea03-4f8b-969d-86ae5efc4d68.png#align=left&display=inline&height=306&originHeight=306&originWidth=1086&size=0&status=done&style=none&width=1086" alt><br><br><br>密码和端口号可以使用默认的，也可以直接重新输入新的。<br>选择加密方式<br><br><br>设置完密码和端口号之后，我们选择加密方式，这里选择 7 ，使用aes-256-cfb的加密模式<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235435-525e1564-eb61-47e0-b9b1-a28683979702.png#align=left&display=inline&height=684&originHeight=684&originWidth=914&size=0&status=done&style=none&width=914" alt><br><br><br>接着按任意键进行安装。<br>安装ss完成后<br><br><br>会给你显示你需要连接 vpn 的信息：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400239145-4d70810e-bc73-4cfa-bc8c-4da35e3e0dcf.png#align=left&display=inline&height=464&originHeight=464&originWidth=1186&size=0&status=done&style=none&width=1186" alt><br>搞定，将这些信息保存起来，那么这时候你就可以使用它们来科学上网啦。<br><a name="bbr"></a></p><h2 id="使用BBR加速上网"><a href="#使用BBR加速上网" class="headerlink" title="使用BBR加速上网"></a>使用BBR加速上网</h2><p>安装 BBR<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh</span><br></pre></td></tr></table></figure><p><br>获取读写权限<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x bbr.sh</span><br></pre></td></tr></table></figure><p><br>启动BBR安装<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bbr.sh</span><br></pre></td></tr></table></figure><p><br>接着按任意键，开始安装，坐等一会。安装完成一会之后它会提示我们是否重新启动vps，我们输入 y 确定重启服务器。<br>重新启动之后，输入：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep bbr</span><br></pre></td></tr></table></figure><p><br>如果看到 tcp_bbr 就说明 BBR 已经启动了。<br><a name="-6"></a></p><h2 id="客户端进行连接"><a href="#客户端进行连接" class="headerlink" title="客户端进行连接"></a>客户端进行连接</h2><p><a name="windowsshadowsocks"></a></p><h3 id="windows使用Shadowsocks"><a href="#windows使用Shadowsocks" class="headerlink" title="windows使用Shadowsocks"></a>windows使用Shadowsocks</h3><p>windows点击下载：<a href="https://pan.baidu.com/s/19m0AfTkPDSRj0bfYrGpbIg" target="_blank" rel="external nofollow noopener noreferrer">Shadowsocks windows客户端</a><br>打开 Shadowsocks 客户端，输入ip地址，密码，端口，和加密方式。接着点击确定，右下角会有个小飞机按钮，右键–&gt;启动代理。<br><a name="androidshadowsocks"></a></p><h3 id="Android使用Shadowsocks"><a href="#Android使用Shadowsocks" class="headerlink" title="Android使用Shadowsocks"></a>Android使用Shadowsocks</h3><p>Android点击下载：<a href="https://pan.baidu.com/s/1coAkZn-GuYHu5eIKaHECxA" target="_blank" rel="external nofollow noopener noreferrer">Shadowsocks Android客户端</a><br>打开apk安装，接着打开APP，输入ip地址，密码，端口，和加密方式。即可科学上网。<br><a name="iphoneshadowsocks"></a></p><h3 id="iPhone使用Shadowsocks"><a href="#iPhone使用Shadowsocks" class="headerlink" title="iPhone使用Shadowsocks"></a>iPhone使用Shadowsocks</h3><p>iPhone要下载的app需要在appstore下载，但是需要用美区账号才能下载，而且这个APP需要钱。在这里提供一种解决方案，就是可以再搭建一个<a href="https://wistbean.github.io/ipsec,l2tp_vpn.html#%E4%BD%BF%E7%94%A8-IPsec-L2TP-%E8%84%9A%E6%9C%AC%E6%90%AD%E5%BB%BA" target="_blank" rel="external nofollow noopener noreferrer">IPsec/L2TP</a> VPN,专门给你的iPhone使用。<br><a name="mac"></a></p><h3 id="Mac配置"><a href="#Mac配置" class="headerlink" title="Mac配置"></a>Mac配置</h3><p>用的是Mac电脑，所以点击相关链接。东西都挂在github上，下载对应的zip文件，下载完成后安装并运行起来。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235178-7ccd25cd-8b34-4103-8cc8-204e84672cfe.png#align=left&display=inline&height=748&originHeight=748&originWidth=1302&size=0&status=done&style=none&width=1302" alt><br><br><br>点击图标，进入 服务器设置<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400239120-45698c54-ac3b-48b9-9c4d-9f3537938f87.png#align=left&display=inline&height=926&originHeight=926&originWidth=1302&size=0&status=done&style=none&width=1302" alt><br><br><br>主要有四个地方要填，服务器的地址，端口号，加密方法，密码。服务器地址即为之前 Main controls选项中的IP地址。端口号、加密方法、密码必须与之前 Shadowsocks Server 中的信息一一匹配，否则会连接失败。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235629-2861fc8f-5bfc-4610-993f-49064774e693.png#align=left&display=inline&height=1156&originHeight=1156&originWidth=1292&size=0&status=done&style=none&width=1292" alt><br><br><br>设置完成后点击确定，然后服务器选择这个配置，默认选中PAC自动模式，确保Shadowsocks状态为On，这时候打开谷歌试试~<br>接着就可以上外网了 😂</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="工具" scheme="cpeixin.cn/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="shadowsock" scheme="cpeixin.cn/tags/shadowsock/"/>
    
  </entry>
  
  <entry>
    <title>数据分析-关联规则原理</title>
    <link href="cpeixin.cn/2019/03/02/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E5%8E%9F%E7%90%86/"/>
    <id>cpeixin.cn/2019/03/02/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E5%8E%9F%E7%90%86/</id>
    <published>2019-03-02T14:19:09.000Z</published>
    <updated>2020-04-05T14:30:54.004Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>关联规则这个概念，最早是由 Agrawal 等人在 1993 年提出的。在 1994 年 Agrawal 等人又提出了基于关联规则的 Apriori 算法，至今 Apriori 仍是关联规则挖掘的重要算法。<br><br><br><strong>关联规则挖掘</strong>可以让我们从数据集中发现项与项（item 与 item）之间的关系，它在我们的生活中有很多应用场景，“购物篮分析”就是一个常见的场景，这个场景可以从消费者交易记录中发掘商品与商品之间的关联关系，进而通过商品捆绑销售或者相关推荐的方式带来更多的销售量。所以说，关联规则挖掘是个非常有用的技术。<br><br><br>在今天的内容中，希望你能带着问题，和我一起来搞懂以下几个知识点：</p><ul><li>搞懂关联规则中的几个重要概念：支持度、置信度、提升度；</li><li>Apriori 算法的工作原理；</li><li>在实际工作中，我们该如何进行关联规则挖掘。</li></ul><p><a name="iGDgo"></a></p><h3 id="关联规则概念"><a href="#关联规则概念" class="headerlink" title="关联规则概念"></a>关联规则概念</h3><p>搞懂关联规则中的几个概念<br><br><br>我举一个超市购物的例子，下面是几名客户购买的商品列表：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585750069389-0cb13df9-8d19-442d-bb19-c3e5c3175230.png#align=left&display=inline&height=195&name=f7d0cc3c1a845bf790b344f62372941c.png&originHeight=195&originWidth=468&size=27163&status=done&style=none&width=468" alt="f7d0cc3c1a845bf790b344f62372941c.png"><br><br><br><br><br><strong>什么是支持度呢？</strong><br><br><br>支持度是个百分比，<strong>它指的是某个商品组合出现的次数与总次数之间的比例</strong>。<br><br><br>支持度越高，代表这个组合出现的频率越大。在这个例子中，我们能看到“牛奶”出现了 4 次，那么这 5 笔订单中“牛奶”的支持度就是 4/5=0.8。<br><br><br>同样<strong>“牛奶 + 面包”出现了 3 次，那么这 5 笔订单中“牛奶 + 面包”的支持度就是 3/5=0.6。</strong><br><br><br><strong>什么是置信度呢？</strong><br><br><br>它指的就是当你购买了商品 A，会有多大的概率购买商品 B，在上面这个例子中：<br><br><br>置信度（牛奶→啤酒）=2/4=0.5，代表如果你购买了牛奶，有多大的概率会购买啤酒？<br><br><br>置信度（啤酒→牛奶）=2/3=0.67，代表如果你购买了啤酒，有多大的概率会购买牛奶？<br><br><br>我们能看到，在 4 次购买了牛奶的情况下，有 2 次购买了啤酒，所以置信度 (牛奶→啤酒)=0.5，而在 3 次购买啤酒的情况下，有 2 次购买了牛奶，所以置信度（啤酒→牛奶）=0.67。<br><br><br>所以说置信度是个条件概念，<strong>就是说在 A 发生的情况下，B 发生的概率是多少。</strong><br><br><br><strong>什么是提升度呢？</strong><br><br><br>我们在做商品推荐的时候，<strong>重点考虑的是提升度</strong>，因为提升度代表的是“商品 A 的出现，对商品 B 的出现概率提升的”程度。<br><br><br>还是看上面的例子，如果我们单纯看置信度 (可乐→尿布)=1，也就是说可乐出现的时候，用户都会购买尿布，那么当用户购买可乐的时候，我们就需要推荐尿布么？<br><br><br>实际上，就算用户不购买可乐，也会直接购买尿布的，所以用户是否购买可乐，对尿布的提升作用并不大。<br><br><br>我们可以用下面的公式来计算商品 A 对商品 B 的提升度：<br><br><br><strong>提升度 (A→B)= 置信度 (A→B)/ 支持度 (B)</strong><br><br><br>这个公式是用来衡量 A 出现的情况下，是否会对 B 出现的概率有所提升。<br><br><br>所以提升度有三种可能：<br></p><ul><li>提升度 (A→B)&gt;1：代表有提升；</li><li>提升度 (A→B)=1：代表有没有提升，也没有下降；</li><li>提升度 (A→B)&lt;1：代表有下降。</li></ul><p><br><strong>提升度 (牛奶→啤酒)</strong><br><strong><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1585752575464-518e8992-94d7-43e9-8ebd-5a11f913fb53.jpeg#align=left&display=inline&height=987&name=WechatIMG84.jpeg&originHeight=987&originWidth=1754&size=425247&status=done&style=none&width=1754" alt="WechatIMG84.jpeg"></strong><br><a name="j6KYP"></a></p><h3 id="Apriori-的工作原理"><a href="#Apriori-的工作原理" class="headerlink" title="Apriori 的工作原理"></a>Apriori 的工作原理</h3><p><br>明白了关联规则中支持度、置信度和提升度这几个重要概念，我们来看下 Apriori 算法是如何工作的。首先我们把上面案例中的商品用 ID 来代表，牛奶、面包、尿布、可乐、啤酒、鸡蛋的商品 ID 分别设置为 1-6，上面的数据表可以变为：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585752122553-ac9771fe-3eeb-4734-a9bb-b74262913f76.png#align=left&display=inline&height=196&name=e30fe11a21191259e6a93568461fa933.png&originHeight=196&originWidth=466&size=19390&status=done&style=none&width=466" alt="e30fe11a21191259e6a93568461fa933.png"><br><br><br>Apriori 算法其实就是查找<strong>频繁项集 (frequent itemset) **的过程，所以首先我们需要定义什么是频繁项集。</strong>频繁项集就是支持度大于等于最小支持度 (Min Support) 阈值的项集**，所以小于最小值支持度的项目就是非频繁项集，而大于等于最小支持度的项集就是频繁项集。<br><br><br>项集这个概念，英文叫做 itemset，它可以是单个的商品，也可以是商品的组合。<br><br><br>我们再来看下这个例子，假设我随机指定最小支持度是 50%，也就是 0.5。我们来看下 Apriori 算法是如何运算的。首先，我们先计算单个商品的支持度，也就是得到 K=1 项的支持度：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585752711588-43ac0c51-e9d4-40bc-9e1a-d1074ab82df6.png#align=left&display=inline&height=228&name=fff5ba49aff930bba71c98685be4fcde.png&originHeight=228&originWidth=467&size=18392&status=done&style=none&width=467" alt="fff5ba49aff930bba71c98685be4fcde.png"><br><br><br>因为最小支持度是 0.5，所以你能看到商品 4、6 是不符合最小支持度的，不属于频繁项集，于是经过筛选商品的频繁项集就变成：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585752793262-6a6d8b43-60c0-4be7-a89d-a2e7cc743eca.png#align=left&display=inline&height=164&name=ae108dc65c33e9ed9546a0d91bd881b6.png&originHeight=164&originWidth=464&size=15564&status=done&style=none&width=464" alt="ae108dc65c33e9ed9546a0d91bd881b6.png"><br><br><br>在这个基础上，我们将商品两两组合， 根据订单编号图，得到 k=2 项的支持度：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585752835552-c15c5f06-8c43-4cc9-946a-0ad834631594.png#align=left&display=inline&height=228&name=a51fd814ebd68304e3cb137630af3ea3.png&originHeight=228&originWidth=463&size=19667&status=done&style=none&width=463" alt="a51fd814ebd68304e3cb137630af3ea3.png"><br><br><br>我们再筛掉小于最小值支持度的商品组合，可以得到：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585753001938-ae00db12-51a2-44d9-8496-a8eabfc8f046.png#align=left&display=inline&height=136&name=a087cd1bd2a9e033105de275834b79c8.png&originHeight=136&originWidth=472&size=15168&status=done&style=none&width=472" alt="a087cd1bd2a9e033105de275834b79c8.png"></p><p>我们再将商品进行 K=3 项的商品组合，可以得到：<br></p><table><thead><tr><th align="center">商品项集</th><th align="center">支持度</th></tr></thead><tbody><tr><td align="center">1，2，3</td><td align="center">3/5</td></tr><tr><td align="center">1，2，5</td><td align="center">1/5</td></tr><tr><td align="center">1，3，5</td><td align="center">2/5</td></tr><tr><td align="center">2，3，5</td><td align="center">2/5</td></tr></tbody></table><p><br>再筛掉小于最小值支持度的商品组合，可以得到：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585753598894-55ee09c8-60e6-424c-9c09-21893fc841de.png#align=left&display=inline&height=75&name=d51fc9137a537d8cb96fa21707cab70f.png&originHeight=75&originWidth=469&size=12115&status=done&style=none&width=469" alt="d51fc9137a537d8cb96fa21707cab70f.png"></p><p>通过上面这个过程，我们可以得到 K=3 项的频繁项集{1,2,3}，也就是{牛奶、面包、尿布}的组合。<br><br><br>到这里，你已经和我模拟了一遍整个 Apriori 算法的流程，下面我来给你总结下 Apriori 算法的递归流程：</p><ul><li>K=1，计算 K 项集的支持度；</li><li>筛选掉小于最小支持度的项集；</li><li>如果项集为空，则对应 K-1 项集的结果为最终结果。</li></ul><p><br>否则 K=K+1，重复 1-3 步。<br></p><p><a name="gNxin"></a></p><h3 id="Apriori-的改进算法：FP-Growth-算法"><a href="#Apriori-的改进算法：FP-Growth-算法" class="headerlink" title="Apriori 的改进算法：FP-Growth 算法"></a>Apriori 的改进算法：FP-Growth 算法</h3><p><br>我们刚完成了 Apriori 算法的模拟，你能看到 Apriori 在计算的过程中有以下几个缺点：</p><ul><li>可能产生大量的候选集。因为采用排列组合的方式，把可能的项集都组合出来了；</li><li>每次计算都需要重新扫描数据集，来计算每个项集的支持度。</li></ul><p><br>所以 Apriori 算法会浪费很多计算空间和计算时间，为此人们提出了 FP-Growth 算法，它的特点是：创建了一棵 FP 树来存储频繁项集。在创建前对不满足最小支持度的项进行删除，减少了存储空间。<br><br><br>我稍后会讲解如何构造一棵 FP 树；整个生成过程只遍历数据集 2 次，大大减少了计算量。所以在实际工作中，我们常用 FP-Growth 来做频繁项集的挖掘，下面我给你简述下 FP-Growth 的原理。<br><br><br><strong>1. 创建项头表（item header table）</strong><br><br><br>创建项头表的作用是为 FP 构建及频繁项集挖掘提供索引。这一步的流程是先扫描一遍数据集，对于满足最小支持度的单个项（K=1 项集）按照支持度从高到低进行排序，这个过程中删除了不满足最小支持度的项。项头表包括了项目、支持度，以及该项在 FP 树中的链表。初始的时候链表为空。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585753828193-fb2cd719-a0ba-4ff8-ae47-a1321a8065fb.png#align=left&display=inline&height=166&name=69ce07c61a654faafb4f5114df1557f5.png&originHeight=166&originWidth=485&size=16312&status=done&style=none&width=485" alt="69ce07c61a654faafb4f5114df1557f5.png"><br><br><br><strong>2. 构造 FP 树</strong><br><br><br>FP 树的根节点记为 NULL 节点。整个流程是需要再次扫描数据集，对于每一条数据，按照支持度从高到低的顺序进行创建节点（也就是第一步中项头表中的排序结果），节点如果存在就将计数 count+1，如果不存在就进行创建。同时在创建的过程中，需要更新项头表的链表。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585754477615-f0cc1aeb-f303-4170-aa56-9102a1f3717c.png#align=left&display=inline&height=976&name=image.png&originHeight=976&originWidth=2198&size=1341075&status=done&style=none&width=2198" alt="image.png"><br><br><br><strong>3. 通过 FP 树挖掘频繁项集</strong><br><br><br>到这里，我们就得到了一个存储频繁项集的 FP 树，以及一个项头表。我们可以通过项头表来挖掘出每个频繁项集。具体的操作会用到一个概念，叫“条件模式基”，它指的是以要挖掘的节点为叶子节点，自底向上求出 FP 子树，然后将 FP 子树的祖先节点设置为叶子节点之和。我以“啤酒”的节点为例，从 FP 树中可以得到一棵 FP 子树，将祖先节点的支持度记为叶子节点之和，得到：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585754623125-7a63f4af-3a40-4030-b56e-4ef0c3263815.png#align=left&display=inline&height=1130&name=image.png&originHeight=1130&originWidth=1332&size=630041&status=done&style=none&width=1332" alt="image.png"><br><br><br>你能看出来，相比于原来的 FP 树，尿布和牛奶的频繁项集数减少了。这是因为我们求得的是以“啤酒”为节点的 FP 子树，也就是说，在频繁项集中一定要含有“啤酒”这个项。<br><br><br>你可以再看下原始的数据，其中订单 1{牛奶、面包、尿布}和订单 5{牛奶、面包、尿布、可乐}并不存在“啤酒”这个项，所以针对订单 1，尿布→牛奶→面包这个项集就会从 FP 树中去掉，针对订单 5 也包括了尿布→牛奶→面包这个项集也会从 FP 树中去掉，所以你能看到以“啤酒”为节点的 FP 子树，尿布、牛奶、面包项集上的计数比原来少了 2。<br><br><br>条件模式基不包括“啤酒”节点，而且祖先节点如果小于最小支持度就会被剪枝，所以“啤酒”的条件模式基为空。同理，我们可以求得“面包”的条件模式基为：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585754761520-d88566ff-b066-4d0e-be2f-9aabe0352757.png#align=left&display=inline&height=754&name=41026c8f25b64b01125c8b8d6a19a113.png&originHeight=754&originWidth=724&size=288803&status=done&style=none&width=724" alt="41026c8f25b64b01125c8b8d6a19a113.png"><br><br><br>所以可以求得面包的频繁项集为{尿布，面包}，{尿布，牛奶，面包}。同样，我们还可以求得牛奶，尿布的频繁项集，这里就不再计算展示。<br></p><p><a name="yN64E"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br>今天我给你讲了 Apriori 算法，它是在“购物篮分析”中常用的关联规则挖掘算法，在 Apriori 算法中你最主要是需要明白支持度、置信度、提升度这几个概念，以及 Apriori 迭代计算频繁项集的工作流程。<br><br><br>Apriori 算法在实际工作中需要对数据集扫描多次，会消耗大量的计算时间，所以在 2000 年 FP-Growth 算法被提出来，它只需要扫描两次数据集即可以完成关联规则的挖掘。<br><br><br>FP-Growth 算法最主要的贡献就是提出了 FP 树和项头表，通过 FP 树减少了频繁项集的存储以及计算时间。当然 Apriori 的改进算法除了 FP-Growth 算法以外，还有 CBA 算法、GSP 算法，这里就不进行介绍。<br><br><br>你能发现一种新理论的提出，往往是先从最原始的概念出发，提出一种新的方法。原始概念最接近人们模拟的过程，但往往会存在空间和时间复杂度过高的情况。所以后面其他人会对这个方法做改进型的创新，重点是在空间和时间复杂度上进行降维，比如采用新型的数据结构。你能看出树在存储和检索中是一个非常好用的数据结构。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585755090342-5e94e16e-33a2-4d60-b886-2c5908be24a5.png#align=left&display=inline&height=849&name=c7aee3b17269139ed3d5a6b82cc56735.png&originHeight=849&originWidth=1552&size=380704&status=done&style=none&width=1552" alt="c7aee3b17269139ed3d5a6b82cc56735.png"><br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;关联规则这个概念，最早是由 Agrawal 等人在 1993 年提出的。在 1994 年 Agrawal 等人又提出了基于关联规则的 Aprio
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Apriori" scheme="cpeixin.cn/tags/Apriori/"/>
    
  </entry>
  
  <entry>
    <title>数据分析-关联规则 实战</title>
    <link href="cpeixin.cn/2019/03/01/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99-%E5%AE%9E%E6%88%98/"/>
    <id>cpeixin.cn/2019/03/01/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99-%E5%AE%9E%E6%88%98/</id>
    <published>2019-03-01T14:19:27.000Z</published>
    <updated>2020-04-05T14:30:52.019Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>昨天讲解了关联规则挖掘的原理。关联规则挖掘在生活中有很多使用场景，不仅是商品的捆绑销售，甚至在挑选演员决策上，你也能通过关联规则挖掘看出来某个导演选择演员的倾向。今天我来带你用 Apriori 算法做一个项目实战。<br><br><br>你需要掌握的是以下几点：<br></p><ul><li>熟悉上节课讲到的几个重要概念：支持度、置信度和提升度；</li><li>熟悉与掌握 Apriori 工具包的使用；</li><li>在实际问题中，灵活运用。包括数据集的准备等。</li></ul><p><a name="ZNoZJ"></a></p><h3 id="如何使用-Apriori"><a href="#如何使用-Apriori" class="headerlink" title="如何使用 Apriori"></a>如何使用 Apriori</h3><p><br>Apriori 虽然是十大算法之一，不过在 sklearn 工具包中并没有它，也没有 FP-Growth 算法。这里教你个方法，来选择 Python 中可以使用的工具包，你可以通过<a href="https://pypi.org/" target="_blank" rel="external nofollow noopener noreferrer">https://pypi.org/</a> 搜索工具包。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585838109422-3948da19-7f5e-439f-ae9f-53c4da519dd3.png#align=left&display=inline&height=767&name=image.png&originHeight=767&originWidth=1726&size=192193&status=done&style=none&width=1726" alt="image.png"><br><br><br>这个网站提供的工具包都是 Python 语言的，你能找到 8 个 Python 语言的 Apriori 工具包，具体选择哪个呢？建议你使用第二个工具包，即 efficient-apriori。后面我会讲到为什么推荐这个工具包。<br><br><br>首先你需要通过 pip install efficient-apriori 安装这个工具包。然后看下如何使用它，核心的代码就是这一行：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">itemsets, rules = apriori(data, min_support,  min_confidence)</span><br></pre></td></tr></table></figure><p><br>其中 data 是我们要提供的数据集，它是一个 list 数组类型。min_support 参数为最小支持度，在 efficient-apriori 工具包中用 0 到 1 的数值代表百分比，比如 0.5 代表最小支持度为 50%。min_confidence 是最小置信度，数值也代表百分比，比如 1 代表 100%。<br></p><blockquote><p>一般来说最小支持度常见的取值有0.5，0.1, 0.05。最小置信度常见的取值有1.0, 0.9, 0.8。可以通过尝试一些取值，然后观察关联结果的方式来调整最小值尺度和最小置信度的取值。</p></blockquote><p><br>关于支持度、置信度和提升度，我们再来简单回忆下。<br><br><br>支持度指的是某个商品组合出现的次数与总次数之间的比例。支持度越高，代表这个组合出现的概率越大。<br><br><br>置信度是一个条件概念，就是在 A 发生的情况下，B 发生的概率是多少。<br><br><br>提升度代表的是“商品 A 的出现，对商品 B 的出现概率提升了多少”。<br><br><br>接下来我们用这个工具包，跑一下上节课中讲到的超市购物的例子。下面是客户购买的商品列表：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585838224965-bc422cf1-7921-43d2-893c-46fff07a69a9.png#align=left&display=inline&height=202&name=image.png&originHeight=202&originWidth=476&size=27188&status=done&style=none&width=476" alt="image.png"><br><br><br>具体实现的代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> efficient_apriori <span class="keyword">import</span> apriori</span><br><span class="line"><span class="comment"># 设置数据集</span></span><br><span class="line">data = [(<span class="string">'牛奶'</span>,<span class="string">'面包'</span>,<span class="string">'尿布'</span>),</span><br><span class="line">           (<span class="string">'可乐'</span>,<span class="string">'面包'</span>, <span class="string">'尿布'</span>, <span class="string">'啤酒'</span>),</span><br><span class="line">           (<span class="string">'牛奶'</span>,<span class="string">'尿布'</span>, <span class="string">'啤酒'</span>, <span class="string">'鸡蛋'</span>),</span><br><span class="line">           (<span class="string">'面包'</span>, <span class="string">'牛奶'</span>, <span class="string">'尿布'</span>, <span class="string">'啤酒'</span>),</span><br><span class="line">           (<span class="string">'面包'</span>, <span class="string">'牛奶'</span>, <span class="string">'尿布'</span>, <span class="string">'可乐'</span>)]</span><br><span class="line"><span class="comment"># 挖掘频繁项集和频繁规则</span></span><br><span class="line">itemsets, rules = apriori(data, min_support=<span class="number">0.5</span>,  min_confidence=<span class="number">1</span>)</span><br><span class="line">print(itemsets)</span><br><span class="line">print(rules)</span><br></pre></td></tr></table></figure><p><br>结果：<br></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&#123;<span class="number">1</span>: &#123;(<span class="string">'啤酒'</span>,): <span class="number">3</span>, (<span class="string">'尿布'</span>,): <span class="number">5</span>, (<span class="string">'牛奶'</span>,): <span class="number">4</span>, (<span class="string">'面包'</span>,): <span class="number">4</span>&#125;, <span class="number">2</span>: &#123;(<span class="string">'啤酒'</span>, <span class="string">'尿布'</span>): <span class="number">3</span>, (<span class="string">'尿布'</span>, <span class="string">'牛奶'</span>): <span class="number">4</span>, (<span class="string">'尿布'</span>, <span class="string">'面包'</span>): <span class="number">4</span>, (<span class="string">'牛奶'</span>, <span class="string">'面包'</span>): <span class="number">3</span>&#125;, <span class="number">3</span>: &#123;(<span class="string">'尿布'</span>, <span class="string">'牛奶'</span>, <span class="string">'面包'</span>): <span class="number">3</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line">[&#123;啤酒&#125; -&gt; &#123;尿布&#125;, &#123;牛奶&#125; -&gt; &#123;尿布&#125;, &#123;面包&#125; -&gt; &#123;尿布&#125;, &#123;牛奶, 面包&#125; -&gt; &#123;尿布&#125;]</span><br></pre></td></tr></table></figure><p><br>你能从代码中看出来，data 是个 List 数组类型，其中每个值都可以是一个集合。实际上你也可以把 data 数组中的每个值设置为 List 数组类型，比如：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">data = [[<span class="string">'牛奶'</span>,<span class="string">'面包'</span>,<span class="string">'尿布'</span>],</span><br><span class="line">           [<span class="string">'可乐'</span>,<span class="string">'面包'</span>, <span class="string">'尿布'</span>, <span class="string">'啤酒'</span>],</span><br><span class="line">           [<span class="string">'牛奶'</span>,<span class="string">'尿布'</span>, <span class="string">'啤酒'</span>, <span class="string">'鸡蛋'</span>],</span><br><span class="line">           [<span class="string">'面包'</span>, <span class="string">'牛奶'</span>, <span class="string">'尿布'</span>, <span class="string">'啤酒'</span>],</span><br><span class="line">           [<span class="string">'面包'</span>, <span class="string">'牛奶'</span>, <span class="string">'尿布'</span>, <span class="string">'可乐'</span>]]</span><br></pre></td></tr></table></figure><p><br>两者的运行结果是一样的，efficient-apriori 工具包把每一条数据集里的项式都放到了一个集合中进行运算，并没有考虑它们之间的先后顺序。<strong>因为实际情况下，同一个购物篮中的物品也不需要考虑购买的先后顺序。而其他的 Apriori 算法可能会因为考虑了先后顺序，出现计算频繁项集结果不对的情况。所以这里采用的是 efficient-apriori 这个工具包。</strong><br>**<br><a name="ajpzD"></a></p><h3 id="挖掘-导演是如何选择演员"><a href="#挖掘-导演是如何选择演员" class="headerlink" title="挖掘-导演是如何选择演员"></a>挖掘-导演是如何选择演员</h3><p><br>在实际工作中，数据集是需要自己来准备的，比如今天我们要挖掘导演是如何选择演员的数据情况，但是并没有公开的数据集可以直接使用。因此我们需要使用之前讲到的 Python 爬虫进行数据采集。不同导演选择演员的规则是不同的，因此我们需要先指定导演。数据源我们选用豆瓣电影。先来梳理下采集的工作流程。首先我们先在<a href="https://movie.douban.com搜索框中输入导演姓名，比如“宁浩”。" target="_blank" rel="external nofollow noopener noreferrer">https://movie.douban.com搜索框中输入导演姓名，比如“宁浩”。</a><br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585838710307-db035b28-c32f-4010-bf42-fb3d28c527dc.png#align=left&display=inline&height=1150&name=image.png&originHeight=1150&originWidth=1728&size=524786&status=done&style=none&width=1728" alt="image.png"><br><br><br>页面会呈现出来导演之前的所有电影，然后对页面进行观察，你能观察到以下几个现象：</p><ol><li>页面默认是 15 条数据反馈，第一页会返回 16 条。因为第一条数据实际上这个导演的概览，你可以理解为是一条广告的插入，下面才是真正的返回结果。</li><li>每条数据的最后一行是电影的演出人员的信息，第一个人员是导演，其余为演员姓名。姓名之间用“/”分割。有了这些观察之后，我们就可以编写抓取程序了。</li></ol><p><br>在代码讲解中你能看出这两点观察的作用。抓取程序的目的是为了生成宁浩导演（你也可以抓取其他导演）的数据集，结果会保存在 csv 文件中。完整的抓取代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 下载某个导演的电影数据集</span></span><br><span class="line"><span class="keyword">from</span> efficient_apriori <span class="keyword">import</span> apriori</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">driver = webdriver.Chrome()</span><br><span class="line"><span class="comment"># 设置想要下载的导演 数据集</span></span><br><span class="line">director = <span class="string">u'宁浩'</span></span><br><span class="line"><span class="comment"># 写CSV文件</span></span><br><span class="line">file_name = <span class="string">'./'</span> + director + <span class="string">'.csv'</span></span><br><span class="line">base_url = <span class="string">'https://movie.douban.com/subject_search?search_text='</span>+director+<span class="string">'&amp;cat=1002&amp;start='</span></span><br><span class="line">out = open(file_name,<span class="string">'w'</span>, newline=<span class="string">''</span>, encoding=<span class="string">'utf-8-sig'</span>)</span><br><span class="line">csv_write = csv.writer(out, dialect=<span class="string">'excel'</span>)</span><br><span class="line">flags=[]</span><br><span class="line"><span class="comment"># 下载指定页面的数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(request_url)</span>:</span></span><br><span class="line">  driver.get(request_url)</span><br><span class="line">  time.sleep(<span class="number">1</span>)</span><br><span class="line">  html = driver.find_element_by_xpath(<span class="string">"//*"</span>).get_attribute(<span class="string">"outerHTML"</span>)</span><br><span class="line">  html = etree.HTML(html)</span><br><span class="line">  <span class="comment"># 设置电影名称，导演演员 的XPATH</span></span><br><span class="line">  movie_lists = html.xpath(<span class="string">"/html/body/div[@id='wrapper']/div[@id='root']/div[1]//div[@class='item-root']/div[@class='detail']/div[@class='title']/a[@class='title-text']"</span>)</span><br><span class="line">  name_lists = html.xpath(<span class="string">"/html/body/div[@id='wrapper']/div[@id='root']/div[1]//div[@class='item-root']/div[@class='detail']/div[@class='meta abstract_2']"</span>)</span><br><span class="line">  <span class="comment"># 获取返回的数据个数</span></span><br><span class="line">  num = len(movie_lists)</span><br><span class="line">  <span class="keyword">if</span> num &gt; <span class="number">15</span>: <span class="comment">#第一页会有16条数据</span></span><br><span class="line">    <span class="comment"># 默认第一个不是，所以需要去掉</span></span><br><span class="line">    movie_lists = movie_lists[<span class="number">1</span>:]</span><br><span class="line">    name_lists = name_lists[<span class="number">1</span>:]</span><br><span class="line">  <span class="keyword">for</span> (movie, name_list) <span class="keyword">in</span> zip(movie_lists, name_lists):</span><br><span class="line">    <span class="comment"># 会存在数据为空的情况</span></span><br><span class="line">    <span class="keyword">if</span> name_list.text <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    <span class="comment"># 显示下演员名称</span></span><br><span class="line">    print(name_list.text)</span><br><span class="line">    names = name_list.text.split(<span class="string">'/'</span>)</span><br><span class="line">    <span class="comment"># 判断导演是否为指定的director</span></span><br><span class="line">    <span class="keyword">if</span> names[<span class="number">0</span>].strip() == director <span class="keyword">and</span> movie.text <span class="keyword">not</span> <span class="keyword">in</span> flags:</span><br><span class="line">      <span class="comment"># 将第一个字段设置为电影名称</span></span><br><span class="line">      names[<span class="number">0</span>] = movie.text</span><br><span class="line">      flags.append(movie.text)</span><br><span class="line">      csv_write.writerow(names)</span><br><span class="line">  print(<span class="string">'OK'</span>) <span class="comment"># 代表这页数据下载成功</span></span><br><span class="line">  print(num)</span><br><span class="line">  <span class="keyword">if</span> num &gt;= <span class="number">14</span>: <span class="comment">#有可能一页会有14个电影</span></span><br><span class="line">    <span class="comment"># 继续下一页</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 没有下一页</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始的ID为0，每页增加15</span></span><br><span class="line">start = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> start&lt;<span class="number">10000</span>: <span class="comment">#最多抽取1万部电影</span></span><br><span class="line">  request_url = base_url + str(start)</span><br><span class="line">  <span class="comment"># 下载数据，并返回是否有下一页</span></span><br><span class="line">  flag = download(request_url)</span><br><span class="line">  <span class="keyword">if</span> flag:</span><br><span class="line">    start = start + <span class="number">15</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">out.close()</span><br><span class="line">print(<span class="string">'finished'</span>)</span><br></pre></td></tr></table></figure><p><br>爬取的代码在这里就不赘述了，其中有一点就是这里用到了selenium模拟打开窗口爬取。<br><br><br>下面是爬取下来的数据：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585838880690-4b759b67-2067-43c2-ae2c-a56d868a5553.png#align=left&display=inline&height=411&name=image.png&originHeight=411&originWidth=1729&size=161621&status=done&style=none&width=1729" alt="image.png"><br><br><br>我们用获取到的少量宁浩数据，来做一次关联规则分析：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> efficient_apriori <span class="keyword">import</span> apriori</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">director = <span class="string">u'宁浩'</span></span><br><span class="line">file_name = <span class="string">'./'</span>+director+<span class="string">'.csv'</span></span><br><span class="line">lists = csv.reader(open(file_name, <span class="string">'r'</span>, encoding=<span class="string">'utf-8-sig'</span>))</span><br><span class="line"><span class="comment"># 数据加载</span></span><br><span class="line">data = []</span><br><span class="line"><span class="keyword">for</span> names <span class="keyword">in</span> lists:</span><br><span class="line">     name_new = []</span><br><span class="line">     <span class="keyword">for</span> name <span class="keyword">in</span> names:</span><br><span class="line">           <span class="comment"># 去掉演员数据中的空格</span></span><br><span class="line">           name_new.append(name.strip())</span><br><span class="line">     data.append(name_new[<span class="number">1</span>:])</span><br><span class="line"><span class="comment"># 挖掘频繁项集和关联规则</span></span><br><span class="line">itemsets, rules = apriori(data, min_support=<span class="number">0.5</span>,  min_confidence=<span class="number">1</span>)</span><br><span class="line">print(itemsets)</span><br><span class="line">print(rules)</span><br></pre></td></tr></table></figure><p><br>代码中使用的 apriori 方法和开头中用 Apriori 获取购物篮规律的方法类似，比如代码中都设定了最小支持度和最小置信系数，这样我们可以找到支持度大于 50%，置信系数为 1 的频繁项集和关联规则。这是最后的运行结果：<br></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="number">1</span>: &#123;(<span class="string">'徐峥'</span>,): <span class="number">5</span>, (<span class="string">'黄渤'</span>,): <span class="number">6</span>&#125;, <span class="number">2</span>: &#123;(<span class="string">'徐峥'</span>, <span class="string">'黄渤'</span>): <span class="number">5</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line">[&#123;徐峥&#125; -&gt; &#123;黄渤&#125;]</span><br></pre></td></tr></table></figure><p><br>你能看出来，宁浩导演喜欢用徐峥和黄渤，并且有徐峥的情况下，一般都会用黄渤。你也可以用上面的代码来挖掘下其他导演选择演员的规律。<br></p><p><a name="TXA7M"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br><strong>Apriori 算法的核心就是理解频繁项集和关联规则</strong>。<br><br><br>在算法运算的过程中，还要重点掌握对支持度、置信度和提升度的理解。<br><br><br>在工具使用上，你可以使用 efficient-apriori 这个工具包，它会把每一条数据中的项（item）放到一个集合（篮子）里来处理，不考虑项（item）之间的先后顺序。<br><br><br>在实际运用中你还需要灵活处理，比如导演如何选择演员这个案例，虽然工具的使用会很方便，但重要的还是数据挖掘前的准备过程，也就是获取某个导演的电影数据集。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585839157353-5f4a763c-6e42-4c05-a9ec-50d9cabb3684.png#align=left&display=inline&height=509&name=282c25e8651b3e0b675be7267d13629d.png&originHeight=509&originWidth=1727&size=206986&status=done&style=none&width=1727" alt="282c25e8651b3e0b675be7267d13629d.png"><br><br><br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;昨天讲解了关联规则挖掘的原理。关联规则挖掘在生活中有很多使用场景，不仅是商品的捆绑销售，甚至在挑选演员决策上，你也能通过关联规则挖掘看出来某个导
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Apriori" scheme="cpeixin.cn/tags/Apriori/"/>
    
  </entry>
  
  <entry>
    <title>数据分析 - EM聚类 实战</title>
    <link href="cpeixin.cn/2019/02/18/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-EM%E8%81%9A%E7%B1%BB-%E5%AE%9E%E6%88%98/"/>
    <id>cpeixin.cn/2019/02/18/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-EM%E8%81%9A%E7%B1%BB-%E5%AE%9E%E6%88%98/</id>
    <published>2019-02-18T14:18:53.000Z</published>
    <updated>2020-04-05T14:30:47.934Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>今天进行 EM 的实战。上篇讲了 EM 算法的原理，EM 算法相当于一个聚类框架，里面有不同的聚类模型，比如 GMM 高斯混合模型，或者 HMM 隐马尔科夫模型。<br><br><br>其中你需要理解的是 EM 的两个步骤，E 步和 M 步：E 步相当于通过初始化的参数来估计隐含变量，M 步是通过隐含变量来反推优化参数。最后通过 EM 步骤的迭代得到最终的模型参数。<br><br><br>今天我们进行 EM 算法的实战，你需要思考的是：<br>如何使用 EM 算法工具完成聚类？<br>什么情况下使用聚类算法？<br>我们用聚类算法的任务目标是什么？<br><br><br>面对王者荣耀的英雄数据，EM 算法能帮助我们分析出什么？<br></p><p><a name="MGdE6"></a></p><h3 id="如何使用-EM-工具包"><a href="#如何使用-EM-工具包" class="headerlink" title="如何使用 EM 工具包"></a>如何使用 EM 工具包</h3><p><br>在 Python 中有第三方的 EM 算法工具包。由于 EM 算法是一个聚类框架，所以你需要明确你要用的具体算法，比如是采用 GMM 高斯混合模型，还是 HMM 隐马尔科夫模型。这节课我们主要讲解 GMM 的使用，在使用前你需要引入工具包：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br></pre></td></tr></table></figure><p><br>我们看下如何在 sklearn 中创建 GMM 聚类。<br><br><br>首先我们使用 gmm = GaussianMixture(n_components=1, covariance_type=‘full’, max_iter=100) 来创建 GMM 聚类，其中有几个比较主要的参数（GMM 类的构造参数比较多，我筛选了一些主要的进行讲解），我分别来讲解下：<br><br><br>1.n_components：即高斯混合模型的个数，也就是我们要聚类的个数，默认值为 1。如果你不指定 n_components，最终的聚类结果都会为同一个值。<br><br><br>2.covariance_type：代表协方差类型。一个高斯混合模型的分布是由均值向量和协方差矩阵决定的，所以协方差的类型也代表了不同的高斯混合模型的特征。协方差类型有 4 种取值：</p><ul><li>covariance_type=full，代表完全协方差，也就是元素都不为 0；</li><li>covariance_type=tied，代表相同的完全协方差；</li><li>covariance_type=diag，代表对角协方差，也就是对角不为 0，其余为 0；</li><li>covariance_type=spherical，代表球面协方差，非对角为 0，对角完全相同，呈现球面的特性。</li></ul><p><br>3.max_iter：代表最大迭代次数，EM 算法是由 E 步和 M 步迭代求得最终的模型参数，这里可以指定最大迭代次数，默认值为 100。创建完 GMM 聚类器之后，我们就可以传入数据让它进行迭代拟合。我们使用 fit 函数，传入样本特征矩阵，模型会自动生成聚类器，然后使用 prediction=gmm.predict(data) 来对数据进行聚类，传入你想进行聚类的数据，可以得到聚类结果 prediction。<br><br><br>你能看出来拟合训练和预测可以传入相同的特征矩阵，这是因为聚类是无监督学习，你不需要事先指定聚类的结果，也无法基于先验的结果经验来进行学习。只要在训练过程中传入特征值矩阵，机器就会按照特征值矩阵生成聚类器，然后就可以使用这个聚类器进行聚类了。<br></p><p><a name="GUfM0"></a></p><h3 id="如何用-EM-算法对王者荣耀数据进行聚类"><a href="#如何用-EM-算法对王者荣耀数据进行聚类" class="headerlink" title="如何用 EM 算法对王者荣耀数据进行聚类"></a>如何用 EM 算法对王者荣耀数据进行聚类</h3><p><br>了解了 GMM 聚类工具之后，我们看下如何对王者荣耀的英雄数据进行聚类。首先我们知道聚类的原理是“人以群分，物以类聚”。通过聚类算法把特征值相近的数据归为一类，不同类之间的差异较大，这样就可以对原始数据进行降维。通过分成几个组（簇），来研究每个组之间的特性。或者我们也可以把组（簇）的数量适当提升，这样就可以找到可以互相替换的英雄，比如你的对手选择了你擅长的英雄之后，你可以选择另一个英雄作为备选。我们先看下数据长什么样子：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585581142741-2923fa33-e84e-4c7d-b15d-d6bf6f8c8ec8.png#align=left&display=inline&height=396&name=3c4e14e7b33fc211f96fe0108f6196a0.png&originHeight=396&originWidth=1726&size=159767&status=done&style=none&width=1726" alt="3c4e14e7b33fc211f96fe0108f6196a0.png"><br><br><br>这里我们收集了 69 名英雄的 20 个特征属性，这些属性分别是最大生命、生命成长、初始生命、最大法力、法力成长、初始法力、最高物攻、物攻成长、初始物攻、最大物防、物防成长、初始物防、最大每 5 秒回血、每 5 秒回血成长、初始每 5 秒回血、最大每 5 秒回蓝、每 5 秒回蓝成长、初始每 5 秒回蓝、最大攻速和攻击范围等。<br><br><br>现在我们需要对王者荣耀的英雄数据进行聚类，我们先设定项目的执行流程：<br><br><br>首先我们需要加载数据源；在准备阶段，我们需要对数据进行探索，包括采用数据可视化技术，让我们对英雄属性以及这些属性之间的关系理解更加深刻，然后对数据质量进行评估，是否进行数据清洗，最后进行特征选择方便后续的聚类算法；<br><br><br>聚类阶段：选择适合的聚类模型，这里我们采用 GMM 高斯混合模型进行聚类，并输出聚类结果，对结果进行分析。按照上面的步骤，我们来编写下代码。完整的代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 数据加载，避免中文乱码问题</span></span><br><span class="line">data_ori = pd.read_csv(<span class="string">'./heros7.csv'</span>, encoding = <span class="string">'gb18030'</span>)</span><br><span class="line">features = [<span class="string">u'最大生命'</span>,<span class="string">u'生命成长'</span>,<span class="string">u'初始生命'</span>,<span class="string">u'最大法力'</span>, <span class="string">u'法力成长'</span>,<span class="string">u'初始法力'</span>,<span class="string">u'最高物攻'</span>,<span class="string">u'物攻成长'</span>,<span class="string">u'初始物攻'</span>,<span class="string">u'最大物防'</span>,<span class="string">u'物防成长'</span>,<span class="string">u'初始物防'</span>, <span class="string">u'最大每5秒回血'</span>, <span class="string">u'每5秒回血成长'</span>, <span class="string">u'初始每5秒回血'</span>, <span class="string">u'最大每5秒回蓝'</span>, <span class="string">u'每5秒回蓝成长'</span>, <span class="string">u'初始每5秒回蓝'</span>, <span class="string">u'最大攻速'</span>, <span class="string">u'攻击范围'</span>]</span><br><span class="line">data = data_ori[features]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 对英雄属性之间的关系进行可视化分析</span></span><br><span class="line"><span class="comment"># 设置plt正确显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>]=[<span class="string">'SimHei'</span>] <span class="comment">#用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="literal">False</span> <span class="comment">#用来正常显示负号</span></span><br><span class="line"><span class="comment"># 用热力图呈现features_mean字段之间的相关性</span></span><br><span class="line">corr = data[features].corr()</span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">14</span>))</span><br><span class="line"><span class="comment"># annot=True显示每个方格的数据</span></span><br><span class="line">sns.heatmap(corr, annot=<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 相关性大的属性保留一个，因此可以对属性进行降维</span></span><br><span class="line">features_remain = [<span class="string">u'最大生命'</span>, <span class="string">u'初始生命'</span>, <span class="string">u'最大法力'</span>, <span class="string">u'最高物攻'</span>, <span class="string">u'初始物攻'</span>, <span class="string">u'最大物防'</span>, <span class="string">u'初始物防'</span>, <span class="string">u'最大每5秒回血'</span>, <span class="string">u'最大每5秒回蓝'</span>, <span class="string">u'初始每5秒回蓝'</span>, <span class="string">u'最大攻速'</span>, <span class="string">u'攻击范围'</span>]</span><br><span class="line">data = data_ori[features_remain]</span><br><span class="line">data[<span class="string">u'最大攻速'</span>] = data[<span class="string">u'最大攻速'</span>].apply(<span class="keyword">lambda</span> x: float(x.strip(<span class="string">'%'</span>))/<span class="number">100</span>)</span><br><span class="line">data[<span class="string">u'攻击范围'</span>]=data[<span class="string">u'攻击范围'</span>].map(&#123;<span class="string">'远程'</span>:<span class="number">1</span>,<span class="string">'近战'</span>:<span class="number">0</span>&#125;)</span><br><span class="line"><span class="comment"># 采用Z-Score规范化数据，保证每个特征维度的数据均值为0，方差为1</span></span><br><span class="line">ss = StandardScaler()</span><br><span class="line">data = ss.fit_transform(data)</span><br><span class="line"><span class="comment"># 构造GMM聚类</span></span><br><span class="line">gmm = GaussianMixture(n_components=<span class="number">30</span>, covariance_type=<span class="string">'full'</span>)</span><br><span class="line">gmm.fit(data)</span><br><span class="line"><span class="comment"># 训练数据</span></span><br><span class="line">prediction = gmm.predict(data)</span><br><span class="line">print(prediction)</span><br><span class="line"><span class="comment"># 将分组结果输出到CSV文件中</span></span><br><span class="line">data_ori.insert(<span class="number">0</span>, <span class="string">'分组'</span>, prediction)</span><br><span class="line">data_ori.to_csv(<span class="string">'./hero_out.csv'</span>, index=<span class="literal">False</span>, sep=<span class="string">','</span>)</span><br></pre></td></tr></table></figure><p><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585581441251-8cc5e460-f96a-4e02-aac0-f1453cf6e55c.png#align=left&display=inline&height=1396&name=dbe96b767d7f3ff2dd9f44b651cde8fb.png&originHeight=1396&originWidth=1729&size=694331&status=done&style=none&width=1729" alt="dbe96b767d7f3ff2dd9f44b651cde8fb.png"><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[28 14  8  9  5  5 15  8  3 14 18 14  9  7 16 18 13  3  5  4 19 12  4 12</span><br><span class="line"> 12 12  4 17 24  2  7  2  2 24  2  2 24  6 20 22 22 24 24  2  2 22 14 20</span><br><span class="line"> 14 24 26 29 27 25 25 28 11  1 23  5 11  0 10 28 21 29 29 29 17]</span><br></pre></td></tr></table></figure><p><br>同时你也能看到输出的聚类结果文件 hero_out.csv（它保存在你本地运行的文件夹里，程序会自动输出这个文件，你可以自己看下）。我来简单讲解下程序的几个模块。<br></p><p><a name="NxDzi"></a></p><h3 id="关于引用包首"><a href="#关于引用包首" class="headerlink" title="关于引用包首"></a>关于引用包首</h3><p><br>先我们会用 DataFrame 数据结构来保存读取的数据，最后的聚类结果会写入到 CSV 文件中，因此会用到 pandas 和 CSV 工具包。<br><br><br>另外我们需要对数据进行可视化，采用热力图展现属性之间的相关性，这里会用到 matplotlib.pyplot 和 seaborn 工具包。在数据规范化中我们使用到了 Z-Score 规范化，用到了 StandardScaler 类，最后我们还会用到 sklearn 中的 GaussianMixture 类进行聚类。<br></p><p><a name="oz4qU"></a></p><h3 id="数据可视化的探索"><a href="#数据可视化的探索" class="headerlink" title="数据可视化的探索"></a>数据可视化的探索</h3><p><br>你能看到我们将 20 个英雄属性之间的关系用热力图呈现了出来，中间的数字代表两个属性之间的关系系数，最大值为 1，代表完全正相关，关系系数越大代表相关性越大。从图中你能看出来“最大生命”“生命成长”和“初始生命”这三个属性的相关性大，我们只需要保留一个属性即可。同理我们也可以对其他相关性大的属性进行筛选，保留一个。你在代码中可以看到，我用 features_remain 数组保留了特征选择的属性，这样就将原本的 20 个属性降维到了 13 个属性。<br></p><p><a name="yY6Go"></a></p><h3 id="关于数据规范化"><a href="#关于数据规范化" class="headerlink" title="关于数据规范化"></a>关于数据规范化</h3><p><br>我们能看到“最大攻速”这个属性值是百分数，不适合做矩阵运算，因此我们需要将百分数转化为小数。我们也看到“攻击范围”这个字段的取值为远程或者近战，也不适合矩阵运算，我们将取值做个映射，用 1 代表远程，0 代表近战。然后采用 Z-Score 规范化，对特征矩阵进行规范化。<br></p><p><a name="QjcZZ"></a></p><h3 id="在聚类阶段"><a href="#在聚类阶段" class="headerlink" title="在聚类阶段"></a>在聚类阶段</h3><p><br>我们采用了 GMM 高斯混合模型，并将结果输出到 CSV 文件中。这里我将输出的结果截取了一段（设置聚类个数为 30）：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585581772770-f1e277eb-e09a-4f80-a541-440092e9d41a.png#align=left&display=inline&height=446&name=image.png&originHeight=446&originWidth=1262&size=69995&status=done&style=none&width=1262" alt="image.png"><br><br><br>第一列代表的是分组（簇），我们能看到张飞、程咬金分到了一组，牛魔、白起是一组，老夫子自己是一组，达摩、典韦是一组。<br><br><br>聚类的特点是相同类别之间的属性值相近，不同类别的属性值差异大。因此如果你擅长用典韦这个英雄，不防试试达摩这个英雄。同样你也可以在张飞和程咬金中进行切换。这样就算你的英雄被别人选中了，你依然可以有备选的英雄可以使用。<br></p><p><a name="08ZDG"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br>今天我带你一起做了 EM 聚类的实战，具体使用的是 GMM 高斯混合模型。从整个流程中可以看出，我们需要经过数据加载、数据探索、数据可视化、特征选择、GMM 聚类和结果分析等环节。聚类和分类不一样，<strong>聚类是无监督的学习方式</strong>，也就是我们没有实际的结果可以进行比对，所以聚类的结果评估不像分类准确率一样直观，那么有没有聚类结果的评估方式呢？这里我们可以采用 Calinski-Harabaz 指标，代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> calinski_harabaz_score</span><br><span class="line">print(calinski_harabaz_score(data, prediction))</span><br></pre></td></tr></table></figure><p><br>指标分数越高，代表聚类效果越好，也就是相同类中的差异性小，不同类之间的差异性大。当然具体聚类的结果含义，我们需要人工来分析，也就是当这些数据被分成不同的类别之后，具体每个类表代表的含义。另外聚类算法也可以作为其他数据挖掘算法的预处理阶段，这样我们就可以将数据进行降维了。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585582063729-9c938ad2-7839-41e3-a1f6-98ee4102e29e.png#align=left&display=inline&height=984&name=43b35b8f49ac83799ea1ca88383609d7.png&originHeight=984&originWidth=1729&size=384377&status=done&style=none&width=1729" alt="43b35b8f49ac83799ea1ca88383609d7.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;今天进行 EM 的实战。上篇讲了 EM 算法的原理，EM 算法相当于一个聚类框架，里面有不同的聚类模型，比如 GMM 高斯混合模型，或者 HMM
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="EM" scheme="cpeixin.cn/tags/EM/"/>
    
  </entry>
  
  <entry>
    <title>数据分析 - EM聚类</title>
    <link href="cpeixin.cn/2019/02/15/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-EM%E8%81%9A%E7%B1%BB/"/>
    <id>cpeixin.cn/2019/02/15/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-EM%E8%81%9A%E7%B1%BB/</id>
    <published>2019-02-15T14:18:39.000Z</published>
    <updated>2020-04-05T14:30:45.641Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>今天要来学习 EM 聚类。EM 的英文是 Expectation Maximization，所以 EM 算法也叫最大期望算法。<br><br><br>我们先看一个简单的场景：假设你炒了一份菜，想要把它平均分到两个碟子里，该怎么分？很少有人用称对菜进行称重，再计算一半的分量进行平分。<br><br><br>大部分人的方法是先分一部分到碟子 A 中，然后再把剩余的分到碟子 B 中，再来观察碟子 A 和 B 里的菜是否一样多，哪个多就匀一些到少的那个碟子里，然后再观察碟子 A 和 B 里的是否一样多……整个过程一直重复下去，直到份量不发生变化为止。<br><br><br>你能从这个例子中看到三个主要的步骤：初始化参数、观察预期、重新估计。首先是先给每个碟子初始化一些菜量，然后再观察预期，这两个步骤实际上就是期望步骤（Expectation）。如果结果存在偏差就需要重新估计参数，这个就是最大化步骤（Maximization）。这两个步骤加起来也就是 EM 算法的过程。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1585579694839-61e15913-43c5-422b-9cd9-998ac1a34a08.jpeg#align=left&display=inline&height=711&name=91f617ac484a7de011108ae99bd8cb3c.jpg&originHeight=711&originWidth=1842&size=144489&status=done&style=none&width=1842" alt="91f617ac484a7de011108ae99bd8cb3c.jpg"><br></p><p><a name="eJkPo"></a></p><h3 id="EM-算法的工作原理"><a href="#EM-算法的工作原理" class="headerlink" title="EM 算法的工作原理"></a>EM 算法的工作原理</h3><p><br>说到 EM 算法，我们先来看一个概念“最大似然”，英文是 Maximum Likelihood，Likelihood 代表可能性，所以最大似然也就是最大可能性的意思。<br><br><br>什么是最大似然呢？举个例子，有一男一女两个同学，现在要对他俩进行身高的比较，谁会更高呢？根据我们的经验，相同年龄下男性的平均身高比女性的高一些，所以男同学高的可能性会很大。这里运用的就是最大似然的概念。<br><br><br>最大似然估计是什么呢？它指的就是一件事情已经发生了，然后反推更有可能是什么因素造成的。还是用一男一女比较身高为例，假设有一个人比另一个人高，反推他可能是男性。最大似然估计是一种通过已知结果，估计参数的方法。<br><br><br>那么 EM 算法是什么？它和最大似然估计又有什么关系呢？EM 算法是一种求解最大似然估计的方法，通过观测样本，来找出样本的模型参数。再回过来看下开头我给你举的分菜的这个例子，实际上最终我们想要的是碟子 A 和碟子 B 中菜的份量，你可以把它们理解为想要求得的模型参数。然后我们通过 EM 算法中的 E 步来进行观察，然后通过 M 步来进行调整 A 和 B 的参数，最后让碟子 A 和碟子 B 的参数不再发生变化为止。实际我们遇到的问题，比分菜复杂。我再给你举个一个投掷硬币的例子，假设我们有 A 和 B 两枚硬币，我们做了 5 组实验，每组实验投掷 10 次，然后统计出现正面的次数，实验结果如下：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585579902137-c107e92c-d000-493c-b08e-a95396729269.png#align=left&display=inline&height=197&name=c8b3f2489735a21ad86d05fb9e8c0de4.png&originHeight=197&originWidth=471&size=15123&status=done&style=none&width=471" alt="c8b3f2489735a21ad86d05fb9e8c0de4.png"><br><br><br>投掷硬币这个过程中存在隐含的数据，即我们事先并不知道每次投掷的硬币是 A 还是 B。假设我们知道这个隐含的数据，并将它完善，可以得到下面的结果：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585579940461-9300ad99-021b-4513-8b39-eb958df65148.png#align=left&display=inline&height=198&name=91eace1de7799a2d2d392908b462730d.png&originHeight=198&originWidth=484&size=18518&status=done&style=none&width=484" alt="91eace1de7799a2d2d392908b462730d.png"><br><br><br>我们现在想要求得硬币 A 和 B 出现正面次数的概率，可以直接求得：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585580000560-b6093c13-d436-431f-ad9f-9d997fce19cd.png#align=left&display=inline&height=56&name=image.png&originHeight=56&originWidth=320&size=11906&status=done&style=none&width=320" alt="image.png"><br>而实际情况是我不知道每次投掷的硬币是 A 还是 B，那么如何求得硬币 A 和硬币 B 出现正面的概率呢？这里就需要采用 EM 算法的思想。<br>1. 初始化参数。我们假设硬币 A 和 B 的正面概率（随机指定）是θA=0.5 和θB=0.9。<br><br><br>2. 计算期望值。假设实验 1 投掷的是硬币 A，那么正面次数为 5 的概率为：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585580082277-c4a68b6a-7620-4846-82f4-9cba3b689785.png#align=left&display=inline&height=39&name=7b1bab8bf4eecb0c55b34fb8049374f6.png&originHeight=39&originWidth=212&size=10115&status=done&style=none&width=212" alt="7b1bab8bf4eecb0c55b34fb8049374f6.png"><br><br><br>所以实验 1 更有可能投掷的是硬币 A。<br>然后我们对实验 2~5 重复上面的计算过程，可以推理出来硬币顺序应该是{A，A，B，B，A}。这个过程实际上是通过假设的参数来估计未知参数，即“每次投掷是哪枚硬币”。<br><br><br>3. 通过猜测的结果{A, A, B, B, A}来完善初始化的参数θA 和θB。然后一直重复第二步和第三步，直到参数不再发生变化。简单总结下上面的步骤，你能看出 EM 算法中的 E 步骤就是通过旧的参数来计算隐藏变量。然后在 M 步骤中，通过得到的隐藏变量的结果来重新估计参数。直到参数不再发生变化，得到我们想要的结果。<br></p><p><a name="fjxPq"></a></p><h3 id="EM-聚类的工作原理"><a href="#EM-聚类的工作原理" class="headerlink" title="EM 聚类的工作原理"></a>EM 聚类的工作原理</h3><p><br>上面你能看到 EM 算法最直接的应用就是求参数估计。如果我们把潜在类别当做隐藏变量，样本看做观察值，就可以把聚类问题转化为参数估计问题。这也就是 EM 聚类的原理。相比于 K-Means 算法，EM 聚类更加灵活，比如下面这两种情况，K-Means 会得到下面的聚类结果。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1585580200547-0479504c-1985-4895-80ab-be34456f2d73.jpeg#align=left&display=inline&height=941&name=bafc98deb68400100fde69a41ebc66ca.jpg&originHeight=941&originWidth=2142&size=244125&status=done&style=none&width=2142" alt="bafc98deb68400100fde69a41ebc66ca.jpg"><br><br><br>因为 K-Means 是通过距离来区分样本之间的差别的，且每个样本在计算的时候只能属于一个分类，称之为是硬聚类算法。而 EM 聚类在求解的过程中，实际上每个样本都有一定的概率和每个聚类相关，叫做软聚类算法。<br><br><br>你可以把 EM 算法理解成为是一个框架，在这个框架中可以采用不同的模型来用 EM 进行求解。常用的 EM 聚类有 GMM 高斯混合模型和 HMM 隐马尔科夫模型。GMM（高斯混合模型）聚类就是 EM 聚类的一种。比如上面这两个图，可以采用 GMM 来进行聚类。和 K-Means 一样，我们事先知道聚类的个数，但是不知道每个样本分别属于哪一类。通常，我们可以假设样本是符合高斯分布的（也就是正态分布）。<br><br><br>每个高斯分布都属于这个模型的组成部分（component），要分成 K 类就相当于是 K 个组成部分。这样我们可以先初始化每个组成部分的高斯分布的参数，然后再看来每个样本是属于哪个组成部分。这也就是 E 步骤。再通过得到的这些隐含变量结果，反过来求每个组成部分高斯分布的参数，即 M 步骤。反复 EM 步骤，直到每个组成部分的高斯分布参数不变为止。<br><br><br>这样也就相当于将样本按照 GMM 模型进行了 EM 聚类。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1585580420713-b81ad6a3-2643-471a-accb-30883522c414.jpeg#align=left&display=inline&height=901&name=18fe6407b90130e5e4fa74467b1d493b.jpg&originHeight=901&originWidth=2035&size=232636&status=done&style=none&width=2035" alt="18fe6407b90130e5e4fa74467b1d493b.jpg"><br></p><p><a name="WxvyZ"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>EM 算法相当于一个框架，你可以采用不同的模型来进行聚类，比如 GMM（高斯混合模型），或者 HMM（隐马尔科夫模型）来进行聚类。GMM 是通过概率密度来进行聚类，聚成的类符合高斯分布（正态分布）。而 HMM 用到了马尔可夫过程，在这个过程中，我们通过状态转移矩阵来计算状态转移的概率。HMM 在自然语言处理和语音识别领域中有广泛的应用。在 EM 这个框架中，E 步骤相当于是通过初始化的参数来估计隐含变量。M 步骤就是通过隐含变量反推来优化参数。最后通过 EM 步骤的迭代得到模型参数。<br><br><br>在这个过程里用到的一些数学公式这节课不进行展开。你需要重点理解 EM 算法的原理。通过上面举的炒菜的例子，你可以知道 EM 算法是一个不断观察和调整的过程。通过求硬币正面概率的例子，你可以理解如何通过初始化参数来求隐含数据的过程，以及再通过求得的隐含数据来优化参数。通过上面 GMM 图像聚类的例子，你可以知道很多 K-Means 解决不了的问题，EM 聚类是可以解决的。在 EM 框架中，我们将潜在类别当做隐藏变量，样本看做观察值，把聚类问题转化为参数估计问题，最终把样本进行聚类。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;今天要来学习 EM 聚类。EM 的英文是 Expectation Maximization，所以 EM 算法也叫最大期望算法。&lt;br&gt;&lt;br&gt;&lt;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="EM" scheme="cpeixin.cn/tags/EM/"/>
    
  </entry>
  
  <entry>
    <title>数据分析-K-Means_1</title>
    <link href="cpeixin.cn/2019/02/01/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-K-Means-1/"/>
    <id>cpeixin.cn/2019/02/01/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-K-Means-1/</id>
    <published>2019-02-01T15:26:13.000Z</published>
    <updated>2020-04-04T17:38:15.018Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><h1 id="数据分析-K-Means-原理"><a href="#数据分析-K-Means-原理" class="headerlink" title="数据分析 - K-Means 原理"></a>数据分析 - K-Means 原理</h1><p>K-Means 是一种非监督学习，解决的是聚类问题。K 代表的是 K 类，Means 代表的是中心，你可以理解这个算法的本质是确定 K 类的中心点，当你找到了这些中心点，也就完成了聚类。<br><br><br>那么请你和我思考以下三个问题：</p><ul><li>如何确定 K 类的中心点？</li><li>如何将其他点划分到 K 类中？</li><li>如何区分 K-Means 与 KNN？</li></ul><p><br>如果理解了上面这 3 个问题，那么对 K-Means 的原理掌握得也就差不多了。先请你和我思考一个场景，假设我有 20 支亚洲足球队，想要将它们按照成绩划分成 3 个等级，可以怎样划分？<br></p><p><a name="tdJch"></a></p><h3 id="K-Means-的工作原理"><a href="#K-Means-的工作原理" class="headerlink" title="K-Means 的工作原理"></a>K-Means 的工作原理</h3><p><br>对亚洲足球队的水平，你可能也有自己的判断。比如一流的亚洲球队有谁？你可能会说伊朗或韩国。二流的亚洲球队呢？你可能说是中国。三流的亚洲球队呢？你可能会说越南。其实这些都是靠我们的经验来划分的，那么伊朗、中国、越南可以说是三个等级的典型代表，也就是我们每个类的中心点。<br><br><br>所以回过头来，如何确定 K 类的中心点？一开始我们是可以随机指派的，当你确认了中心点后，就可以按照距离将其他足球队划分到不同的类别中。这也就是 K-Means 的中心思想，就是这么简单直接。<br><br><br>你可能会问：如果一开始，选择一流球队是中国，二流球队是伊朗，三流球队是韩国，中心点选择错了怎么办？其实不用担心，K-Means 有自我纠正机制，在不断的迭代过程中，会纠正中心点。中心点在整个迭代过程中，并不是唯一的，只是你需要一个初始值，一般算法会随机设置初始的中心点。好了，那我来把 K-Means 的工作原理给你总结下：<br></p><ol><li>选取 K 个点作为初始的类中心点，这些点一般都是从数据集中随机抽取的；</li><li>将每个点分配到最近的类中心点，这样就形成了 K 个类，然后重新计算每个类的中心点；</li><li>重复第二步，直到类不发生变化，或者你也可以设置最大迭代次数，这样即使类中心点发生变化，但是只要达到最大迭代次数就会结束。</li></ol><p><a name="WeqHb"></a></p><h3 id="如何给亚洲球队做聚类"><a href="#如何给亚洲球队做聚类" class="headerlink" title="如何给亚洲球队做聚类"></a>如何给亚洲球队做聚类</h3><p><br>对于机器来说需要数据才能判断类中心点，所以我整理了 2015-2019 年亚洲球队的排名，如下表所示。我来说明一下数据概况。其中 2019 年国际足联的世界排名，2015 年亚洲杯排名均为实际排名。2018 年世界杯中，很多球队没有进入到决赛圈，所以只有进入到决赛圈的球队才有实际的排名。如果是亚洲区预选赛 12 强的球队，排名会设置为 40。如果没有进入亚洲区预选赛 12 强，球队排名会设置为 50。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585319665552-bf820517-59c1-4c80-97ea-7e8c4add82cc.png#align=left&display=inline&height=794&name=d8ac2a98aa728d64f919bac088ed574a.png&originHeight=794&originWidth=784&size=75133&status=done&style=none&width=784" alt="d8ac2a98aa728d64f919bac088ed574a.png"><br><br><br>针对上面的排名，我们首先需要做的是数据规范化。你可以把这些值划分到[0,1]或者按照均值为 0，方差为 1 的正态分布进行规范化。我先把数值都规范化到[0,1]的空间中，得到了以下的数值表：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585319721708-569fa0e7-9ae2-4f5e-8d72-73c785cd5d79.png#align=left&display=inline&height=789&name=a722eeab035fb13751a6dc5c0530ed17.png&originHeight=789&originWidth=726&size=104223&status=done&style=none&width=726" alt="a722eeab035fb13751a6dc5c0530ed17.png"><br><br><br>如果我们随机选取中国、日本、韩国为三个类的中心点，我们就需要看下这些球队到中心点的距离。距离有多种计算的方式，有关距离的计算我在 KNN 算法中也讲到过：</p><ul><li>欧氏距离</li><li>曼哈顿距离</li><li>切比雪夫距离</li><li>余弦距离</li></ul><p><br>欧氏距离是最常用的距离计算方式，这里我选择欧氏距离作为距离的标准，计算每个队伍分别到中国、日本、韩国的距离，然后根据距离远近来划分。我们看到大部分的队，会和中国队聚类到一起。这里我整理了距离的计算过程，比如中国和中国的欧氏距离为 0，中国和日本的欧式距离为 0.732003。如果按照中国、日本、韩国为 3 个分类的中心点，欧氏距离的计算结果如下表所示：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585319859553-47a6149f-6259-4ce9-814c-31982c39c9fd.png#align=left&display=inline&height=828&name=b603ccdb93420c8455aea7278efaece9.png&originHeight=828&originWidth=616&size=115865&status=done&style=none&width=616" alt="b603ccdb93420c8455aea7278efaece9.png"><br><br><br>然后我们再重新计算这三个类的中心点，如何计算呢？最简单的方式就是取平均值，然后根据新的中心点按照距离远近重新分配球队的分类，再根据球队的分类更新中心点的位置。计算过程这里不展开，最后一直迭代（重复上述的计算过程：计算中心点和划分分类）到分类不再发生变化，可以得到以下的分类结果：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585320001148-d48868fc-bab4-48c4-bc62-9b8007a29b54.png#align=left&display=inline&height=919&name=12c6039884ee99742fbbebf198425998.png&originHeight=919&originWidth=865&size=185098&status=done&style=none&width=865" alt="12c6039884ee99742fbbebf198425998.png"><br><br><br>所以我们能看出来第一梯队有日本、韩国、伊朗、沙特、澳洲；第二梯队有中国、伊拉克、阿联酋、乌兹别克斯坦；第三梯队有卡塔尔、泰国、越南、阿曼、巴林、朝鲜、印尼、叙利亚、约旦、科威特和巴勒斯坦。<br></p><p><a name="vFDux"></a></p><h3 id="如何使用-sklearn-中的-K-Means-算法"><a href="#如何使用-sklearn-中的-K-Means-算法" class="headerlink" title="如何使用 sklearn 中的 K-Means 算法"></a>如何使用 sklearn 中的 K-Means 算法</h3><p><br>sklearn 是 Python 的机器学习工具库，如果从功能上来划分，sklearn 可以实现分类、聚类、回归、降维、模型选择和预处理等功能。这里我们使用的是 sklearn 的聚类函数库，因此需要引用工具包，具体代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br></pre></td></tr></table></figure><p><br>当然 K-Means 只是 sklearn.cluster 中的一个聚类库，实际上包括 K-Means 在内，sklearn.cluster 一共提供了 9 种聚类方法，比如 Mean-shift，DBSCAN，Spectral clustering（谱聚类）等。这些聚类方法的原理和 K-Means 不同，这里不做介绍。我们看下 K-Means 如何创建：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KMeans(n_clusters=<span class="number">8</span>, init=<span class="string">'k-means++'</span>, n_init=<span class="number">10</span>, max_iter=<span class="number">300</span>, tol=<span class="number">0.0001</span>, precompute_distances=<span class="string">'auto'</span>, verbose=<span class="number">0</span>, random_state=<span class="literal">None</span>, copy_x=<span class="literal">True</span>, n_jobs=<span class="number">1</span>, algorithm=<span class="string">'auto'</span>)</span><br></pre></td></tr></table></figure><p><br>我们能看到在 K-Means 类创建的过程中，有一些主要的参数：</p><ul><li>n_clusters: 即 K 值，一般需要多试一些 K 值来保证更好的聚类效果。你可以随机设置一些 K 值，然后选择聚类效果最好的作为最终的 K 值；</li><li>max_iter： 最大迭代次数，如果聚类很难收敛的话，设置最大迭代次数可以让我们及时得到反馈结果，否则程序运行时间会非常长；</li><li>n_init：初始化中心点的运算次数，默认是 10。程序是否能快速收敛和中心点的选择关系非常大，所以在中心点选择上多花一些时间，来争取整体时间上的快速收敛还是非常值得的。由于每一次中心点都是随机生成的，这样得到的结果就有好有坏，非常不确定，所以要运行 n_init 次, 取其中最好的作为初始的中心点。如果 K 值比较大的时候，你可以适当增大 n_init 这个值；</li><li>init： 即初始值选择的方式，默认是采用优化过的 k-means++ 方式，你也可以自己指定中心点，或者采用 random 完全随机的方式。自己设置中心点一般是对于个性化的数据进行设置，很少采用。random 的方式则是完全随机的方式，一般推荐采用优化过的 k-means++ 方式；</li><li>algorithm：k-means 的实现算法，有“auto” “full”“elkan”三种。一般来说建议直接用默认的”auto”。简单说下这三个取值的区别，如果你选择”full”采用的是传统的 K-Means 算法，“auto”会根据数据的特点自动选择是选择“full”还是“elkan”。我们一般选择默认的取值，即“auto” 。</li></ul><p><br>在创建好 K-Means 类之后，就可以使用它的方法，最常用的是 fit 和 predict 这个两个函数。你可以单独使用 fit 函数和 predict 函数，也可以合并使用 fit_predict 函数。其中 fit(data) 可以对 data 数据进行 k-Means 聚类。 predict(data) 可以针对 data 中的每个样本，计算最近的类。现在我们要完整地跑一遍 20 支亚洲球队的聚类问题。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 输入数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">'data.csv'</span>, encoding=<span class="string">'gbk'</span>)</span><br><span class="line">train_x = data[[<span class="string">"2019年国际排名"</span>,<span class="string">"2018世界杯"</span>,<span class="string">"2015亚洲杯"</span>]]</span><br><span class="line">df = pd.DataFrame(train_x)</span><br><span class="line"><span class="comment"># kmeans = KMeans(n_clusters=3)</span></span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">3</span>, init=<span class="string">'k-means++'</span>, n_init=<span class="number">10</span>, max_iter=<span class="number">300</span>, tol=<span class="number">0.0001</span>, precompute_distances=<span class="string">'auto'</span>, verbose=<span class="number">0</span>, random_state=<span class="literal">None</span>, copy_x=<span class="literal">True</span>, n_jobs=<span class="number">1</span>, algorithm=<span class="string">'auto'</span>)</span><br><span class="line"><span class="comment"># 规范化到[0,1]空间</span></span><br><span class="line">min_max_scaler=preprocessing.MinMaxScaler()</span><br><span class="line">train_x=min_max_scaler.fit_transform(train_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># kmeans算法</span></span><br><span class="line">kmeans.fit(train_x)</span><br><span class="line">predict_y = kmeans.predict(train_x)</span><br><span class="line"><span class="comment"># 合并聚类结果，插入到原数据中</span></span><br><span class="line">result = pd.concat((data,pd.DataFrame(predict_y)),axis=<span class="number">1</span>)</span><br><span class="line">result.rename(&#123;<span class="number">0</span>:<span class="string">u'聚类'</span>&#125;,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><p><br>结果：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">        国家  <span class="number">2019</span>年国际排名  <span class="number">2018</span>世界杯  <span class="number">2015</span>亚洲杯  聚类</span><br><span class="line"><span class="number">0</span>       中国         <span class="number">73</span>       <span class="number">40</span>        <span class="number">7</span>   <span class="number">2</span></span><br><span class="line"><span class="number">1</span>       日本         <span class="number">60</span>       <span class="number">15</span>        <span class="number">5</span>   <span class="number">0</span></span><br><span class="line"><span class="number">2</span>       韩国         <span class="number">61</span>       <span class="number">19</span>        <span class="number">2</span>   <span class="number">0</span></span><br><span class="line"><span class="number">3</span>       伊朗         <span class="number">34</span>       <span class="number">18</span>        <span class="number">6</span>   <span class="number">0</span></span><br><span class="line"><span class="number">4</span>       沙特         <span class="number">67</span>       <span class="number">26</span>       <span class="number">10</span>   <span class="number">0</span></span><br><span class="line"><span class="number">5</span>      伊拉克         <span class="number">91</span>       <span class="number">40</span>       <span class="number">4</span>    <span class="number">2</span></span><br><span class="line"><span class="number">6</span>      卡塔尔        <span class="number">101</span>       <span class="number">40</span>       <span class="number">13</span>   <span class="number">1</span></span><br><span class="line"><span class="number">7</span>      阿联酋         <span class="number">81</span>       <span class="number">40</span>        <span class="number">6</span>   <span class="number">2</span></span><br><span class="line"><span class="number">8</span>   乌兹别克斯坦         <span class="number">88</span>       <span class="number">40</span>        <span class="number">8</span>     <span class="number">2</span></span><br><span class="line"><span class="number">9</span>       泰国        <span class="number">122</span>       <span class="number">40</span>       <span class="number">17</span>   <span class="number">1</span></span><br><span class="line"><span class="number">10</span>      越南        <span class="number">102</span>       <span class="number">50</span>       <span class="number">17</span>   <span class="number">1</span></span><br><span class="line"><span class="number">11</span>      阿曼         <span class="number">87</span>       <span class="number">50</span>       <span class="number">12</span>   <span class="number">1</span></span><br><span class="line"><span class="number">12</span>      巴林        <span class="number">116</span>       <span class="number">50</span>       <span class="number">11</span>   <span class="number">1</span></span><br><span class="line"><span class="number">13</span>      朝鲜        <span class="number">110</span>       <span class="number">50</span>       <span class="number">14</span>   <span class="number">1</span></span><br><span class="line"><span class="number">14</span>      印尼        <span class="number">164</span>       <span class="number">50</span>       <span class="number">17</span>   <span class="number">1</span></span><br><span class="line"><span class="number">15</span>      澳洲         <span class="number">40</span>       <span class="number">30</span>        <span class="number">1</span>   <span class="number">0</span></span><br><span class="line"><span class="number">16</span>     叙利亚         <span class="number">76</span>       <span class="number">40</span>       <span class="number">17</span>      <span class="number">1</span></span><br><span class="line"><span class="number">17</span>      约旦        <span class="number">118</span>       <span class="number">50</span>        <span class="number">9</span>   <span class="number">1</span></span><br><span class="line"><span class="number">18</span>     科威特        <span class="number">160</span>       <span class="number">50</span>       <span class="number">15</span>      <span class="number">1</span></span><br><span class="line"><span class="number">19</span>    巴勒斯坦         <span class="number">96</span>       <span class="number">50</span>       <span class="number">16</span>      <span class="number">1</span></span><br></pre></td></tr></table></figure><p><a name="PGFOw"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>如何确定 K 类的中心点？其中包括了初始的设置，以及中间迭代过程中中心点的计算。在初始设置中，会进行 n_init 次的选择，然后选择初始中心点效果最好的为初始值。在每次分类更新后，你都需要重新确认每一类的中心点，一般采用均值的方式进行确认。<br><br><br>如何将其他点划分到 K 类中？这里实际上是关于距离的定义，我们知道距离有多种定义的方式，在 K-Means 和 KNN 中，我们都可以采用欧氏距离、曼哈顿距离、切比雪夫距离、余弦距离等。对于点的划分，就看它离哪个类的中心点的距离最近，就属于哪一类。<br><br><br>如何区分 K-Means 和 KNN 这两种算法呢？刚学过 K-Means 和 KNN 算法的同学应该能知道两者的区别，但往往过了一段时间，就容易混淆。所以我们可以从三个维度来区分 K-Means 和 KNN 这两个算法：<br></p><ul><li>首先，这两个算法解决数据挖掘的两类问题。K-Means 是聚类算法，KNN 是分类算法。</li><li>这两个算法分别是两种不同的学习方式。K-Means 是非监督学习，也就是不需要事先给出分类标签，而 KNN 是有监督学习，需要我们给出训练数据的分类标识。</li><li>最后，K 值的含义不同。K-Means 中的 K 值代表 K 类。KNN 中的 K 值代表 K 个最接近的邻居。</li></ul><p><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585322317887-46d24bc4-6cbc-4173-8d10-ae8a610ed00a.png#align=left&display=inline&height=588&name=eb60546c6a3d9bc6a1538049c26723c5.png&originHeight=588&originWidth=864&size=163570&status=done&style=none&width=864" alt="eb60546c6a3d9bc6a1538049c26723c5.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;数据分析-K-Means-原理&quot;&gt;&lt;a href=&quot;#数据分析-K-Means-原理&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="K-Means" scheme="cpeixin.cn/tags/K-Means/"/>
    
  </entry>
  
  <entry>
    <title>数据分析-KNN_2</title>
    <link href="cpeixin.cn/2019/01/27/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-KNN-2/"/>
    <id>cpeixin.cn/2019/01/27/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-KNN-2/</id>
    <published>2019-01-26T16:14:49.000Z</published>
    <updated>2020-04-04T17:37:45.109Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>通过 sklearn 中自带的手写数字数据集来进行实战。<br></p><p><a name="je2jJ"></a></p><h3 id="如何在-sklearn-中使用-KNN"><a href="#如何在-sklearn-中使用-KNN" class="headerlink" title="如何在 sklearn 中使用 KNN"></a>如何在 sklearn 中使用 KNN</h3><p><br>在 Python 的 sklearn 工具包中有 KNN 算法。KNN 既可以做分类器，也可以做回归。<br><br><br>如果是做分类，你需要引用：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br></pre></td></tr></table></figure><p><br>如果是做回归，你需要引用：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br></pre></td></tr></table></figure><p><br>从名字上你也能看出来 Classifier 对应的是分类，Regressor 对应的是回归。一般来说如果一个算法有 Classifier 类，都能找到相应的 Regressor 类。比如在决策树分类中，你可以使用 DecisionTreeClassifier，也可以使用决策树来做回归 DecisionTreeRegressor。<br><br><br>好了，我们看下如何在 sklearn 中创建 KNN 分类器。这里，我们使用构造函数<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KNeighborsClassifier(n_neighbors=<span class="number">5</span>, weights=‘uniform’, algorithm=‘auto’, leaf_size=<span class="number">30</span>)</span><br></pre></td></tr></table></figure><p><br>这里有几个比较主要的参数，我分别来讲解下：<br>1.n_neighbors：即 KNN 中的 K 值，代表的是邻居的数量。K 值如果比较小，会造成过拟合。如果 K 值比较大，无法将未知物体分类出来。一般我们使用默认值 5。<br><br><br>2.weights：是用来确定邻居的权重，有三种方式：</p><ul><li>weights=uniform，代表所有邻居的权重相同；</li><li>weights=distance，代表权重是距离的倒数，即与距离成反比；</li><li>自定义函数，你可以自定义不同距离所对应的权重。大部分情况下不需要自己定义函数。</li></ul><p><br>3.algorithm：用来规定计算邻居的方法，它有四种方式：</p><ul><li>algorithm=auto，根据数据的情况自动选择适合的算法，默认情况选择 auto；</li><li>algorithm=kd_tree，也叫作 KD 树，是多维空间的数据结构，方便对关键数据进行检索，不过 KD 树适用于维度少的情况，一般维数不超过 20，如果维数大于 20 之后，效率反而会下降；</li><li>algorithm=ball_tree，也叫作球树，它和 KD 树一样都是多维空间的数据结果，不同于 KD 树，球树更适用于维度大的情况；</li><li>algorithm=brute，也叫作暴力搜索，它和 KD 树不同的地方是在于采用的是线性扫描，而不是通过构造树结构进行快速检索。当训练集大的时候，效率很低。</li></ul><p><br>4.leaf_size：代表构造 KD 树或球树时的叶子数，默认是 30，调整 leaf_size 会影响到树的构造和搜索速度。<br><br><br>创建完 KNN 分类器之后，我们就可以输入训练集对它进行训练，这里我们使用 fit() 函数，传入训练集中的样本特征矩阵和分类标识，会自动得到训练好的 KNN 分类器。然后可以使用 predict() 函数来对结果进行预测，这里传入测试集的特征矩阵，可以得到测试集的预测分类结果。<br></p><p><a name="0f8U9"></a></p><h3 id="如何用-KNN-对手写数字进行识别分类"><a href="#如何用-KNN-对手写数字进行识别分类" class="headerlink" title="如何用 KNN 对手写数字进行识别分类"></a>如何用 KNN 对手写数字进行识别分类</h3><p><br>手写数字数据集是个非常有名的用于图像识别的数据集。数字识别的过程就是将这些图片与分类结果 0-9 一一对应起来。完整的手写数字数据集 MNIST 里面包括了 60000 个训练样本，以及 10000 个测试样本。如果你学习深度学习的话，MNIST 基本上是你接触的第一个数据集。今天我们用 sklearn 自带的手写数字数据集做 KNN 分类，你可以把这个数据集理解成一个简版的 MNIST 数据集，它只包括了 1797 幅数字图像，每幅图像大小是 8*8 像素。好了，我们先来规划下整个 KNN 分类的流程：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1584978279144-0fe97312-03bb-4b5e-ae5a-8b4a6c0259b9.jpeg#align=left&display=inline&height=1087&name=8af94562f6bd3ac42036ec47f5ad2578.jpg&originHeight=1087&originWidth=2373&size=265868&status=done&style=none&width=2373" alt="8af94562f6bd3ac42036ec47f5ad2578.jpg"><br><br><br>整个训练过程基本上都会包括三个阶段：</p><ul><li>数据加载：我们可以直接从 sklearn 中加载自带的手写数字数据集；</li><li>准备阶段：在这个阶段中，我们需要对数据集有个初步的了解，比如样本的个数、图像长什么样、识别结果是怎样的。你可以通过可视化的方式来查看图像的呈现。通过数据规范化可以让数据都在同一个数量级的维度。另外，因为训练集是图像，每幅图像是个 8*8 的矩阵，我们不需要对它进行特征选择，将全部的图像数据作为特征值矩阵即可；</li><li>分类阶段：通过训练可以得到分类器，然后用测试集进行准确率的计算。</li></ul><p>好了，按照上面的步骤，我们一起来实现下这个项目。首先是加载数据和对数据的探索：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">digits = load_digits()</span><br><span class="line">data = digits.data</span><br><span class="line"><span class="comment"># 数据探索</span></span><br><span class="line">print(data.shape)</span><br><span class="line"><span class="comment"># 查看第5幅图像</span></span><br><span class="line">print(digits.images[<span class="number">4</span>])</span><br><span class="line"><span class="comment"># 第5幅图像代表的数字含义</span></span><br><span class="line">print(digits.target[<span class="number">4</span>])</span><br><span class="line"><span class="comment"># 将第5幅图像显示出来</span></span><br><span class="line">plt.gray()</span><br><span class="line">plt.imshow(digits.images[<span class="number">4</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><br>结果：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">1797</span>, <span class="number">64</span>)</span><br><span class="line">[[ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">1.</span> <span class="number">11.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">7.</span>  <span class="number">8.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">1.</span> <span class="number">13.</span>  <span class="number">6.</span>  <span class="number">2.</span>  <span class="number">2.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">7.</span> <span class="number">15.</span>  <span class="number">0.</span>  <span class="number">9.</span>  <span class="number">8.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">5.</span> <span class="number">16.</span> <span class="number">10.</span>  <span class="number">0.</span> <span class="number">16.</span>  <span class="number">6.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">4.</span> <span class="number">15.</span> <span class="number">16.</span> <span class="number">13.</span> <span class="number">16.</span>  <span class="number">1.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">3.</span> <span class="number">15.</span> <span class="number">10.</span>  <span class="number">0.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">2.</span> <span class="number">16.</span>  <span class="number">4.</span>  <span class="number">0.</span>  <span class="number">0.</span>]]</span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure><p><br>对应的手写图像数据：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584978882317-efa5547a-1c70-4824-ac47-2d5e835292bc.png#align=left&display=inline&height=928&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-23%20%E4%B8%8B%E5%8D%8811.52.03.png&originHeight=928&originWidth=1206&size=69352&status=done&style=none&width=1206" alt="屏幕快照 2020-03-23 下午11.52.03.png"><br><br><br>我们对原始数据集中的第一幅进行数据可视化，可以看到图像是个 8<em>8 的像素矩阵，上面这幅图像是一个“4”，从训练集的分类标注中我们也可以看到分类标注为“4”。sklearn 自带的手写数字数据集一共包括了 1797 个样本，每幅图像都是 8</em>8 像素的矩阵。因为并没有专门的测试集，所以我们需要对数据集做划分，划分成训练集和测试集。因为 KNN 算法和距离定义相关，我们需要对数据进行规范化处理，采用 Z-Score 规范化，代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 分割数据，将25%的数据作为测试集，其余作为训练集（你也可以指定其他比例的数据作为训练集）</span></span><br><span class="line">train_x, test_x, train_y, test_y = train_test_split(data, digits.target, test_size=<span class="number">0.25</span>, random_state=<span class="number">33</span>)</span><br><span class="line"><span class="comment"># 采用Z-Score规范化</span></span><br><span class="line">ss = preprocessing.StandardScaler()</span><br><span class="line">train_ss_x = ss.fit_transform(train_x)</span><br><span class="line">test_ss_x = ss.transform(test_x)</span><br></pre></td></tr></table></figure><p><br><strong>注：上面代码中，在train的时候用到了：train_ss_x = ss.fit_transform(train_x)</strong><br><strong>实际上：fit_transform是fit和transform两个函数都执行一次。所以ss是进行了fit拟合的。只有在fit拟合之后，才能进行transform，在进行test的时候，我们已经在train的时候fit过了，所以直接transform即可。</strong><br><strong>另外，如果我们没有fit，直接进行transform会报错，因为需要先fit拟合，才可以进行transform。</strong><br><br><br>然后我们构造一个 KNN 分类器 knn，把训练集的数据传入构造好的 knn，并通过测试集进行结果预测，与测试集的结果进行对比，得到 KNN 分类器准确率，代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 创建KNN分类器</span></span><br><span class="line">knn = KNeighborsClassifier() </span><br><span class="line">knn.fit(train_ss_x, train_y) </span><br><span class="line">predict_y = knn.predict(test_ss_x) </span><br><span class="line">print(<span class="string">"KNN准确率: %.4lf"</span> % accuracy_score(test_y, predict_y))</span><br></pre></td></tr></table></figure><p><br>运行结果：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">KNN准确率: <span class="number">0.9756</span></span><br></pre></td></tr></table></figure><p><br>好了，这样我们就构造好了一个 KNN 分类器。之前我们还讲过 SVM、朴素贝叶斯和决策树分类。我们用手写数字数据集一起来训练下这些分类器，然后对比下哪个分类器的效果更好。代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 创建SVM分类器</span></span><br><span class="line">svm = SVC()</span><br><span class="line">svm.fit(train_ss_x, train_y)</span><br><span class="line">predict_y=svm.predict(test_ss_x)</span><br><span class="line">print(<span class="string">'SVM准确率: %0.4lf'</span> % accuracy_score(test_y, predict_y))</span><br><span class="line"><span class="comment"># 采用Min-Max规范化</span></span><br><span class="line">mm = preprocessing.MinMaxScaler()</span><br><span class="line">train_mm_x = mm.fit_transform(train_x)</span><br><span class="line">test_mm_x = mm.transform(test_x)</span><br><span class="line"><span class="comment"># 创建Naive Bayes分类器</span></span><br><span class="line">mnb = MultinomialNB()</span><br><span class="line">mnb.fit(train_mm_x, train_y) </span><br><span class="line">predict_y = mnb.predict(test_mm_x) </span><br><span class="line">print(<span class="string">"多项式朴素贝叶斯准确率: %.4lf"</span> % accuracy_score(test_y, predict_y))</span><br><span class="line"><span class="comment"># 创建CART决策树分类器</span></span><br><span class="line">dtc = DecisionTreeClassifier()</span><br><span class="line">dtc.fit(train_mm_x, train_y) </span><br><span class="line">predict_y = dtc.predict(test_mm_x) </span><br><span class="line">print(<span class="string">"CART决策树准确率: %.4lf"</span> % accuracy_score(test_y, predict_y))</span><br></pre></td></tr></table></figure><p><br>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">SVM准确率: <span class="number">0.9867</span></span><br><span class="line">多项式朴素贝叶斯准确率: <span class="number">0.8844</span></span><br><span class="line">CART决策树准确率: <span class="number">0.8556</span></span><br></pre></td></tr></table></figure><p><br>这里需要注意的是，我们在做多项式朴素贝叶斯分类的时候，传入的数据不能有负数。因为 Z-Score 会将数值规范化为一个标准的正态分布，即均值为 0，方差为 1，数值会包含负数。因此我们需要采用 Min-Max 规范化，将数据规范化到[0,1]范围内。<br><br><br>你能看出来 KNN 的准确率还是不错的，和 SVM 不相上下。<br><br><br>完整代码：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 手写数字分类</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">digits = load_digits()</span><br><span class="line">data = digits.data</span><br><span class="line"><span class="comment"># 数据探索</span></span><br><span class="line">print(data.shape)</span><br><span class="line"><span class="comment"># 查看第一幅图像</span></span><br><span class="line">print(digits.images[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 第一幅图像代表的数字含义</span></span><br><span class="line">print(digits.target[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 将第一幅图像显示出来</span></span><br><span class="line">plt.gray()</span><br><span class="line">plt.imshow(digits.images[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割数据，将25%的数据作为测试集，其余作为训练集</span></span><br><span class="line">train_x, test_x, train_y, test_y = train_test_split(data, digits.target, test_size=<span class="number">0.25</span>, random_state=<span class="number">33</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 采用Z-Score规范化</span></span><br><span class="line">ss = preprocessing.StandardScaler()</span><br><span class="line">train_ss_x = ss.fit_transform(train_x)</span><br><span class="line">test_ss_x = ss.transform(test_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建KNN分类器</span></span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">knn.fit(train_ss_x, train_y) </span><br><span class="line">predict_y = knn.predict(test_ss_x) </span><br><span class="line">print(<span class="string">"KNN准确率: %.4lf"</span> % accuracy_score(test_y, predict_y))</span><br></pre></td></tr></table></figure><p><a name="L7xTB"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>手写数字分类识别的实战，分别用 KNN、SVM、朴素贝叶斯和决策树做分类器，并统计了四个分类器的准确率。在这个过程中你应该对数据探索、数据可视化、数据规范化、模型训练和结果评估的使用过程有了一定的体会。在数据量不大的情况下，使用 sklearn 还是方便的。如果数据量很大，比如 MNIST 数据集中的 6 万个训练数据和 1 万个测试数据，那么采用深度学习 +GPU 运算的方式会更适合。因为深度学习的特点就是需要大量并行的重复计算，GPU 最擅长的就是做大量的并行计算。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584979402056-090c5ab3-5561-40b4-b01f-0df58cad2641.png#align=left&display=inline&height=400&name=d08f489c3bffaacb6910f32a0fa600e1.png&originHeight=400&originWidth=788&size=121634&status=done&style=none&width=788" alt="d08f489c3bffaacb6910f32a0fa600e1.png"><br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;通过 sklearn 中自带的手写数字数据集来进行实战。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a name=&quot;je2jJ&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h3 id=&quot;如
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="KNN" scheme="cpeixin.cn/tags/KNN/"/>
    
  </entry>
  
  <entry>
    <title>数据分析-KNN_1</title>
    <link href="cpeixin.cn/2019/01/26/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-KNN-1/"/>
    <id>cpeixin.cn/2019/01/26/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-KNN-1/</id>
    <published>2019-01-25T16:14:49.000Z</published>
    <updated>2020-04-04T17:37:43.047Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><h1 id="数据分析-KNN-原理"><a href="#数据分析-KNN-原理" class="headerlink" title="数据分析 - KNN 原理"></a>数据分析 - KNN 原理</h1><p>KNN 的英文叫 K-Nearest Neighbor，应该算是数据挖掘算法中最简单的一种。我们先用一个例子体会下。假设，我们想对电影的类型进行分类，统计了电影中打斗次数、接吻次数，当然还有其他的指标也可以被统计到，如下表所示。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584547000621-d502499d-8b11-462b-b989-5df35d2efdbd.png#align=left&display=inline&height=440&name=6dac3a9961e69aa86d80de32bdc00987.png&originHeight=440&originWidth=1134&size=74222&status=done&style=none&width=1134" alt="6dac3a9961e69aa86d80de32bdc00987.png"><br><br><br>我们很容易理解《战狼》《红海行动》《碟中谍 6》是动作片，《前任 3》《春娇救志明》《泰坦尼克号》是爱情片，但是有没有一种方法让机器也可以掌握这个分类的规则，当有一部新电影的时候，也可以对它的类型自动分类呢？<br><br><br>我们可以把打斗次数看成 X 轴，接吻次数看成 Y 轴，然后在二维的坐标轴上，对这几部电影进行标记，如下图所示。对于未知的电影 A，坐标为 (x,y)，我们需要看下离电影 A 最近的都有哪些电影，这些电影中的大多数属于哪个分类，那么电影 A 就属于哪个分类。实际操作中，我们还需要确定一个 K 值，也就是我们要观察离电影 A 最近的电影有多少个。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584546016437-8281d3c6-6f5f-403d-ac2b-0e283a6cdead.png#align=left&display=inline&height=388&name=fa0aa02dae219b21de5984371950c3cc.png&originHeight=388&originWidth=674&size=72040&status=done&style=none&width=674" alt="fa0aa02dae219b21de5984371950c3cc.png"><br></p><p><a name="3YI61"></a></p><h3 id="KNN-的工作原理"><a href="#KNN-的工作原理" class="headerlink" title="KNN 的工作原理"></a>KNN 的工作原理</h3><p><br>“近朱者赤，近墨者黑”可以说是 KNN 的工作原理。<br><br><br>整个计算过程分为三步：</p><ul><li>计算待分类物体与其他物体之间的距离；</li><li>统计距离最近的 K 个邻居；</li><li>对于 K 个最近的邻居，它们属于哪个分类最多，待分类物体就属于哪一类。</li></ul><p><a name="OlXgV"></a></p><h3 id="K-值如何选择"><a href="#K-值如何选择" class="headerlink" title="K 值如何选择"></a>K 值如何选择</h3><p><br>你能看出整个 KNN 的分类过程，K 值的选择还是很重要的。那么问题来了，K 值选择多少是适合的呢？<br><br><br>如果 K 值比较小，就相当于未分类物体与它的邻居非常接近才行。这样产生的一个问题就是，如果邻居点是个噪声点，那么未分类物体的分类也会产生误差，这样 KNN 分类就会产生过拟合。<br><br><br>如果 K 值比较大，相当于距离过远的点也会对未知物体的分类产生影响，虽然这种情况的好处是鲁棒性强，但是不足也很明显，会产生欠拟合情况，也就是没有把未分类物体真正分类出来。<br><br><br>所以 K 值应该是个实践出来的结果，并不是我们事先而定的。在工程上，我们一般采用交叉验证的方式选取 K 值。交叉验证的思路就是，把样本集中的大部分样本作为训练集，剩余的小部分样本用于预测，来验证分类模型的准确性。所以在 KNN 算法中，我们一般会把 K 值选取在较小的范围内，同时在验证集上准确率最高的那一个最终确定作为 K 值。<br></p><p><a name="Dubk8"></a></p><h3 id="距离如何计算在-KNN"><a href="#距离如何计算在-KNN" class="headerlink" title="距离如何计算在 KNN"></a>距离如何计算在 KNN</h3><p><br>算法中，还有一个重要的计算就是关于距离的度量。两个样本点之间的距离代表了这两个样本之间的相似度。距离越大，差异性越大；距离越小，相似度越大。<br><br><br>关于距离的计算方式有下面五种方式：</p><ol><li>欧氏距离；</li><li>曼哈顿距离；</li><li>闵可夫斯基距离；</li><li>切比雪夫距离；</li><li>余弦距离。</li></ol><p>其中前三种距离是 KNN 中最常用的距离，我给你分别讲解下。<br><br><br>欧氏距离是我们最常用的距离公式，也叫做欧几里得距离。在二维空间中，两点的欧式距离就是：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584546310792-966b911e-96e1-42f1-b59c-62b4fc328c98.png#align=left&display=inline&height=162&name=f8d4fe58ec9580a4ffad5cee263b1b80.png&originHeight=162&originWidth=748&size=18688&status=done&style=none&width=748" alt="f8d4fe58ec9580a4ffad5cee263b1b80.png"><br><br><br>同理，我们也可以求得两点在 n 维空间中的距离：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584546284862-5cf34ec5-6a80-4214-b5b3-e0debb86c9f4.png#align=left&display=inline&height=190&name=40efe7cb4a2571e55438b55f8d37366a.png&originHeight=190&originWidth=1262&size=33639&status=done&style=none&width=1262" alt="40efe7cb4a2571e55438b55f8d37366a.png"><br><br><br>曼哈顿距离在几何空间中用的比较多。以下图为例，绿色的直线代表两点之间的欧式距离，而红色和黄色的线为两点的曼哈顿距离。所以曼哈顿距离等于两个点在坐标系上绝对轴距总和。用公式表示就是：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1584546337196-c21e88b1-bef3-4846-b927-126eb5ad7fbd.jpeg#align=left&display=inline&height=1500&name=dd19ca4f0be3f60b526e9ea0b7d13543.jpg&originHeight=1500&originWidth=1467&size=239780&status=done&style=none&width=1467" alt="dd19ca4f0be3f60b526e9ea0b7d13543.jpg"><br><br><br>闵可夫斯基距离不是一个距离，而是一组距离的定义。对于 n 维空间中的两个点 x(x1,x2,…,xn) 和 y(y1,y2,…,yn) ， x 和 y 两点之间的闵可夫斯基距离为：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584546368933-d651d60a-3ccc-425d-8962-6cbcd4c5a72e.png#align=left&display=inline&height=238&name=4d614c3d6722c02e4ea03cb1e6653dc5.png&originHeight=238&originWidth=516&size=16729&status=done&style=none&width=516" alt="4d614c3d6722c02e4ea03cb1e6653dc5.png"><br><br><br>其中 p 代表空间的维数，当 p=1 时，就是曼哈顿距离；当 p=2 时，就是欧氏距离；当 p→∞时，就是切比雪夫距离。<br><br><br>那么切比雪夫距离怎么计算呢？二个点之间的切比雪夫距离就是这两个点坐标数值差的绝对值的最大值，用数学表示就是：max(|x1-y1|,|x2-y2|)。其公式为p为极限无穷的情况：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584546700060-d96ebbde-05be-4668-a0a2-17f8b8f1620e.png#align=left&display=inline&height=168&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-18%20%E4%B8%8B%E5%8D%8811.49.01.png&originHeight=168&originWidth=786&size=27593&status=done&style=none&width=786" alt="屏幕快照 2020-03-18 下午11.49.01.png"><br><br><br>余弦距离实际上计算的是两个向量的夹角，是在方向上计算两者之间的差异，对绝对数值不敏感。在兴趣相关性比较上，角度关系比距离的绝对值更重要，因此余弦距离可以用于衡量用户对内容兴趣的区分度。比如我们用搜索引擎搜索某个关键词，它还会给你推荐其他的相关搜索，这些推荐的关键词就是采用余弦距离计算得出的。<br></p><p><a name="eKgJh"></a></p><h3 id="KD-树"><a href="#KD-树" class="headerlink" title="KD 树"></a>KD 树</h3><p><br>其实从上文你也能看出来，KNN 的计算过程是大量计算样本点之间的距离。为了减少计算距离次数，提升 KNN 的搜索效率，人们提出了 KD 树（K-Dimensional 的缩写）。KD 树是对数据点在 K 维空间中划分的一种数据结构。在 KD 树的构造中，每个节点都是 k 维数值点的二叉树。既然是二叉树，就可以采用二叉树的增删改查操作，这样就大大提升了搜索效率。在这里，我们不需要对 KD 树的数学原理了解太多，你只需要知道它是一个二叉树的数据结构，方便存储 K 维空间的数据就可以了。而且在 sklearn 中，我们直接可以调用 KD 树，很方便。<br></p><p><a name="K1rKD"></a></p><h3 id="用-KNN-做回归"><a href="#用-KNN-做回归" class="headerlink" title="用 KNN 做回归"></a>用 KNN 做回归</h3><p><br>KNN 不仅可以做分类，还可以做回归。首先讲下什么是回归。在开头电影这个案例中，如果想要对未知电影进行类型划分，这是一个分类问题。首先看一下要分类的未知电影，离它最近的 K 部电影大多数属于哪个分类，这部电影就属于哪个分类。如果是一部新电影，已知它是爱情片，想要知道它的打斗次数、接吻次数可能是多少，这就是一个回归问题。<br><br><br>那么 KNN 如何做回归呢？对于一个新电影 X，我们要预测它的某个属性值，比如打斗次数，具体特征属性和数值如下所示。此时，我们会先计算待测点（新电影 X）到已知点的距离，选择距离最近的 K 个点。假设 K=3，此时最近的 3 个点（电影）分别是《战狼》，《红海行动》和《碟中谍 6》，那么它的打斗次数就是这 3 个点的该属性值的平均值，即 (100+95+105)/3=100 次。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584546868363-1e581966-91b8-4011-a72b-2ac38608fab1.png#align=left&display=inline&height=396&name=35dc8cc7d781c94b0fbaa0b53c01f716.png&originHeight=396&originWidth=890&size=66224&status=done&style=none&width=890" alt="35dc8cc7d781c94b0fbaa0b53c01f716.png"><br></p><p><a name="aZ4z7"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br>今天我给你讲了 KNN 的原理，以及 KNN 中的几个关键因素。比如针对 K 值的选择，我们一般采用交叉验证的方式得出。<br><br><br>针对样本点之间的距离的定义，常用的有 5 种表达方式，你也可以自己来定义两个样本之间的距离公式。不同的定义，适用的场景不同。比如在搜索关键词推荐中，余弦距离是更为常用的。<br><br><br>另外你也可以用 KNN 进行回归，通过 K 个邻居对新的点的属性进行值的预测。KNN 的理论简单直接，针对 KNN 中的搜索也有相应的 KD 树这个数据结构。KNN 的理论成熟，可以应用到线性和非线性的分类问题中，也可以用于回归分析。不过 KNN 需要计算测试点与样本点之间的距离，当数据量大的时候，计算量是非常庞大的，需要大量的存储空间和计算时间。另外如果样本分类不均衡，比如有些分类的样本非常少，那么该类别的分类准确率就会低很多。<br><br><br>当然在实际工作中，我们需要考虑到各种可能存在的情况，比如针对某类样本少的情况，可以增加该类别的权重。同样 KNN 也可以用于推荐算法，虽然现在很多推荐系统的算法会使用 TD-IDF、协同过滤、Apriori 算法，不过针对数据量不大的情况下，采用 KNN 作为推荐算法也是可行的。</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584546977892-60b1a6bc-e309-4c4a-be3e-203c729d42f2.png#align=left&display=inline&height=1017&name=d67073bef9247e1ca7a58ae7869f390f.png&originHeight=1017&originWidth=1172&size=243740&status=done&style=none&width=1172" alt="d67073bef9247e1ca7a58ae7869f390f.png"><br><br><br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;数据分析-KNN-原理&quot;&gt;&lt;a href=&quot;#数据分析-KNN-原理&quot; class=&quot;headerlink&quot; title=&quot;数据分析 
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="KNN" scheme="cpeixin.cn/tags/KNN/"/>
    
  </entry>
  
  <entry>
    <title>数据分析-SVM_2</title>
    <link href="cpeixin.cn/2019/01/25/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-SVM-2/"/>
    <id>cpeixin.cn/2019/01/25/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-SVM-2/</id>
    <published>2019-01-25T12:27:13.000Z</published>
    <updated>2020-04-04T17:34:30.961Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p>SVM 是有监督的学习模型，我们需要事先对数据打上分类标签，通过求解最大分类间隔来求解二分类问题。如果要求解多分类问题，可以将多个二分类器组合起来形成一个多分类器。</p><p><a name="c0qdV"></a></p><h3 id="sklearn-中使用-SVM"><a href="#sklearn-中使用-SVM" class="headerlink" title="sklearn 中使用 SVM"></a>sklearn 中使用 SVM</h3><p>在 Python 的 sklearn 工具包中有 SVM 算法，首先需要引用工具包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br></pre></td></tr></table></figure><p>SVM 既可以做回归，也可以做分类器。</p><p>当用 SVM 做回归的时候，我们可以使用 SVR 或 LinearSVR。SVR 的英文是 Support Vector Regression。</p><p>这篇文章只讲分类，这里只是简单地提一下。当做分类器的时候，我们使用的是 SVC 或者 LinearSVC。SVC 的英文是 Support Vector Classification。</p><p>我简单说一下这两者之前的差别。</p><p>从名字上你能看出 LinearSVC 是个线性分类器，用于处理线性可分的数据，只能使用线性核函数。上一节，我讲到 SVM 是通过核函数将样本从原始空间映射到一个更高维的特质空间中，这样就使得样本在新的空间中线性可分。</p><p>如果是针对非线性的数据，需要用到 SVC。在 SVC 中，我们既可以使用到线性核函数（进行线性划分），也能使用高维的核函数（进行非线性划分）。</p><p><a name="eWSro"></a></p><h3 id="创建一个-SVM-分类器"><a href="#创建一个-SVM-分类器" class="headerlink" title="创建一个 SVM 分类器"></a>创建一个 SVM 分类器</h3><p>我们首先使用 SVC 的构造函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = svm.SVC(kernel=‘rbf’, C=<span class="number">1.0</span>, gamma=‘auto’)</span><br></pre></td></tr></table></figure><p>这里有三个重要的参数 kernel、C 和 gamma。</p><p>kernel 代表核函数的选择，它有四种选择，只不过默认是 rbf，即高斯核函数。</p><ol><li>linear：线性核函数</li><li>poly：多项式核函数</li><li>rbf：高斯核函数（默认）</li><li>sigmoid：sigmoid 核函数</li></ol><p>这四种函数代表不同的映射方式，你可能会问，在实际工作中，如何选择这 4 种核函数呢？我来给你解释一下：</p><p>线性核函数，是在数据线性可分的情况下使用的，运算速度快，效果好。不足在于它不能处理线性不可分的数据。</p><p>多项式核函数可以将数据从低维空间映射到高维空间，但参数比较多，计算量大。</p><p>高斯核函数同样可以将样本映射到高维空间，但相比于多项式核函数来说所需的参数比较少，通常性能不错，所以是默认使用的核函数。</p><p>了解深度学习的同学应该知道 sigmoid 经常用在神经网络的映射中。因此当选用 sigmoid 核函数时，SVM 实现的是多层神经网络。上面介绍的 4 种核函数，除了第一种线性核函数外，其余 3 种都可以处理线性不可分的数据。</p><p>参数 C 代表目标函数的惩罚系数，惩罚系数指的是分错样本时的惩罚程度，默认情况下为 1.0。当 C 越大的时候，分类器的准确性越高，但同样容错率会越低，泛化能力会变差。相反，C 越小，泛化能力越强，但是准确性会降低。</p><p>参数 gamma 代表核函数的系数，默认为样本特征数的倒数，即 gamma = 1 / n_features。在创建 SVM 分类器之后，就可以输入训练集对它进行训练。我们使用 model.fit(train_X,train_y)，传入训练集中的特征值矩阵 train_X 和分类标识 train_y。特征值矩阵就是我们在特征选择后抽取的特征值矩阵（当然你也可以用全部数据作为特征值矩阵）；分类标识就是人工事先针对每个样本标识的分类结果。这样模型会自动进行分类器的训练。我们可以使用 prediction=model.predict(test_X) 来对结果进行预测，传入测试集中的样本特征矩阵 test_X，可以得到测试集的预测分类结果 prediction。</p><p>同样我们也可以创建线性 SVM 分类器，使用 model=svm.LinearSVC()。在 LinearSVC 中没有 kernel 这个参数，限制我们只能使用线性核函数。由于 LinearSVC 对线性分类做了优化，对于数据量大的线性可分问题，使用 LinearSVC 的效率要高于 SVC。</p><p>如果你不知道数据集是否为线性，可以直接使用 SVC 类创建 SVM 分类器。</p><p>在训练和预测中，LinearSVC 和 SVC 一样，都是使用 model.fit(train_X,train_y) 和 model.predict(test_X)。</p><p><a name="ZQodv"></a></p><h3 id="SVM-进行乳腺癌检测"><a href="#SVM-进行乳腺癌检测" class="headerlink" title="SVM 进行乳腺癌检测"></a>SVM 进行乳腺癌检测</h3><p>在了解了如何创建和使用 SVM 分类器后，我们来看一个实际的项目，数据集来自美国威斯康星州的乳腺癌诊断数据集，点击这里进行下载 <a href="https://github.com/cystanford/breast_cancer_data/blob/master/data.csv" target="_blank" rel="external nofollow noopener noreferrer">https://github.com/cystanford/breast_cancer_data/blob/master/data.csv</a>。医疗人员采集了患者乳腺肿块经过细针穿刺 (FNA) 后的数字化图像，并且对这些数字图像进行了特征提取，这些特征可以描述图像中的细胞核呈现。肿瘤可以分成良性和恶性。部分数据截屏如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584281681475-3c6ed20a-f7a6-4633-970e-e8be3f9ca5dc.png#align=left&display=inline&height=968&name=image.png&originHeight=968&originWidth=1482&size=238425&status=done&style=none&width=1482" alt="image.png"></p><p>数据表一共包括了 32 个字段，代表的含义如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584281699309-c39300dc-5a10-4181-8c0f-eb37dc117515.png#align=left&display=inline&height=1031&name=1e6af6fa8bebdfba10457c111b5e9c13.png&originHeight=1031&originWidth=622&size=325518&status=done&style=none&width=622" alt="1e6af6fa8bebdfba10457c111b5e9c13.png"></p><p>上面的表格中，mean 代表平均值，se 代表标准差，worst 代表最大值（3 个最大值的平均值）。每张图像都计算了相应的特征，得出了这 30 个特征值（不包括 ID 字段和分类标识结果字段 diagnosis），实际上是 10 个特征值（radius、texture、perimeter、area、smoothness、compactness、concavity、concave points、symmetry 和 fractal_dimension_mean）的 3 个维度，平均、标准差和最大值。这些特征值都保留了 4 位数字。字段中没有缺失的值。在 569 个患者中，一共有 357 个是良性，212 个是恶性。</p><p>好了，我们的目标是生成一个乳腺癌诊断的 SVM 分类器，并计算这个分类器的准确率。首先设定项目的执行流程：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584282681711-9d8d82c5-ea3c-489d-a0c1-1ddc0ed43531.png#align=left&display=inline&height=558&name=image.png&originHeight=558&originWidth=1216&size=382196&status=done&style=none&width=1216" alt="image.png"></p><p>首先我们需要加载数据源；在准备阶段，需要对加载的数据源进行探索，查看样本特征和特征值，这个过程你也可以使用数据可视化，它可以方便我们对数据及数据之间的关系进一步加深了解。</p><p>然后按照“完全合一”的准则来评估数据的质量，如果数据质量不高就需要做数据清洗。数据清洗之后，你可以做特征选择，方便后续的模型训练；</p><p>在分类阶段，选择核函数进行训练，如果不知道数据是否为线性，可以考虑使用 SVC(kernel=‘rbf’) ，也就是高斯核函数的 SVM 分类器。然后对训练好的模型用测试集进行评估。按照上面的流程，我们来编写下代码，加载数据并对数据做部分的探索：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集，你需要把数据放到目录中</span></span><br><span class="line">data = pd.read_csv(<span class="string">"./data.csv"</span>)</span><br><span class="line"><span class="comment"># 数据探索</span></span><br><span class="line"><span class="comment"># 因为数据集中列比较多，我们需要把dataframe中的列全部显示出来</span></span><br><span class="line">pd.set_option(<span class="string">'display.max_columns'</span>, <span class="literal">None</span>)</span><br><span class="line">print(data.columns)</span><br><span class="line">print(data.head(<span class="number">5</span>))</span><br><span class="line">print(data.describe())</span><br></pre></td></tr></table></figure><p>运行结果中，你能看到 32 个字段里，id 是没有实际含义的，可以去掉。diagnosis 字段的取值为 B 或者 M，我们可以用 0 和 1 来替代。另外其余的 30 个字段，其实可以分成三组字段，下划线后面的 mean、se 和 worst 代表了每组字段不同的度量方式，分别是平均值、标准差和最大值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 将特征字段分成3组</span></span><br><span class="line">features_mean= list(data.columns[<span class="number">2</span>:<span class="number">12</span>])</span><br><span class="line">features_se= list(data.columns[<span class="number">12</span>:<span class="number">22</span>])</span><br><span class="line">features_worst=list(data.columns[<span class="number">22</span>:<span class="number">32</span>])</span><br><span class="line"><span class="comment"># 数据清洗</span></span><br><span class="line"><span class="comment"># ID列没有用，删除该列</span></span><br><span class="line">data.drop(<span class="string">"id"</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 将B良性替换为0，M恶性替换为1</span></span><br><span class="line">data[<span class="string">'diagnosis'</span>]=data[<span class="string">'diagnosis'</span>].map(&#123;<span class="string">'M'</span>:<span class="number">1</span>,<span class="string">'B'</span>:<span class="number">0</span>&#125;)</span><br></pre></td></tr></table></figure><p>然后我们要做特征字段的筛选，首先需要观察下 features_mean 各变量之间的关系，这里我们可以用 DataFrame 的 corr() 函数，然后用热力图帮我们可视化呈现。同样，我们也会看整体良性、恶性肿瘤的诊断情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 将肿瘤诊断结果可视化</span></span><br><span class="line">sns.countplot(data[<span class="string">'diagnosis'</span>],label=<span class="string">"Count"</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 用热力图呈现features_mean字段之间的相关性</span></span><br><span class="line">corr = data[features_mean].corr()</span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">14</span>))</span><br><span class="line"><span class="comment"># annot=True显示每个方格的数据</span></span><br><span class="line">sns.heatmap(corr, annot=<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图表展示：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584283328012-45c4e411-27f8-4334-b18e-b5d1dfa2c4e5.png#align=left&display=inline&height=658&name=a65435de48cee8091bd5f83d286ddb4d.png&originHeight=658&originWidth=864&size=31224&status=done&style=none&width=864" alt="a65435de48cee8091bd5f83d286ddb4d.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584289159025-e03f3a3a-eddc-4359-9594-23febd6cc5f5.png#align=left&display=inline&height=1586&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-16%20%E4%B8%8A%E5%8D%8812.16.14.png&originHeight=1586&originWidth=1568&size=318165&status=done&style=none&width=1568" alt="屏幕快照 2020-03-16 上午12.16.14.png"></p><p>热力图中对角线上的为单变量自身的相关系数是 1。颜色越浅代表相关性越大。所以你能看出来 radius_mean、perimeter_mean 和 area_mean 相关性非常大，compactness_mean、concavity_mean、concave_points_mean 这三个字段也是相关的，因此我们可以取其中的一个作为代表。</p><p>那么如何进行特征选择呢？特征选择的目的是降维，用少量的特征代表数据的特性，这样也可以增强分类器的泛化能力，避免数据过拟合。</p><p>我们能看到 mean、se 和 worst 这三组特征是对同一组内容的不同度量方式，我们可以保留 mean 这组特征，在特征选择中忽略掉 se 和 worst。同时我们能看到 mean 这组特征中，radius_mean、perimeter_mean、area_mean 这三个属性相关性大，compactness_mean、daconcavity_mean、concave points_mean 这三个属性相关性大。</p><p>我们分别从这 2 类中选择 1 个属性作为代表，比如 radius_mean 和 compactness_mean。这样我们就可以把原来的 10 个属性缩减为 6 个属性，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征选择</span></span><br><span class="line">features_remain = [<span class="string">'radius_mean'</span>,<span class="string">'texture_mean'</span>, <span class="string">'smoothness_mean'</span>,<span class="string">'compactness_mean'</span>,</span><br><span class="line">                   <span class="string">'symmetry_mean'</span>, <span class="string">'fractal_dimension_mean'</span>]</span><br></pre></td></tr></table></figure><p>对特征进行选择之后，我们就可以准备训练集和测试集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 抽取30%的数据作为测试集，其余作为训练集</span></span><br><span class="line">train, test = train_test_split(data, test_size = <span class="number">0.3</span>)<span class="comment"># in this our main data is splitted into train and test</span></span><br><span class="line"><span class="comment"># 抽取特征选择的数值作为训练和测试数据</span></span><br><span class="line">train_X = train[features_remain]</span><br><span class="line">train_y=train[<span class="string">'diagnosis'</span>]</span><br><span class="line">test_X= test[features_remain]</span><br><span class="line">test_y =test[<span class="string">'diagnosis'</span>]</span><br></pre></td></tr></table></figure><p>在训练之前，我们需要对数据进行规范化，这样让数据同在同一个量级上，避免因为维度问题造成数据误差：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 采用Z-Score规范化数据，保证每个特征维度的数据均值为0，方差为1</span></span><br><span class="line">ss = StandardScaler()</span><br><span class="line">train_X = ss.fit_transform(train_X)</span><br><span class="line">test_X = ss.transform(test_X)</span><br></pre></td></tr></table></figure><p>最后我们可以让 SVM 做训练和预测了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 创建SVM分类器</span></span><br><span class="line">model = svm.SVC()</span><br><span class="line"><span class="comment"># 用训练集做训练</span></span><br><span class="line">model.fit(train_X,train_y)</span><br><span class="line"><span class="comment"># 用测试集做预测</span></span><br><span class="line">prediction=model.predict(test_X)</span><br><span class="line">print(<span class="string">'准确率: '</span>, metrics.accuracy_score(prediction,test_y))</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">准确率:  <span class="number">0.9181286549707602</span></span><br></pre></td></tr></table></figure><p>乳腺癌诊断分类的 SVM 实战，从这个过程中整个执行的流程，包括数据加载、数据探索、数据清洗、特征选择、SVM 训练和结果评估等环节。sklearn 已经为我们提供了很好的工具，对上节课中讲到的 SVM 的创建和训练都进行了封装，让我们无需关心中间的运算细节。但正因为这样，我们更需要对每个流程熟练掌握，通过实战项目训练数据化思维和对数据的敏感度。</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1584283983373-21da2dfb-3082-4a72-b3dd-6722a2d4af30.png#align=left&display=inline&height=309&name=797fe646ae4668139600fca2c50c5282.png&originHeight=309&originWidth=864&size=86329&status=done&style=none&width=864" alt="797fe646ae4668139600fca2c50c5282.png"></p><p>全部代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, metrics</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">data = pandas.read_csv(<span class="string">"data.csv"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pandas.set_option(<span class="string">'display.max_columns'</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将特征字段分成3组</span></span><br><span class="line">features_mean= list(data.columns[<span class="number">2</span>:<span class="number">12</span>])</span><br><span class="line">features_se= list(data.columns[<span class="number">12</span>:<span class="number">22</span>])</span><br><span class="line">features_worst=list(data.columns[<span class="number">22</span>:<span class="number">32</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据清洗</span></span><br><span class="line"><span class="comment"># ID列没有用，删除该列</span></span><br><span class="line">data.drop(<span class="string">"id"</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 将B良性替换为0，M恶性替换为1</span></span><br><span class="line">data[<span class="string">'diagnosis'</span>]=data[<span class="string">'diagnosis'</span>].map(&#123;<span class="string">'M'</span>:<span class="number">1</span>,<span class="string">'B'</span>:<span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 将肿瘤诊断结果可视化</span></span><br><span class="line"><span class="comment"># sns.countplot(data['diagnosis'],label="Count")</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"><span class="comment"># # 用热力图呈现features_mean字段之间的相关性</span></span><br><span class="line"><span class="comment"># corr = data[features_mean].corr()</span></span><br><span class="line"><span class="comment"># plt.figure(figsize=(14,14))</span></span><br><span class="line"><span class="comment"># # annot=True显示每个方格的数据</span></span><br><span class="line"><span class="comment"># sns.heatmap(corr, annot=True)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征选择</span></span><br><span class="line">features_remain = [<span class="string">'radius_mean'</span>,<span class="string">'texture_mean'</span>, <span class="string">'smoothness_mean'</span>,<span class="string">'compactness_mean'</span>,<span class="string">'symmetry_mean'</span>, <span class="string">'fractal_dimension_mean'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 抽取30%的数据作为测试集，其余作为训练集</span></span><br><span class="line">train, test = train_test_split(data, test_size = <span class="number">0.3</span>)<span class="comment"># in this our main data is splitted into train and test</span></span><br><span class="line"><span class="comment"># 抽取特征选择的数值作为训练和测试数据</span></span><br><span class="line">train_X = train[features_remain]</span><br><span class="line">train_y=train[<span class="string">'diagnosis'</span>]</span><br><span class="line">test_X= test[features_remain]</span><br><span class="line">test_y =test[<span class="string">'diagnosis'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 采用Z-Score规范化数据，保证每个特征维度的数据均值为0，方差为1</span></span><br><span class="line">ss = StandardScaler()</span><br><span class="line">train_X = ss.fit_transform(train_X)</span><br><span class="line">test_X = ss.transform(test_X)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建SVM分类器</span></span><br><span class="line">model = svm.SVC()</span><br><span class="line"><span class="comment"># 用训练集做训练</span></span><br><span class="line">model.fit(train_X,train_y)</span><br><span class="line"><span class="comment"># 用测试集做预测</span></span><br><span class="line">prediction=model.predict(test_X)</span><br><span class="line">print(<span class="string">'准确率: '</span>, metrics.accuracy_score(prediction,test_y))</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;SVM 是有监督的学习模型，我们需要事先对数据打上分类标签，通过求解最大分类间隔来求解二分类问题。如果要求解多分类问题，可以将多个二分类器组合起
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="SVM" scheme="cpeixin.cn/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>数据分析-SVM_1</title>
    <link href="cpeixin.cn/2019/01/24/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-SVM-1/"/>
    <id>cpeixin.cn/2019/01/24/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-SVM-1/</id>
    <published>2019-01-24T14:27:13.000Z</published>
    <updated>2020-04-04T17:34:33.868Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --><p><a name="XR4XW"></a></p><h3 id="SVM-支持向量机"><a href="#SVM-支持向量机" class="headerlink" title="SVM 支持向量机"></a>SVM 支持向量机</h3><p>SVM 的英文叫 Support Vector Machine，中文名为支持向量机。</p><p>它是常见的一种分类方法，在机器学习中，SVM 是有监督的学习模型。什么是有监督的学习模型呢？它指的是我们需要事先对数据打上分类标签，这样机器就知道这个数据属于哪个分类。同样无监督学习，就是数据没有被打上分类标签，这可能是因为我们不具备先验的知识，或者打标签的成本很高。所以我们需要机器代我们部分完成这个工作，比如将数据进行聚类，方便后续人工对每个类进行分析。SVM 作为有监督的学习模型，通常可以帮我们模式识别、分类以及回归分析。</p><p>桌子上我放了红色和蓝色两种球，请你用一根棍子将这两种颜色的球分开。</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583848057858-85ca0b55-bc91-49b7-bed8-7d3bc5d55195.png#align=left&display=inline&height=704&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%889.44.57.png&originHeight=704&originWidth=1144&size=551983&status=done&style=none&width=1144" alt="屏幕快照 2020-03-10 下午9.44.57.png"></p><p>你可以很快想到解决方案，在红色和蓝色球之间画条直线就好了，如下图所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583848114572-d05fbf11-0704-4b29-8958-afdbe3c401bb.png#align=left&display=inline&height=798&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%889.46.07.png&originHeight=798&originWidth=1054&size=558953&status=done&style=none&width=1054" alt="屏幕快照 2020-03-10 下午9.46.07.png"></p><p>这次难度升级，桌子上依然放着红色、蓝色两种球，但是它们的摆放不规律，如下图所示。如何用一根棍子把这两种颜色分开呢？</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583848163531-759be244-8599-42a2-8431-7e3d7bb84f13.png#align=left&display=inline&height=638&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%889.46.52.png&originHeight=638&originWidth=1054&size=436782&status=done&style=none&width=1054" alt="屏幕快照 2020-03-10 下午9.46.52.png"></p><p>你可能想了想，认为一根棍子是分不开的。除非把棍子弯曲，像下面这样：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583848206430-7ff055b4-a870-4c97-9ea9-c2703adc1d07.png#align=left&display=inline&height=644&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%889.47.44.png&originHeight=644&originWidth=1056&size=518833&status=done&style=none&width=1056" alt="屏幕快照 2020-03-10 下午9.47.44.png"></p><p>所以这里直线变成了曲线。如果在同一个平面上来看，红蓝两种颜色的球是很难分开的。那么有没有一种方式，可以让它们自然地分开呢？</p><p>这里你可能会灵机一动，猛拍一下桌子，这些小球瞬间腾空而起，如下图所示。在腾起的那一刹那，出现了一个水平切面，恰好把红、蓝两种颜色的球分开。</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583848325363-17ccf722-32b6-4ca6-b21a-46c246fa50e7.png#align=left&display=inline&height=1494&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%889.49.02.png&originHeight=1494&originWidth=1140&size=1239386&status=done&style=none&width=1140" alt="屏幕快照 2020-03-10 下午9.49.02.png"></p><p>在这里，二维平面变成了三维空间。原来的曲线变成了一个平面。这个平面，我们就叫做超平面。</p><p><a name="cmRWw"></a></p><h3 id="SVM-的工作原理用"><a href="#SVM-的工作原理用" class="headerlink" title="SVM 的工作原理用"></a>SVM 的工作原理用</h3><p>SVM 计算的过程就是帮我们找到那个超平面的过程，这个超平面就是我们的 SVM 分类器。我们再过头来看最简单的练习 1，其实我们可以有多种直线的划分，比如下图所示的直线 A、直线 B 和直线 C，究竟哪种才是更好的划分呢？</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583848413801-0ceb1fff-52ca-4e58-9eea-1ea2271d5f50.png#align=left&display=inline&height=1076&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%889.50.59.png&originHeight=1076&originWidth=1062&size=531974&status=done&style=none&width=1062" alt="屏幕快照 2020-03-10 下午9.50.59.png"></p><p>很明显图中的直线 B 更靠近蓝色球，但是在真实环境下，球再多一些的话，蓝色球可能就被划分到了直线 B 的右侧，被认为是红色球。同样直线 A 更靠近红色球，在真实环境下，如果红色球再多一些，也可能会被误认为是蓝色球。所以相比于直线 A 和直线 B，直线 C 的划分更优，因为它的鲁棒性更强。</p><p>那怎样才能寻找到直线 C 这个更优的答案呢？这里，我们引入一个 SVM 特有的概念：分类间隔。实际上，我们的分类环境不是在二维平面中的，而是在多维空间中，这样直线 C 就变成了决策面 C。在保证决策面不变，且分类不产生错误的情况下，我们可以移动决策面 C，直到产生两个极限的位置：如图中的决策面 A 和决策面 B。极限的位置是指，如果越过了这个位置，就会产生分类错误。这样的话，<strong>两个极限位置 A 和 B 之间的分界线 C 就是最优决策面</strong>。极限位置到最优决策面 C 之间的距离，就是“分类间隔”，英文叫做 margin。</p><p>如果我们转动这个最优决策面，你会发现可能存在多个最优决策面，它们都能把数据集正确分开，这些最优决策面的分类间隔可能是不同的，<strong>而那个拥有“最大间隔”（max margin）的决策面就是 SVM 要找的最优解</strong>。</p><p><strong>点到超平面的距离公式</strong><br><strong><br></strong><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583848862628-4e93bb3a-c356-41f0-8088-46138fb57573.png#align=left&display=inline&height=1022&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%889.58.33.png&originHeight=1022&originWidth=1040&size=517784&status=done&style=none&width=1040" alt="屏幕快照 2020-03-10 下午9.58.33.png"><strong><br></strong><br>**在上面这个例子中，如果我们把红蓝两种颜色的球放到一个三维空间里，你发现决策面就变成了一个平面。这里我们可以用线性函数来表示，如果在一维空间里就表示一个点，在二维空间里表示一条直线，在三维空间中代表一个平面，当然空间维数还可以更多，这样我们给这个线性函数起个名称叫做“超平面”。超平面的数学表达可以写成：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583848926092-6ff7478d-c627-4f06-9c39-3600dd492194.png#align=left&display=inline&height=226&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%889.59.41.png&originHeight=226&originWidth=1238&size=66855&status=done&style=none&width=1238" alt="屏幕快照 2020-03-10 下午9.59.41.png"></p><p>在这个公式里，w、x 是 n 维空间里的向量，其中 x 是函数变量；w 是法向量。法向量这里指的是垂直于平面的直线所表示的向量，它决定了超平面的方向。</p><p>SVM 就是帮我们找到一个超平面，这个超平面能将不同的样本划分开，同时使得样本集中的点到这个分类超平面的最小距离（即分类间隔）最大化。在这个过程中，<strong>支持向量就是离分类超平面最近的样本点</strong>，实际上如果确定了支持向量也就确定了这个超平面。所以支持向量决定了分类间隔到底是多少，而在最大间隔以外的样本点，其实对分类都没有意义。</p><p>所以说， <strong>SVM 就是求解最大分类间隔的过程</strong>，我们还需要对分类间隔的大小进行定义。</p><p>首先，我们定义某类样本集到超平面的距离是这个样本集合内的样本到超平面的最短距离。我们用 di 代表点 xi 到超平面 wxi+b=0 的欧氏距离。因此我们要求 di 的最小值，用它来代表这个样本到超平面的最短距离。di 可以用公式计算得出：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583849438170-2fa70c02-1e0f-4528-9473-613228d12a72.png#align=left&display=inline&height=404&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%8810.08.11.png&originHeight=404&originWidth=1060&size=59272&status=done&style=none&width=1060" alt="屏幕快照 2020-03-10 下午10.08.11.png"></p><p>其中||w||为超平面的范数，di 的公式可以用解析几何知识进行推导</p><p><strong>最大间隔的优化模型</strong></p><p>我们的目标就是找出所有分类间隔中最大的那个值对应的超平面。</p><p>在数学上，这是一个凸优化问题（凸优化就是关于求凸集中的凸函数最小化的问题，这里不具体展开）。通过凸优化问题，最后可以求出最优的 w 和 b，也就是我们想要找的最优超平面。中间求解的过程会用到拉格朗日乘子，和 KKT（Karush-Kuhn-Tucker）条件。数学公式比较多，这里不进行展开。</p><p><strong>硬间隔、软间隔和非线性 SVM</strong></p><p>假如数据是完全的线性可分的，那么学习到的模型可以称为硬间隔支持向量机。换个说法，硬间隔指的就是完全分类准确，不能存在分类错误的情况。软间隔，就是允许一定量的样本分类错误。我们知道，实际工作中的数据没有那么“干净”，或多或少都会存在一些噪点。所以线性可分是个理想情况。这时，我们需要使用到软间隔 SVM（近似线性可分），比如下面这种情况：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583849887196-a50333bc-3465-4267-be20-ca3c6231ae0d.png#align=left&display=inline&height=1026&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%8810.13.13.png&originHeight=1026&originWidth=1048&size=693506&status=done&style=none&width=1048" alt="屏幕快照 2020-03-10 下午10.13.13.png"></p><p>另外还存在一种情况，就是非线性支持向量机。</p><p>比如下面的样本集就是个非线性的数据。图中的两类数据，分别分布为两个圆圈的形状。那么这种情况下，不论是多高级的分类器，只要映射函数是线性的，就没法处理，SVM 也处理不了。这时，我们需要引入一个新的概念：核函数。它可以将样本从原始空间映射到一个更高维的特质空间中，使得样本在新的空间中线性可分。这样我们就可以使用原来的推导来进行计算，只是所有的推导是在新的空间，而不是在原来的空间中进行。</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583850072724-04450db0-5917-4314-977e-a514fe95efee.png#align=left&display=inline&height=804&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%8810.16.46.png&originHeight=804&originWidth=1058&size=559074&status=done&style=none&width=1058" alt="屏幕快照 2020-03-10 下午10.16.46.png"></p><p><a name="pxzoC"></a></p><h3 id="用-SVM-如何解决多分类问题"><a href="#用-SVM-如何解决多分类问题" class="headerlink" title="用 SVM 如何解决多分类问题"></a>用 SVM 如何解决多分类问题</h3><p>SVM 本身是一个二值分类器，最初是为二分类问题设计的，也就是回答 Yes 或者是 No。而实际上我们要解决的问题，可能是多分类的情况，比如对文本进行分类，或者对图像进行识别。</p><p>针对这种情况，我们可以将多个二分类器组合起来形成一个多分类器，常见的方法有“一对多法”和“一对一法”两种。</p><ol><li>一对多法假设我们要把物体分成 A、B、C、D 四种分类，那么我们可以先把其中的一类作为分类 1，其他类统一归为分类 2。这样我们可以构造 4 种 SVM，分别为以下的情况：<br>（1）样本 A 作为正集，B，C，D 作为负集；<br>（2）样本 B 作为正集，A，C，D 作为负集；<br>（3）样本 C 作为正集，A，B，D 作为负集；<br>（4）样本 D 作为正集，A，B，C 作为负集。<br><br><br>这种方法，针对 K 个分类，需要训练 K 个分类器，分类速度较快，但训练速度较慢，因为每个分类器都需要对全部样本进行训练，而且负样本数量远大于正样本数量，会造成样本不对称的情况，而且当增加新的分类，比如第 K+1 类时，需要重新对分类器进行构造。<br><br><br>2. 一对一法一对一法的初衷是想在训练的时候更加灵活。我们可以在任意两类样本之间构造一个 SVM，这样针对 K 类的样本，就会有 C(k,2) 类分类器。比如我们想要划分 A、B、C 三个类，可以构造 3 个分类器：<br>（1）分类器 1：A、B；<br>（2）分类器 2：A、C；<br>（3）分类器 3：B、C。<br><br><br>当对一个未知样本进行分类时，每一个分类器都会有一个分类结果，即为 1 票，最终得票最多的类别就是整个未知样本的类别。这样做的好处是，如果新增一类，不需要重新训练所有的 SVM，只需要训练和新增这一类样本的分类器。而且这种方式在训练单个 SVM 模型的时候，训练速度快。但这种方法的不足在于，分类器的个数与 K 的平方成正比，所以当 K 较大时，训练和测试的时间会比较慢。<br></li></ol><p><a name="lPomc"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>SVM 分类器，它在文本分类尤其是针对二分类任务性能卓越。同样，针对多分类的情况，我们可以采用一对多，或者一对一的方法，多个二值分类器组合成一个多分类器。</p><p>另外关于 SVM 分类器的概念，我希望你能掌握以下的三个程度：</p><p>完全线性可分情况下的线性分类器，也就是线性可分的情况，是最原始的 SVM，它最核心的思想就是找到最大的分类间隔；<br><br><br>大部分线性可分情况下的线性分类器，引入了软间隔的概念。软间隔，就是允许一定量的样本分类错误；<br><br><br>线性不可分情况下的非线性分类器，引入了核函数。它让原有的样本空间通过核函数投射到了一个高维的空间中，从而变得线性可分。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Apr 05 2020 22:33:14 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;XR4XW&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h3 id=&quot;SVM-支持向量机&quot;&gt;&lt;a href=&quot;#SVM-支持向量机&quot; class=&quot;h
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="SVM" scheme="cpeixin.cn/tags/SVM/"/>
    
  </entry>
  
</feed>
