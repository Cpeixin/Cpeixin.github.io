<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>布兰特 | 不忘初心</title>
  
  <subtitle>人处在一种默默奋斗的状态，精神就会从琐碎生活中得到升华</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="cpeixin.cn/"/>
  <updated>2020-04-05T15:10:24.541Z</updated>
  <id>cpeixin.cn/</id>
  
  <author>
    <name>Brent</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>def neverGrowUp()</title>
    <link href="cpeixin.cn/2020/04/06/def-neverGrowUp/"/>
    <id>cpeixin.cn/2020/04/06/def-neverGrowUp/</id>
    <published>2020-04-05T16:00:00.000Z</published>
    <updated>2020-04-05T15:10:24.541Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">neverGrowUp</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="title">while</span> <span class="title">true</span>:</span></span><br><span class="line">开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心</span><br><span class="line">开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心</span><br><span class="line">开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心</span><br><span class="line">开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心</span><br><span class="line">开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心</span><br><span class="line">开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心</span><br><span class="line">开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心开心</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span c
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>抗疫英雄</title>
    <link href="cpeixin.cn/2020/04/04/%E6%8A%97%E7%96%AB%E8%8B%B1%E9%9B%84/"/>
    <id>cpeixin.cn/2020/04/04/%E6%8A%97%E7%96%AB%E8%8B%B1%E9%9B%84/</id>
    <published>2020-04-04T14:45:15.000Z</published>
    <updated>2020-04-05T14:46:33.308Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>致敬缅怀每一位抗疫英雄<br><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1586098032229-b4c6c795-bf87-4105-8f82-87a86e48a89a.jpeg#align=left&display=inline&height=1796&name=WechatIMG86.jpeg&originHeight=1796&originWidth=1072&size=175464&status=done&style=none&width=1072" alt="WechatIMG86.jpeg"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;致敬缅怀每一位抗疫英雄&lt;br&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/jpeg/1072113
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>python Flask &amp; Ajax 数据传输</title>
    <link href="cpeixin.cn/2020/03/11/python-Flask-Ajax-%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/"/>
    <id>cpeixin.cn/2020/03/11/python-Flask-Ajax-%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/</id>
    <published>2020-03-11T14:43:01.000Z</published>
    <updated>2020-04-04T17:13:00.080Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>帮朋友写个小工具，没想到还要搞定JS，大学毕业后就没有写过JS，真的是难为我了😂</p><p>忙活三个小时，终于把前端和后端打通了～～</p><p>前端demo：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Title<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"http://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 发送数据，表单方式 （注意：后端接收数据对应代码不同）--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"&#123;&#123; url_for('send_message') &#125;&#125;"</span> <span class="attr">method</span>=<span class="string">"post"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">textarea</span> <span class="attr">name</span> =<span class="string">"domain"</span> <span class="attr">rows</span>=<span class="string">"30"</span> <span class="attr">cols</span>=<span class="string">"100"</span> <span class="attr">placeholder</span>=<span class="string">"请输入需要查询的域名,如cq5999.com"</span>&gt;</span><span class="tag">&lt;/<span class="name">textarea</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&lt;input id="submit" type="submit" value="发送"&gt;--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">id</span>=<span class="string">"btn-bq"</span> <span class="attr">data-toggle</span>=<span class="string">"modal"</span> <span class="attr">data-target</span>=<span class="string">"#myModal"</span>&gt;</span>查询<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 发送数据，input方式 （注意：后端接收数据对应代码不同） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"send_content"</span>&gt;</span>向后台发送消息：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"send_content"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"send_content"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"send"</span> <span class="attr">type</span>=<span class="string">"button"</span> <span class="attr">value</span>=<span class="string">"发送"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"recv_content"</span>&gt;</span>从后台接收消息：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"recv_content"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"recv_content"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- input方式 对应的js代码，如用表单方式请注释掉 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 发送 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span></span><br><span class="line"><span class="javascript">    $(<span class="string">"#send"</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> message = $(<span class="string">"#send_content"</span>).val()</span></span><br><span class="line">        alert(message)</span><br><span class="line"><span class="javascript">        $.ajax(&#123;</span></span><br><span class="line"><span class="actionscript">            url:<span class="string">"/send_message"</span>,</span></span><br><span class="line"><span class="actionscript">            type:<span class="string">"POST"</span>,</span></span><br><span class="line">            data:&#123;</span><br><span class="line">                message:message</span><br><span class="line">            &#125;,</span><br><span class="line"><span class="actionscript">            dataType: <span class="string">'json'</span>,</span></span><br><span class="line"><span class="actionscript">            success:<span class="function"><span class="keyword">function</span> <span class="params">(data)</span> </span>&#123;</span></span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 接收 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span></span><br><span class="line"><span class="javascript">    $(<span class="string">"#send"</span>).click(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">        $.getJSON(<span class="string">"/change_to_json"</span>,<span class="function"><span class="keyword">function</span> (<span class="params">data</span>) </span>&#123;</span></span><br><span class="line"><span class="javascript">            $(<span class="string">"#recv_content"</span>).val(data.message) <span class="comment">//将后端数据显示在前端</span></span></span><br><span class="line"><span class="javascript">            <span class="built_in">console</span>.log(<span class="string">"传到前端的数据的类型："</span> + <span class="keyword">typeof</span> (data.message))</span></span><br><span class="line"><span class="javascript">            $(<span class="string">"#send_content"</span>).val(<span class="string">""</span>)<span class="comment">//发送的输入框清空</span></span></span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>后端demo:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, render_template, request, jsonify</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">"index_v6.html"</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/send_message', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send_message</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> message_get</span><br><span class="line">    message_get = <span class="string">""</span></span><br><span class="line"></span><br><span class="line">    message_get = request.form[<span class="string">"domain"</span>].split(<span class="string">'\n'</span>)</span><br><span class="line">    <span class="comment"># message_get = request.form['message'] #input提交</span></span><br><span class="line">    print(<span class="string">"收到前端发过来的信息：%s"</span> % message_get)</span><br><span class="line">    print(<span class="string">"收到数据的类型为："</span> + str(type(message_get)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"收到消息"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/change_to_json', methods=['GET'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_to_json</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">global</span> message_get</span><br><span class="line">    message_json = &#123;</span><br><span class="line">        <span class="string">"message"</span>: message_get</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jsonify(message_json)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app.run(host=<span class="string">'0.0.0.0'</span>, port=<span class="number">80</span>,debug=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;帮朋友写个小工具，没想到还要搞定JS，大学毕业后就没有写过JS，真的是难为我了😂&lt;/p&gt;&lt;p&gt;忙活三个小时，终于把前端和后端打通了～～&lt;/p&gt;
      
    
    </summary>
    
    
      <category term="python" scheme="cpeixin.cn/categories/python/"/>
    
    
      <category term="flask" scheme="cpeixin.cn/tags/flask/"/>
    
  </entry>
  
  <entry>
    <title>Python Flask接口设计-示例</title>
    <link href="cpeixin.cn/2020/03/10/Python-Flask%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1-%E7%A4%BA%E4%BE%8B/"/>
    <id>cpeixin.cn/2020/03/10/Python-Flask%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1-%E7%A4%BA%E4%BE%8B/</id>
    <published>2020-03-10T15:08:35.000Z</published>
    <updated>2020-04-04T17:12:52.356Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p><a name="LHF1q"></a></p><h3 id="Get-请求"><a href="#Get-请求" class="headerlink" title="Get 请求"></a>Get 请求</h3><p><strong><strong>开发一个只接受get方法的接口，接受参数为name和age，并返回相应内容。</strong></strong><br><strong><br>**</strong>方法 1:****</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> redirect</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> jsonify</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route("/test_1.0", methods=["GET"])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="comment"># 默认返回内容</span></span><br><span class="line">  return_dict = &#123;<span class="string">'return_code'</span>: <span class="string">'200'</span>, <span class="string">'return_info'</span>: <span class="string">'处理成功'</span>, <span class="string">'result'</span>: <span class="literal">False</span>&#125;</span><br><span class="line">  <span class="comment"># 判断入参是否为空</span></span><br><span class="line">  <span class="keyword">if</span> request.args <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    return_dict[<span class="string">'return_code'</span>] = <span class="string">'5004'</span></span><br><span class="line">    return_dict[<span class="string">'return_info'</span>] = <span class="string">'请求参数为空'</span></span><br><span class="line">    <span class="keyword">return</span> json.dumps(return_dict, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">  <span class="comment"># 获取传入的params参数</span></span><br><span class="line">  get_data = request.args.to_dict()</span><br><span class="line">  name = get_data.get(<span class="string">'name'</span>)</span><br><span class="line">  age = get_data.get(<span class="string">'age'</span>)</span><br><span class="line">  <span class="comment"># 对参数进行操作</span></span><br><span class="line">  return_dict[<span class="string">'result'</span>] = tt(name, age)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> json.dumps(return_dict, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 功能函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tt</span><span class="params">(name, age)</span>:</span></span><br><span class="line">  result_str = <span class="string">"%s今年%s岁"</span> % (name, age)</span><br><span class="line">  <span class="keyword">return</span> result_str</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  app.run(host=<span class="string">'0.0.0.0'</span>, port=<span class="number">80</span>)</span><br></pre></td></tr></table></figure><p>此种方式对应的request请求方式：</p><ol><li>拼接请求链接, 直接请求：<a href="http://0.0.0.0/test_1.0?name=ccc&age=18" target="_blank" rel="external nofollow noopener noreferrer">http://0.0.0.0/test_1.0?name=ccc&amp;age=18</a></li><li>request 请求中带有参数，如下图</li></ol><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583826674613-bc99538a-988e-4386-b8e6-9eb9fce1862f.png#align=left&display=inline&height=610&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%883.47.43.png&originHeight=610&originWidth=1424&size=98593&status=done&style=none&width=1424" alt="屏幕快照 2020-03-10 下午3.47.43.png"></p><p>方法 2:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@app.route('/api/banWordSingle/&lt;string:word&gt;', methods=['GET'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">banWordSingleStart</span><span class="params">(word)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> getWordStatus(word)</span><br></pre></td></tr></table></figure><p>此方法 与 方法 1 中的拼接链接相似，但是不用输入关键字</p><p>请求链接：<a href="http://0.0.0.0/test_1.0?name=ccc&age=18" target="_blank" rel="external nofollow noopener noreferrer">http://0.0.0.0</a>/api/banWordSingle/输入词</p><p><a name="vJdOc"></a></p><h3 id="Post-请求"><a href="#Post-请求" class="headerlink" title="Post 请求"></a>Post 请求</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> redirect</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> jsonify</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route("/test_1.0", methods=["POST"])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="comment"># 默认返回内容</span></span><br><span class="line">  return_dict = &#123;<span class="string">'return_code'</span>: <span class="string">'200'</span>, <span class="string">'return_info'</span>: <span class="string">'处理成功'</span>, <span class="string">'result'</span>: <span class="literal">False</span>&#125;</span><br><span class="line">  <span class="comment"># 判断入参是否为空</span></span><br><span class="line">  <span class="keyword">if</span> request.args <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    return_dict[<span class="string">'return_code'</span>] = <span class="string">'5004'</span></span><br><span class="line">    return_dict[<span class="string">'return_info'</span>] = <span class="string">'请求参数为空'</span></span><br><span class="line">    <span class="keyword">return</span> json.dumps(return_dict, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">  <span class="comment"># 获取传入的params参数</span></span><br><span class="line">  get_data = request.args.to_dict()</span><br><span class="line">  name = get_data.get(<span class="string">'name'</span>)</span><br><span class="line">  age = get_data.get(<span class="string">'age'</span>)</span><br><span class="line">  <span class="comment"># 对参数进行操作</span></span><br><span class="line">  return_dict[<span class="string">'result'</span>] = tt(name, age)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> json.dumps(return_dict, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 功能函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tt</span><span class="params">(name, age)</span>:</span></span><br><span class="line">  result_str = <span class="string">"%s今年%s岁"</span> % (name, age)</span><br><span class="line">  <span class="keyword">return</span> result_str</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  app.run(host=<span class="string">'0.0.0.0'</span>, port=<span class="number">8080</span>)</span><br></pre></td></tr></table></figure><p>请求方式：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583831085097-3a858ae4-259d-408d-a162-6a4ed8c5e291.png#align=left&display=inline&height=692&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-10%20%E4%B8%8B%E5%8D%885.00.28.png&originHeight=692&originWidth=1438&size=99272&status=done&style=none&width=1438" alt="屏幕快照 2020-03-10 下午5.00.28.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;LHF1q&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h3 id=&quot;Get-请求&quot;&gt;&lt;a href=&quot;#Get-请求&quot; class=&quot;headerl
      
    
    </summary>
    
    
      <category term="python" scheme="cpeixin.cn/categories/python/"/>
    
    
      <category term="flask" scheme="cpeixin.cn/tags/flask/"/>
    
  </entry>
  
  <entry>
    <title>IDEA install TabNine</title>
    <link href="cpeixin.cn/2020/01/22/IDEA-install-TabNine/"/>
    <id>cpeixin.cn/2020/01/22/IDEA-install-TabNine/</id>
    <published>2020-01-22T02:26:15.000Z</published>
    <updated>2020-04-04T11:06:48.223Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>TabNine是我目前遇到过最好的智能补全工具</p><p>TabNine基于GPT-2的插件</p><p>安装<br>IDEA编译器，找到plugins</p><p>Windows pycharm：File&gt;settings&gt;plugins;<br>Mac pycharm：performence&gt;plugins&gt;marketplace or plugins&gt;Install JetBrains Plugins</p><p>查找 TabNine, 点击 install, 随后 restart</p><p>重启后：Help&gt;Edit Custom Properties…&gt;Create;</p><p>在跳出来的idea.properties中输入（注：英文字符） TabNine::config</p><p>随即会自动弹出TabNine激活页面；</p><p>激活<br>点击Activation Key下面的here；</p><p>输入你的邮箱号；</p><p>复制粘贴邮件里面的API Key到Activation Key下面；（得到的 key 可以在各种编译器中共用）</p><p>等待自动安装，观察页面（最下面有log可以看当前进度）；</p><p>激活完成后TabNine Cloud为Enabled状态，你也可以在安装进度完成后刷新页面手动选择Enabled；</p><p>确认激活完成，重启pycharm即可；</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;TabNine是我目前遇到过最好的智能补全工具&lt;/p&gt;&lt;p&gt;TabNine基于GPT-2的插件&lt;/p&gt;&lt;p&gt;安装&lt;br&gt;IDEA编译器，找到pl
      
    
    </summary>
    
    
      <category term="开发工具" scheme="cpeixin.cn/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="IDEA" scheme="cpeixin.cn/tags/IDEA/"/>
    
  </entry>
  
  <entry>
    <title>GPT-2 Chinese 自动生成文章 - 环境准备</title>
    <link href="cpeixin.cn/2020/01/01/GPT-2-Chinese-%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E6%96%87%E7%AB%A0-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"/>
    <id>cpeixin.cn/2020/01/01/GPT-2-Chinese-%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E6%96%87%E7%AB%A0-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</id>
    <published>2020-01-01T14:28:43.000Z</published>
    <updated>2020-04-13T09:28:23.224Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p><a name="R14AA"></a></p><h2 id="Google-Colab"><a href="#Google-Colab" class="headerlink" title="Google Colab"></a>Google Colab</h2><p><br>Colaboratory 是一个 Google 研究项目，旨在帮助传播机器学习培训和研究成果。它是一个 Jupyter 笔记本环境，不需要进行任何设置就可以使用，并且完全在云端运行。<br><br><br>Colaboratory 笔记本存储在 Google 云端硬盘中，并且可以共享，就如同您使用 Google 文档或表格一样。Colaboratory 可免费使用。利用Colaboratory ，可以方便的使用Keras,TensorFlow,PyTorch等框架进行深度学习应用的开发。<br><br><br>缺点是最多只能运行12小时，时间一到就会清空VM上所有数据。这包括我们安装的软件，包括我们下载的数据，存放的计算结果， 所以最好不要直接在colab上进行文件的修改，以防保存不及时而造成丢失，而且Google Drive只有免费的15G空间，如果训练文件很大的话，需要扩容。<br><br><br><strong>优点 免费！ 免费！免费！</strong><br>**<br><a name="dpofS"></a></p><h3 id="谷歌云盘"><a href="#谷歌云盘" class="headerlink" title="谷歌云盘"></a>谷歌云盘</h3><p><br>当登录账号进入<a href="https://drive.google.com/drive/my-drive" target="_blank" rel="external nofollow noopener noreferrer">谷歌云盘</a>时，系统会给予15G免费空间大小。由于Colab需要依靠谷歌云盘，故需要在云盘上新建一个文件夹，来存放你的代码或者数据。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583723531238-28bbbd81-69e8-472d-b048-1ac67166a201.png#align=left&display=inline&height=612&name=image.png&originHeight=612&originWidth=1268&size=104029&status=done&style=none&width=1268" alt="image.png"><br>可以看到上图，我的存储空间几乎快满了，在选择进行扩容的时候呢，则需要国外银行卡和国外支付方式，这一点就有点头痛，但是不要忘记万能的淘宝，最后通过淘宝的，花费20元左右，就升级到了无限空间，这里需要注意一下，升级存储空间的方式是添加一块共享云盘，如下图：</p><p><a name="EHdj9"></a></p><h3 id="引入Colab"><a href="#引入Colab" class="headerlink" title="引入Colab"></a>引入Colab</h3><p><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583723706098-527d9fff-e46e-4dd1-b92a-0640b0d61555.png#align=left&display=inline&height=674&name=image.png&originHeight=674&originWidth=1125&size=104056&status=done&style=none&width=1125" alt="image.png"><br><br><br><br><br></p><p><a name="kykCO"></a></p><h3 id="设置GPU环境"><a href="#设置GPU环境" class="headerlink" title="设置GPU环境"></a>设置GPU环境</h3><p><br>打开colab后，我们要设置运行环境。”修改”—&gt;”笔记本设置”<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1583723911273-f07371f9-e982-44b2-af34-b3781f294879.png#align=left&display=inline&height=739&name=image.png&originHeight=739&originWidth=1191&size=94677&status=done&style=none&width=1191" alt="image.png"><br><br><br></p><p><a name="f4U2h"></a></p><h3 id="挂载和切换工作目录"><a href="#挂载和切换工作目录" class="headerlink" title="挂载和切换工作目录"></a>挂载和切换工作目录</h3><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">'/content/drive'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># os.chdir('/content/drive/My Drive/code/GPT2-Chinese') # 原本Google drive的目录</span></span><br><span class="line"></span><br><span class="line">os.chdir(<span class="string">'/content/drive/Shared drives/brentfromchina/code_warehouse/GPT2-Chinese'</span>) <span class="comment">## 共享云盘的目录</span></span><br></pre></td></tr></table></figure><p>其中： My Drive 代表你的google网盘根目录</p><pre><code>code/GPT2-Chinese 或者 code_warehouse/GPT2-Chinese 代表网盘中你的程序文件目录</code></pre><p><a name="MyewB"></a></p><h3 id="在Colab中运行任务"><a href="#在Colab中运行任务" class="headerlink" title="在Colab中运行任务"></a>在Colab中运行任务</h3><p>下图是我google drive中的文件结构， 在项目文件中，创建一个.ipynb文件，来执行你的所有操作。</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586769633567-4e4118a0-5c52-4517-9233-71d897e7fd68.png#align=left&display=inline&height=1748&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-04-13%20%E4%B8%8B%E5%8D%885.15.46.png&originHeight=1748&originWidth=3096&size=378104&status=done&style=none&width=3096" alt="屏幕快照 2020-04-13 下午5.15.46.png"></p><p><a name="GZDbL"></a></p><h3 id="ipynb文件内容"><a href="#ipynb文件内容" class="headerlink" title=".ipynb文件内容"></a>.ipynb文件内容</h3><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586769997876-4536842e-6bb3-4d6f-8df9-e220a66026a0.png#align=left&display=inline&height=1702&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-04-13%20%E4%B8%8B%E5%8D%885.23.22.png&originHeight=1702&originWidth=3154&size=396138&status=done&style=none&width=3154" alt="屏幕快照 2020-04-13 下午5.23.22.png"><br><br><br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;R14AA&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 id=&quot;Google-Colab&quot;&gt;&lt;a href=&quot;#Google-Colab&quot; cl
      
    
    </summary>
    
    
      <category term="NLP" scheme="cpeixin.cn/categories/NLP/"/>
    
    
      <category term="GPT-2" scheme="cpeixin.cn/tags/GPT-2/"/>
    
  </entry>
  
  <entry>
    <title>架构思想</title>
    <link href="cpeixin.cn/2019/12/20/%E6%9E%B6%E6%9E%84%E6%80%9D%E6%83%B3/"/>
    <id>cpeixin.cn/2019/12/20/%E6%9E%B6%E6%9E%84%E6%80%9D%E6%83%B3/</id>
    <published>2019-12-20T02:26:15.000Z</published>
    <updated>2020-04-04T11:23:45.206Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p><a name="-2"></a></p><h2><a href="#" class="headerlink"></a></h2><p>关于什么是架构，一种比较通俗的说法是 “最高层次的规划，难以改变的决定”，这些规划和决定奠定了事物未来发展的方向和最终的蓝图。<br><br><br>从这个意义上说，人生规划也是一种架构。选什么学校、学什么专业、进什么公司、找什么对象，过什么样的生活，都是自己人生的架构。<br><br><br>具体到软件架构，维基百科是这样定义的：“有关软件整体结构与组件的抽象描述，用于指导大型软件系统各个方面的设计”。系统的各个重要组成部分及其关系构成了系统的架构，这些组成部分可以是具体的功能模块，也可以是非功能的设计与决策，他们相互关系组成一个整体，共同构成了软件系统的架构。<br><br><br>架构其实就是把复杂的问题抽象化、简单化，可能你会觉得“说起来容易但做起来难”，如何能快速上手。可以多观察，根据物质决定意识，借助生活真实场景（用户故事，要很多故事）来还原这一系列问题，抓住并提取核心特征。<br><a name="-3"></a></p><h4 id="架构思想"><a href="#架构思想" class="headerlink" title="架构思想"></a>架构思想</h4><p>CPU运算速度&gt;&gt;&gt;&gt;&gt;内存的读写速度&gt;&gt;&gt;&gt;磁盘读写速度</p><ul><li><p>满足业务发展需求是最高准则</p></li><li><p>业务建模，抽象和枚举是两种方式，需要平衡，不能走极端</p></li><li><p>模型要能更真实的反应事物的本质，不是名词概念的堆砌，不能过度设计</p></li><li><p>基础架构最关键的是分离不同业务领域、不同技术领域，让整个系统具有持续优化的能力。</p></li><li><p>分离基础服务、业务规则、业务流程，选择合适的工具外化业务规则和业务流程</p></li><li><p>分离业务组件和技术组件，高类聚，低耦合 - 业务信息的执行可以分散，但业务信息的管理要尽量集中</p></li><li><p>不要让软件的逻辑架构与最后物理部署绑死 - 选择合适的技术而不是高深的技术，随着业务的发展调整使用的技术</p></li><li><p>好的系统架构需要合适的组织架构去保障 - 团队成员思想的转变，漫长而艰难</p></li><li><p>业务架构、系统架构、数据模型<br><a name="-4"></a></p><h4 id="面对一块新业务，如何系统架构？"><a href="#面对一块新业务，如何系统架构？" class="headerlink" title="面对一块新业务，如何系统架构？"></a>面对一块新业务，如何系统架构？</h4></li><li><p>业务分析：输出业务架构图，这个系统里有多少个业务模块，从前台用户到底层一共有多少层。</p></li><li><p>系统划分：根据业务架构图输出系统架构图，需要思考的是这块业务划分成多少个系统，可能一个系统能支持多个业务。基于什么原则将一个系统拆分成多个系统？又基于什么原则将两个系统合并成一个系统？</p></li><li><p>系统分层：系统是几层架构，基于什么原则将一个系统进行分层，分成多少层？</p></li><li><p>模块化：系统里有多少个模块，哪些需要模块化？基于什么原则将一类代码变成一个模块。<br><a name="-5"></a></p><h4 id="如何模块化"><a href="#如何模块化" class="headerlink" title="如何模块化"></a>如何模块化</h4></li><li><p>基于水平切分。把一个系统按照业务类型进行水平切分成多个模块，比如权限管理模块，用户管理模块，各种业务模块等。</p></li><li><p>基于垂直切分。把一个系统按照系统层次进行垂直切分成多个模块，如DAO层，SERVICE层，业务逻辑层。</p></li><li><p>基于单一职责。将代码按照职责抽象出来形成一个一个的模块。将系统中同一职责的代码放在一个模块里。比如我们开发的系统要对接多个渠道的数据，每个渠道的对接方式和数据解析方式不一样，为避免不同渠道代码的相互影响，我们把各个渠道的代码放在各自的模块里。</p></li><li><p>基于易变和不易变。将不易变的代码抽象到一个模块里，比如系统的比较通用的功能。将易变的代码放在另外一个或多个模块里，比如业务逻辑。因为易变的代码经常修改，会很不稳定，分开之后易变代码在修改时候，不会将BUG传染给不变的代码。<br><a name="-6"></a></p><h4 id="提升系统的稳定性"><a href="#提升系统的稳定性" class="headerlink" title="提升系统的稳定性"></a>提升系统的稳定性</h4></li><li><p>流控</p></li></ul><p>双11期间，对于一些重要的接口（比如帐号的查询接口，店铺首页）做流量控制，超过阈值直接返回失败。<br>另外对于一些不重要的业务也可以考虑采用降级方案，大促—&gt;邮件系统。根据28原则，提前将大卖家约1W左右在缓存中预热，并设置起止时间，活动期间内这部分大卖家不发交易邮件提醒，以减轻SA邮件服务器的压力。</p><ul><li>容灾</li></ul><p>最大程度保证主链路的可用性，比如我负责交易的下单，而下单过程中有优惠的业务逻辑，此时需要考虑UMP系统挂掉，不会影响用户下单（后面可以通过修改价格弥补），采用的方式是，如果优惠挂掉，重新渲染页面，并增加ump屏蔽标记，下单时会自动屏蔽ump的代码逻辑。<br>另外还会记录ump系统不可用次数，一定时间内超过阈值，系统会自动报警。</p><ul><li>稳定性</li></ul><p>第三方系统可能会不稳定，存在接口超时或宕机，为了增加系统的健壮性，调用接口时设置超时时间以及异常捕获处理。</p><ul><li>容量规划</li></ul><p>做好容量规划、系统间强弱依赖关系梳理。<br>如：冷热数据不同处理，早期的订单采用oracle存储，随着订单的数量越来越多，查询缓慢，考虑数据迁移，引入历史表，将已归档的记录迁移到历史表中。当然最好的方法是分库分表。<br><a name="-7"></a></p><h4 id="分布式架构"><a href="#分布式架构" class="headerlink" title="分布式架构"></a>分布式架构</h4><ul><li><p>分布式系统</p></li><li><p>分布式缓存</p></li><li><p>分布式数据<br><a name="api"></a></p><h4 id="API-和乐高积木有什么相似之处？"><a href="#API-和乐高积木有什么相似之处？" class="headerlink" title="API 和乐高积木有什么相似之处？"></a>API 和乐高积木有什么相似之处？</h4><p>相信我们大多数人在儿童时期都喜欢玩乐高积木。乐高积木的真正乐趣和吸引力在于，尽管包装盒外面都带有示意图片，但你最终都可以随心所欲得搭出各种样子或造型。<br>对 API 的最佳解释就是它们像乐高积木一样。我们可以用创造性的方式来组合它们，而不用在意它们原本的设计和实现意图。<br>你可以发现很多 API 和乐高积木的相似之处：</p></li><li><p>标准化：通用、标准化的组件，作为基本的构建块（building blocks）；<br></p></li><li><p>可用性：强调可用性，附有文档或使用说明；<br></p></li><li><p>可定制：为不同功能使用不同的API；<br></p></li><li><p>创造性：能够组合不同的 API 来创造混搭的结果；</p></li></ul><p><br>乐高和 API 都有超简单的界面/接口，并且借助这样简单的界面/接口，它可以非常直观、容易、快速得构建。<br>虽然乐高和 API 一样可能附带示意图片或使用文档，大概描述了推荐玩法或用途，但真正令人兴奋的结果或收获恰恰是通过创造力产生的。<br><br><br>让我们仔细地思考下上述的提法。在很多情况下，API 的使用者构建出了 API 的构建者超出预期的服务或产品，API 使用者想要的，和 API 构建者认为使用者想要的，这二者之间通常有个断层。事实也确实如此，在 IoT 领域，我们使用 API 创造出了一些非常有创造性的使用场景。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;-2&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;关于什么
      
    
    </summary>
    
    
      <category term="架构" scheme="cpeixin.cn/categories/%E6%9E%B6%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>kali中文设置</title>
    <link href="cpeixin.cn/2019/12/01/kali%E4%B8%AD%E6%96%87%E8%AE%BE%E7%BD%AE/"/>
    <id>cpeixin.cn/2019/12/01/kali%E4%B8%AD%E6%96%87%E8%AE%BE%E7%BD%AE/</id>
    <published>2019-12-01T02:26:15.000Z</published>
    <updated>2020-04-04T11:06:21.313Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>更新源</p><p><a href="https://blog.csdn.net/qq_38333291/article/details/89764967" target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/qq_38333291/article/details/89764967</a></p><p>设置编码和中文字体安装</p><p><a href="http://www.linuxdiyf.com/linux/20701.html" target="_blank" rel="external nofollow noopener noreferrer">http://www.linuxdiyf.com/linux/20701.html</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;更新源&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq_38333291/article/details/897
      
    
    </summary>
    
    
      <category term="Linux" scheme="cpeixin.cn/categories/Linux/"/>
    
    
      <category term="kali" scheme="cpeixin.cn/tags/kali/"/>
    
  </entry>
  
  <entry>
    <title>分布式下的数据hash分布</title>
    <link href="cpeixin.cn/2019/11/19/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AEhash%E5%88%86%E5%B8%83/"/>
    <id>cpeixin.cn/2019/11/19/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AEhash%E5%88%86%E5%B8%83/</id>
    <published>2019-11-19T15:05:08.000Z</published>
    <updated>2020-04-04T11:24:04.737Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;!-- rebuild by neat --&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>我的服务器被黑了（二）</title>
    <link href="cpeixin.cn/2019/09/09/%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E9%BB%91%E4%BA%86%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>cpeixin.cn/2019/09/09/%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E9%BB%91%E4%BA%86%EF%BC%88%E4%BA%8C%EF%BC%89/</id>
    <published>2019-09-09T02:26:15.000Z</published>
    <updated>2020-04-04T12:00:14.168Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>苦逼的周一开始了，苦逼的工作开始了，坐到工位上，上班气正在逐渐的减弱，但是当我发现，我的三台服务器又被那些无情的小黑人们盯上了的时候，我的怒气值达到了顶点，同时还感觉有点丢脸，哈哈哈。<br><br><br>由于这三台服务器属于我个人的，没有经过运维兄弟的照顾，所以在安全方面，基本上没有防护。<br>这次是怎么发现的呢，是因为我服务器上的爬虫突然停止了，我带着疑问去看了下系统日志。于是敲下了下面的命令<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">journalctl -xe</span><br></pre></td></tr></table></figure><p><br>映入眼帘的是满屏的扫描和ssh尝试登陆<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Failed password <span class="keyword">for</span> invalid user admin <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Received disconnect <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span>:<span class="number">11</span>: Bye Bye [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Disconnected <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span> [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Failed password <span class="keyword">for</span> invalid user ansible <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Received disconnect <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span>:<span class="number">11</span>: Bye Bye [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Disconnected <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span> [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span> port <span class="number">45157</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: error: maximum authentication attempts exceeded <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span> port <span class="number">45157</span> ssh2 [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: Disconnecting: Too many authentication failures [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: PAM <span class="number">5</span> more authentication failures; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: PAM service(sshd) ignoring max retries; <span class="number">6</span> &gt; <span class="number">3</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">52</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">310</span>]: pam_unix(sshd:auth): authentication failure; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">52</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">310</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: error: maximum authentication attempts exceeded <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2 [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Disconnecting: Too many authentication failures [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: PAM <span class="number">5</span> more authentication failures; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: PAM service(sshd) ignoring max retries; <span class="number">6</span> &gt; <span class="number">3</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">54</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">314</span>]: pam_unix(sshd:auth): authentication failure; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">54</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">314</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">lines <span class="number">1105</span><span class="number">-1127</span>/<span class="number">1127</span> (END)</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">49</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Failed password <span class="keyword">for</span> invalid user admin <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Received disconnect <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span>:<span class="number">11</span>: Bye Bye [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">303</span>]: Disconnected <span class="keyword">from</span> <span class="number">117.132</span><span class="number">.175</span><span class="number">.25</span> port <span class="number">42972</span> [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Failed password <span class="keyword">for</span> invalid user ansible <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Received disconnect <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span>:<span class="number">11</span>: Bye Bye [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">302</span>]: Disconnected <span class="keyword">from</span> <span class="number">149.56</span><span class="number">.96</span><span class="number">.78</span> port <span class="number">44980</span> [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">50</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span> port <span class="number">45157</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: error: maximum authentication attempts exceeded <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span> port <span class="number">45157</span> ssh2 [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: Disconnecting: Too many authentication failures [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: PAM <span class="number">5</span> more authentication failures; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">51</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65522</span>]: PAM service(sshd) ignoring max retries; <span class="number">6</span> &gt; <span class="number">3</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">52</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">310</span>]: pam_unix(sshd:auth): authentication failure; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">218.92</span><span class="number">.0</span><span class="number">.163</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">52</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">310</span>]: pam_succeed_if(sshd:auth): requirement <span class="string">"uid &gt;= 1000"</span> <span class="keyword">not</span> met by user <span class="string">"root"</span></span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Failed password <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: error: maximum authentication attempts exceeded <span class="keyword">for</span> root <span class="keyword">from</span> <span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span> port <span class="number">24184</span> ssh2 [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: Disconnecting: Too many authentication failures [preauth]</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: PAM <span class="number">5</span> more authentication failures; logname= uid=<span class="number">0</span> euid=<span class="number">0</span> tty=ssh ruser= rhost=<span class="number">49.88</span><span class="number">.112</span><span class="number">.54</span>  user=root</span><br><span class="line">Sep <span class="number">09</span> <span class="number">11</span>:<span class="number">02</span>:<span class="number">53</span> <span class="number">4</span>Z-J16-A47 sshd[<span class="number">65525</span>]: PAM service(sshd) ignoring max retries; <span class="number">6</span> &gt; <span class="number">3</span></span><br></pre></td></tr></table></figure><p><br>看到这里，感觉自己家的鸡，随时都要被偷走呀。。。。这还了得。于是马上开始了加固防护<br>对待这种情况，就是要禁止root用户远程登录，使用新建普通用户，进行远程登录，还有重要的一点，修改默认22端口。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@*** ~]<span class="comment"># useradd one             #创建用户</span></span><br><span class="line">[root@*** ~]<span class="comment"># passwd one              #设置密码</span></span><br></pre></td></tr></table></figure><p><br>输入新用户密码<br>首先确保文件 /etc/sudoers 中<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%wheel    ALL=(ALL)    ALL</span><br><span class="line">```  </span><br><span class="line">没有被注释</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```linux</span><br><span class="line">usermod -g wheel onerocket</span><br></pre></td></tr></table></figure><p><br>设置只有指定用户组才能使用su命令切换到root用户<br><br><br>在linux中，有一个默认的管理组 wheel。在实际生产环境中，即使我们有系统管理员root的权限，也不推荐用root用户登录。一般情况下用普通用户登录就可以了，在需要root权限执行一些操作时，再su登录成为root用户。但是，任何人只要知道了root的密码，就都可以通过su命令来登录为root用户，这无疑为系统带来了安全隐患。所以，将普通用户加入到wheel组，被加入的这个普通用户就成了管理员组内的用户。然后设置只有wheel组内的成员可以使用su命令切换到root用户。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /bin/bash</span></span><br><span class="line"><span class="comment"># Function: 修改配置文件，使得只有wheel组的用户可以使用 su 权限</span></span><br><span class="line">sed -i <span class="string">'/pam_wheel.so use_uid/c\auth            required        pam_wheel.so use_uid '</span> /etc/pam.d/su</span><br><span class="line">n=`cat /etc/login.defs | grep SU_WHEEL_ONLY | wc -l`</span><br><span class="line"><span class="keyword">if</span> [ $n -eq <span class="number">0</span> ];then</span><br><span class="line">echo SU_WHEEL_ONLY yes &gt;&gt; /etc/login.defs</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p><br>打开SSHD的配置文件<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure><p><br>查找“#PermitRootLogin yes”，将前面的“#”去掉，短尾“yes”改为“no”（不同版本可能区分大小写），并保存文件。<br><br><br>修改sshd默认端口<br>虽然更改端口无法在根本上抵御端口扫描，但是，可以在一定程度上提高防御。<br>打开sshd配置文件<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure><p><br>找到#Port 22 删掉注释<br><br><br><em>服务器端口最大可以开到65536</em><br><br><br>同时再添加一个Port 61024 （随意设置）<br><br><br>Port 22<br>Port 61024<br><br><br>重启sshd服务<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service sshd restart      <span class="comment">#centos6系列</span></span><br><span class="line">systemctl restart sshd  <span class="comment">#centos7系列</span></span><br><span class="line">firewall-cmd --add-port=<span class="number">61024</span>/tcp</span><br></pre></td></tr></table></figure><p><br>测试，使用新用户，新端口进行登录<br><br><br>如果登陆成功后，再将Port22注释掉，重启sshd服务。<br>到这里，关于远程登录的防护工作，就做好了。<br>最后，告诫大家，亲身体验，没有防护裸奔的服务器，真的太容易被抓肉鸡了！！！！！</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;苦逼的周一开始了，苦逼的工作开始了，坐到工位上，上班气正在逐渐的减弱，但是当我发现，我的三台服务器又被那些无情的小黑人们盯上了的时候，我的怒气值
      
    
    </summary>
    
    
      <category term="Linux" scheme="cpeixin.cn/categories/Linux/"/>
    
    
      <category term="服务器安全" scheme="cpeixin.cn/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>我的服务器被黑了</title>
    <link href="cpeixin.cn/2019/08/24/%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E9%BB%91%E4%BA%86/"/>
    <id>cpeixin.cn/2019/08/24/%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E9%BB%91%E4%BA%86/</id>
    <published>2019-08-24T02:26:15.000Z</published>
    <updated>2020-04-04T12:00:09.871Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p><a name="-2"></a></p><h1 id="服务器自述"><a href="#服务器自述" class="headerlink" title="服务器自述"></a>服务器自述</h1><p>我是一台8核，16G内存，4T的Linux (centOS 7)服务器… 还有两台和我一起被买来的苦主，我们一同长大，配置一样，都是从香港被贩卖到国外，我们三个组成了分布式爬虫框架，另两位苦主分别负责异步爬取连接，多进程爬取连接和scrapy-redis分布式爬取解析。<br><br><br>而我比较清闲，只负责存储. 网页链接放在我的redis中，而解析好的文章信息放在我的MySQL中。然而故事的开始，就是在安装redis的那天，主人的粗心大意，为了节省时间，从而让他今天花费了小半天来对我进行维修！！😢<br><a name="-3"></a></p><h1 id="为什么黑我的服务器"><a href="#为什么黑我的服务器" class="headerlink" title="为什么黑我的服务器"></a>为什么黑我的服务器</h1><p>这样一台配置的服务器，一个月的价格大概在1000RMB一个月，怎么说呢… 这个价格的服务器对于个人用户搭建自己玩的环境还是有些小贵的。例如我现在写博客，也是托管在GitHub上的，我也可以租用一台服务器来托管的博客，但是目前我的这种级别，也是要考虑到投入产出比是否合适，哈哈哈。<br><br><br>但是对于，服务器上运行的任务和服务产出的价值要远远大于服务器价值的时候，这1000多RMB就可以忽略不计了。同时，还有黑衣人，他们需要大量的服务器，来运行同样的程序，产出的价值他们也无法衡量，有可能很多有可能很少。。<br><br><br>那么这时候，他们为了节约成本，降低成本，就会用一些黑色的手法，例如渗透，sql注入，根据漏洞扫描等方法来 抓“肉鸡”，抓到大量的可侵入的服务器，然后在你的服务器上的某一个角落，放上他的程序，一直在运行，一直在运行，占用着你的cpu,占用着你的带宽…<br><br><br>那么上面提到的黑衣人，就有那么一类角色，“矿工”！！！！<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585404954445-f30a25a0-5939-4773-b5d9-8bb6a7c53b02.png#align=left&display=inline&height=892&name=1.png&originHeight=892&originWidth=1244&size=1778564&status=done&style=none&width=1244" alt="1.png"><br><br><br>曾经，我也专注过区块链，我也短暂的迷失在数字货币的浪潮中，但是没有吃到红利👀👀👀 就是这些数字世界的矿工，利用我服务器的漏洞黑了我的服务器<br><a name="-4"></a></p><h1 id="如何发现被黑"><a href="#如何发现被黑" class="headerlink" title="如何发现被黑"></a>如何发现被黑</h1><p>回到这篇博客的正题，我是如何发现，我的服务器被黑了呢？？<br><br><br>最近我在做scrapy分布式爬虫方面的工作，准备了三台服务器，而这台被黑的服务器是我用来做存储的，其中用到了redis和mysql。其中引发这件事情的就是redis，我在安装redis的时候，可以说责任完全在我，我为了安装节约时间，以后使用方便等，做了几个很错误的操作<br><br><br>1.关闭了Linux防火墙<br><br><br>2.没有设置redis访问密码<br><br><br>3.没有更改redis默认端口<br><br><br>4.开放了任意IP可以远程连接<br><br><br>以上四个很傻的操作,都是因为以前所用的redis都是有公司运维同事进行安装以及安全策略方面的配置，以至我这一次没有注意到安装方面。<br><br><br>当我的爬虫程序已经平稳的运行了两天了，我就开始放心了，静静地看着spider疯狂的spider,可是就是在随后，redis服务出现异常，首先是我本地客户端连接不上远程redis-server，我有想过是不是网络不稳定的问题。在我重启redis后，恢复正常，又平稳的运行了一天。<br><br><br>但是接下来redis频繁出问题，我就想，是不是爬虫爬取了大量的网页链接，对redis造成了阻塞。于是，我开启了对redis.conf，还有程序端的connect两方面360度的优化，然并卵。。。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -i tcp:<span class="number">6379</span></span><br></pre></td></tr></table></figure><p><br>使用上面的命令后，发现redis服务正常运行，6379端口也是开启的。我陷入了深深地迷惑。。。。。<br><br><br>但是这时其实就应该看出一些端倪了，因为正常占用 6379 端口的进程名是 ： redis-ser 。但是现在占用 6379 端口的进程名是 ：xmrig-no (忘记截图了)，但是这时我也没有多想<br>直到我运行：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top</span><br></pre></td></tr></table></figure><p><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585404912911-97736d80-2ee3-455d-a948-6d134f4e2663.png#align=left&display=inline&height=534&name=2.png&originHeight=534&originWidth=3338&size=980508&status=done&style=none&width=3338" alt="2.png"><br>发现了占用 6379 端口的进程全名称xmrig…，我才恍然大悟，我的端口被占用了。我在google上一查，才发现。。我被黑了<br><a name="-5"></a></p><h1 id="做了哪些急救工作"><a href="#做了哪些急救工作" class="headerlink" title="做了哪些急救工作"></a>做了哪些急救工作</h1><p>这时，感觉自己开始投入了一场对抗战<br><br><br>1.首先查找植入程序的位置。<br>在/tmp/目录下，一般植入程序都会放在 /tmp 临时目录下，其实回过头一想，放在这里，也是挺妙的。<br><br><br>2.删除清理可疑文件<br><br><br>杀死进程<br><br><br>删除了正在运行的程序文件还有安装包<br>3.查看所有用户的定时任务<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/passwd |cut -f <span class="number">1</span> -d:crontab -uXXX -l</span><br></pre></td></tr></table></figure><p><br>4.开启防火墙<br><br><br>仅开放会使用到的端口<br>5.修改redis默认端口<br><br><br>redis.conf中的port<br>6.添加redis授权密码<br><br><br>redis.conf中的requirepass<br>7.修改绑定远程绑定ip<br><br><br>redis.conf中的bind<br>最后重启redis服务！<br><a name="-6"></a></p><h1 id="从中学到了什么"><a href="#从中学到了什么" class="headerlink" title="从中学到了什么"></a>从中学到了什么</h1><p>明明是自己被黑了，但是在补救的过程中，却得到了写程序给不了的满足感。感觉因为这件事情，上帝给我打开了另一扇窗户～～～<br>最后说下，这个木马是怎么进来的呢，查了一下原来是利用Redis端口漏洞进来的，它可以对未授权访问redis的服务器登录，定时下载并执行脚本，脚本运行，挖矿，远程调用等。所以除了执行上述操作，linux服务器中的用户权限，服务权限精细化，防止再次被入侵。<br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;-2&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h1 id=&quot;服务器自述&quot;&gt;&lt;a href=&quot;#服务器自述&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
    
      <category term="Linux" scheme="cpeixin.cn/categories/Linux/"/>
    
    
      <category term="服务器安全" scheme="cpeixin.cn/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>python爬虫 - 动态爬取</title>
    <link href="cpeixin.cn/2019/06/12/python%E7%88%AC%E8%99%AB%E4%B9%8B%E5%8A%A8%E6%80%81%E7%88%AC%E5%8F%96/"/>
    <id>cpeixin.cn/2019/06/12/python%E7%88%AC%E8%99%AB%E4%B9%8B%E5%8A%A8%E6%80%81%E7%88%AC%E5%8F%96/</id>
    <published>2019-06-12T15:26:15.000Z</published>
    <updated>2020-04-04T17:11:17.062Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>我们的目的是抓取拉勾网Python分类下全国到目前为止展示出来的所有招聘信息，首先在浏览器点击进去看看吧。如果你足够小心或者网速比较慢，那么你会发现，在点击Python分类之后跳到的新页面上，招聘信息出现时间是晚于页面框架出现时间的。到这里，我们几乎可以肯定，招聘信息并不在页面HTML源码中，我们可以通过按下”command+option+u”(在Windows和Linux上的快捷键是”ctrl+u”)来查看网页源码，果然在源码中没有出现页面展示的招聘信息。<br><br><br>到这一步，我看到的大多数教程都会教，使用什么什么库，如何如何模拟浏览器环境，通过怎样怎样的方式完成网页的渲染，然后得到里面的信息…永远记住，对于爬虫程序，模拟浏览器往往是下下策，只有实在没有办法了，才去考虑模拟浏览器环境，因为那样的内存开销实在是很大，而且效率非常低。<br><br><br>那么我们怎么处理呢？经验是，这样的情况，大多是是浏览器会在请求和解析HTML之后，根据js的“指示”再发送一次请求，得到页面展示的内容，然后通过js渲染之后展示到界面。好消息是，这样的请求往往得到的内容是json格式的，所以我们非但不会加重爬虫的任务，反而可能会省去解析HTML的功夫。<br><br><br>那个，继续打开Chrome的开发者工具，当我们点击“下一页”之后，浏览器发送了如下请求：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585401843101-98e57df8-c124-4923-aa9f-7c42ce2288b6.png#align=left&display=inline&height=1300&originHeight=1300&originWidth=3356&size=0&status=done&style=none&width=3356" alt><br><br><br>注意观察”positionAjax.json”这个请求，它的Type是”xhr”，全称叫做”XMLHttpRequest”，XMLHttpRequest对象可以在不向服务器提交整个页面的情况下，实现局部更新网页。那么，现在它的可能性最大了，我们单击它之后好好观察观察吧：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585401843056-e12f0f79-905f-4420-abfd-fb85625767ac.png#align=left&display=inline&height=1150&originHeight=1150&originWidth=2266&size=0&status=done&style=none&width=2266" alt><br><br><br>点击之后我们在右下角发现了如上详情，其中几个tab的内容表示：<br>Headers：请求和响应的详细信息<br>Preview：响应体格式化之后的显示<br>Response：响应体原始内容<br>Cookies：Cookies<br>Timing：时间开销<br><br><br>通过对内容的观察，返回的确实是一个json字符串，内容包括本页每一个招聘信息，到这里至少我们已经清楚了，确实不需要解析HTML就可以拿到拉钩招聘的信息了。那么，请求该如何模拟呢？我们切换到Headers这一栏，留意三个地方：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585401842263-072689cf-5dea-4f8b-b103-0758d9c5e52e.png#align=left&display=inline&height=262&originHeight=262&originWidth=1276&size=0&status=done&style=none&width=1276" alt><br><br><br>上面的截图展示了这次请求的请求方式、请求地址等信息。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585401843887-cf8bff5f-4570-4ad4-8681-f0f3eae929b3.png#align=left&display=inline&height=884&originHeight=884&originWidth=2652&size=0&status=done&style=none&width=2652" alt><br><br><br>上面的截图展示了这次请求的请求头，一般来讲，其中我们需要关注的是Cookie / Host / Origin / Referer / User-Agent / X-Requested-With等参数。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585401843009-4797a28d-3070-421e-a45c-86781d7f580d.png#align=left&display=inline&height=188&originHeight=188&originWidth=848&size=0&status=done&style=none&width=848" alt><br><br><br>上面这张截图展示了这次请求的提交数据，根据观察，kd表示我们查询的关键字，pn表示当前页码。<br><br><br>那么，我们的爬虫需要做的事情，就是按照页码不断向这个接口发送请求，并解析其中的json内容，将我们需要的值存储下来就好了。这里有两个问题：什么时候结束，以及如何的到json中有价值的内容。<br><br><br>我们回过头重新观察一下返回的json，格式化之后的层级关系如下：<br><br><br>很容易发现，content下的hasNextPage即为是否存在下一页，而content下的result是一个list，其中的每项则是一条招聘信息。在Python中，json字符串到对象的映射可以通过json这个库完成：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">json_obj = json.loads(<span class="string">"&#123;'key': 'value'&#125;"</span>)  <span class="comment"># 字符串到对象</span></span><br><span class="line">json_str = json.dumps(json_obj)            <span class="comment"># 对象到字符串</span></span><br></pre></td></tr></table></figure><p><br>json字符串的”[ ]“映射到Python的类型是list，”{ }”映射到Python则是dict。到这里，分析过程已经完全结束，可以愉快的写代码啦。具体代码这里不再给出，希望你可以自己独立完成，如果在编写过程中存在问题，可以联系我获取帮助。<br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;我们的目的是抓取拉勾网Python分类下全国到目前为止展示出来的所有招聘信息，首先在浏览器点击进去看看吧。如果你足够小心或者网速比较慢，那么你会
      
    
    </summary>
    
    
      <category term="python" scheme="cpeixin.cn/categories/python/"/>
    
    
      <category term="爬虫" scheme="cpeixin.cn/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>shadowsock-vps搭建VPN</title>
    <link href="cpeixin.cn/2019/04/19/shadowsock-vps%E6%90%AD%E5%BB%BAVPN/"/>
    <id>cpeixin.cn/2019/04/19/shadowsock-vps%E6%90%AD%E5%BB%BAVPN/</id>
    <published>2019-04-19T15:26:15.000Z</published>
    <updated>2020-04-04T17:11:07.011Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p><a name="-1"></a></p><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>还有10天左右就要回国了，由于职业的需要，对Google的依赖的越来越大的，那么回国后怎么才能‘科学上网’呢？之前在国内的时候，有使用过Lantern，稳定性和速度都还是不错了，可惜后来被和谐了。所以今天准备尝试搭建VPN，自己独立使用，一边搭建一边将过程记录下来。<br><a name="-2"></a></p><h1 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h1><p>VPS: VPS（Virtual Private Server 虚拟专用服务器）技术，将一台服务器分割成多个虚拟专享服务器的优质服务。实现VPS的技术分为容器 [1] 技术，和虚拟化技术 [2] 。在容器或虚拟机中，每个VPS都可分配独立公网IP地址、独立操作系统、实现不同VPS间磁盘空间、内存、CPU资源、进程和系统配置的隔离，为用户和应用程序模拟出“独占”使用计算资源的体验。VPS可以像独立服务器一样，重装操作系统，安装程序，单独重启服务器。<br><br><br>VPS为使用者提供了管理配置的自由，可用于企业虚拟化，也可以用于IDC资源租用。<br><br><br>VPN: VPN的学名叫虚拟专用网，洋文叫“Virtual Private Network”。维基百科的介绍在“这里”。本来这玩意儿主要是用于商业公司，为了让那些不在公司里的员工（比如出差在外的）能够方便地访问公司的内部网络。为了防止黑客冒充公司的员工，从外部访问公司的内部网络，VPN 软件都会提供强大的加密功能。而这个加密功能，也就让它顺便成为翻墙的利器。<br><a name="-3"></a></p><h1 id="科学上网原理"><a href="#科学上网原理" class="headerlink" title="科学上网原理"></a>科学上网原理</h1><p>VPN浏览外网的原理<br><br><br>使用 VPN 通常需要先安装客户端软件。当你运行 VPN 客户端，它会尝试联到 VPN 服务器（这点跟加密代理类似）。一旦和 VPN 服务器建立连接，VPN 客户端就会在你的系统中建立了一个虚拟局域网。而且，你的系统中也会多出一个虚拟网卡（在 Windows 下，可以用 ipconfig /all 命令，看到这多出来的网卡）。这样一来，你的系统中就有不止一块网卡。这就引出一个问题：那些访问网络的程序，它的数据流应该通过哪个网卡进出？<br>为了解决此问题，VPN 客户端通常会修改你系统的路由表，让那些数据流，优先从虚拟的网卡进出。由于虚拟的网卡是通往 VPN 服务器的，当数据流到达 VPN 服务器之后，VPN 服务器再帮你把数据流转向到真正的目的地。<br><br><br>前面说了，VPN 为了保证安全，都采用强加密的方式传输数据。这样一来，GFW 就无法分析你的网络数据流，进行敏感词过滤。所以，使用墙外的VPN服务器，无形中就能达到翻墙的效果。<br><a name="-4"></a></p><h1 id="方案选择"><a href="#方案选择" class="headerlink" title="方案选择"></a>方案选择</h1><p>VPN是一个大类，其中有很多实现的方法，防火长城现在将 VPN 屏蔽的已经所剩无几，后来大家看到了SSH，使用SSH的sock5很稳定，但是特征也十分明显，防火长城可以对其直接进行定向干扰。<br><br><br>而除了VPN，对于翻墙大家仍然有很多方法，比如Shadowsocks 、Lantern、VPNGate 等等，而实际上无论哪种方式，他们本身都需要一台服务器作为中间人进行消息传递。而VPS虚拟专用服务器就十分适合担当这个角色，并且由于VPS平时就作为商品在各类云服务器平台上售卖，自行购买并搭建相当方便，唯一需要的就是人们对于服务器的操作技术。<br><br><br><strong>而这次选择的方案是：VPS+Shadowsocks</strong><br>**<br>Shadowsocks特点：<br><br><br>省电，在电量查看里几乎看不到它的身影；<br><br><br>支持开机自启动，且断网无影响，无需手动重连，方便网络不稳定或者3G&amp;Wi-Fi频繁切换的小伙伴；<br><br><br>可使用自己的服务器，安全和速度的保证；<br><br><br>支持区分国内外流量，传统VPN在翻出墙外后访问国内站点会变慢；<br><br><br>可对应用设置单独代理，5.0之后的系统无需root。<br><br><br>Shadowsocks 目前不容易被封杀主要是因为：<br>建立在socks5协议之上，socks5是运用很广泛的协议，所以没办法直接封杀socks5协议<br>使用socks5协议建立连接，而没有使用VPN中的服务端身份验证和密钥协商过程。而是在服务端和客户端直接写死密钥和加密算法。所以防火墙很难找到明显的特征，因为这就是个普通的socks5协议。<br><br><br>Shadowsock搭建也比较简单，所以很多人自己架设VPS搭建，个人使用流量也很小，没法通过流量监控方式封杀。<br>自定义加密方式和密钥。因为加密主要主要是防止被检测，所以要选择安全系数高的加密方式。之前RC4会很容易被破解，而导致被封杀。所以现在推荐使用AES加密。而在客户端和服务端自定义密钥，泄露的风险相对较小。<br>所以如果是自己搭建的Shadosocks被封的概率很小，但是如果是第三方的Shadeowsocks，密码是server定的，你的数据很可能遭受到中间人攻击。<br><a name="-5"></a></p><h1 id="开工"><a href="#开工" class="headerlink" title="开工"></a>开工</h1><p><a name="vps"></a></p><h2 id="购买vps"><a href="#购买vps" class="headerlink" title="购买vps"></a>购买vps</h2><p>首先我们需要购买一台境外的服务器，接着我们在这台云服务器里面安装代理服务，那么以后我们上网的时候就可以通过它来中转，轻松畅快的畅游全网了。<br>购买VPS,我选择了<a href="https://www.vultr.com/" target="_blank" rel="external nofollow noopener noreferrer">vultr</a>，大家用过都说好，购买的过程也很方便。<br><br><br>第一步：选择离中国较近国家的服务器。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400540784-be727007-a613-4b5b-a3d5-9b5fbf9734a7.png#align=left&display=inline&height=1468&name=step1.png&originHeight=1468&originWidth=3066&size=659813&status=done&style=none&width=3066" alt="step1.png"><br><br><br><br><br>第二步：选择服务器配置和系统<br><br><br>这里，系统选择的是CentOS 7,配置的话，如果只是自己浏览网页的话，选择最低配置就好。其他的选项可以略过。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400556831-e2446e46-8c7e-4292-97a8-b89e6d983c9c.png#align=left&display=inline&height=1594&name=step2.png&originHeight=1594&originWidth=2792&size=669959&status=done&style=none&width=2792" alt="step2.png"><br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235703-e6afdea2-828f-42a0-a955-67960c8710bc.png#align=left&display=inline&height=1812&originHeight=1812&originWidth=2600&size=0&status=done&style=none&width=2600" alt><br><br><br>第三步：支付和部署<br><br><br>支付可以选择支付宝支付，非常方便。购买成功后，点击Server中的“+”号，来部署你刚刚选择的服务器。<br>第四步：登陆服务器<br><br><br>查看服务器详情 Server Details,根据提供的服务器信息，登陆服务器。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235150-95a87ca7-8392-404e-a5d9-c4a606b8ae7e.png#align=left&display=inline&height=1166&originHeight=1166&originWidth=2728&size=0&status=done&style=none&width=2728" alt><br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235639-e36e0afa-200d-49ad-a324-350004d08d09.png#align=left&display=inline&height=1232&originHeight=1232&originWidth=2612&size=0&status=done&style=none&width=2612" alt><br><br><br>我是使用Mac本身终端ssh到服务器上的，因为Mac上多数的SSH客户端要么收费，要么不好用，要么安装过程非常繁琐。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p <span class="number">22</span> root@ip</span><br></pre></td></tr></table></figure><p><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235316-408c45f7-df95-4c8c-9428-9f476c6c7190.png#align=left&display=inline&height=244&originHeight=244&originWidth=1304&size=0&status=done&style=none&width=1304" alt><br><a name="shadowsocks"></a></p><h2 id="搭建shadowsocks服务器"><a href="#搭建shadowsocks服务器" class="headerlink" title="搭建shadowsocks服务器"></a>搭建shadowsocks服务器</h2><p>连接到你的 vultr 服务器之后，接下来就可以使用几个命令让你快速搭建一个属于自己的 ss 服务器：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install wget</span><br></pre></td></tr></table></figure><p><br>接着执行安装shadowsocks：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget –no-check-certificate -O shadowsocks.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh</span><br></pre></td></tr></table></figure><p><br>获取 <a href="http://shadowsocks.sh/" target="_blank" rel="external nofollow noopener noreferrer">shadowsocks.sh</a> 读取权限：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x shadowsocks.sh</span><br></pre></td></tr></table></figure><p><br>设置你的 ss 密码和端口号：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./shadowsocks.sh <span class="number">2</span>&gt;&amp;<span class="number">1</span> | tee shadowsocks.log</span><br></pre></td></tr></table></figure><p><br>接下来后就可以设置密码和端口号了<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400236071-267db22c-ea03-4f8b-969d-86ae5efc4d68.png#align=left&display=inline&height=306&originHeight=306&originWidth=1086&size=0&status=done&style=none&width=1086" alt><br><br><br>密码和端口号可以使用默认的，也可以直接重新输入新的。<br>选择加密方式<br><br><br>设置完密码和端口号之后，我们选择加密方式，这里选择 7 ，使用aes-256-cfb的加密模式<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235435-525e1564-eb61-47e0-b9b1-a28683979702.png#align=left&display=inline&height=684&originHeight=684&originWidth=914&size=0&status=done&style=none&width=914" alt><br><br><br>接着按任意键进行安装。<br>安装ss完成后<br><br><br>会给你显示你需要连接 vpn 的信息：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400239145-4d70810e-bc73-4cfa-bc8c-4da35e3e0dcf.png#align=left&display=inline&height=464&originHeight=464&originWidth=1186&size=0&status=done&style=none&width=1186" alt><br>搞定，将这些信息保存起来，那么这时候你就可以使用它们来科学上网啦。<br><a name="bbr"></a></p><h2 id="使用BBR加速上网"><a href="#使用BBR加速上网" class="headerlink" title="使用BBR加速上网"></a>使用BBR加速上网</h2><p>安装 BBR<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh</span><br></pre></td></tr></table></figure><p><br>获取读写权限<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x bbr.sh</span><br></pre></td></tr></table></figure><p><br>启动BBR安装<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bbr.sh</span><br></pre></td></tr></table></figure><p><br>接着按任意键，开始安装，坐等一会。安装完成一会之后它会提示我们是否重新启动vps，我们输入 y 确定重启服务器。<br>重新启动之后，输入：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep bbr</span><br></pre></td></tr></table></figure><p><br>如果看到 tcp_bbr 就说明 BBR 已经启动了。<br><a name="-6"></a></p><h2 id="客户端进行连接"><a href="#客户端进行连接" class="headerlink" title="客户端进行连接"></a>客户端进行连接</h2><p><a name="windowsshadowsocks"></a></p><h3 id="windows使用Shadowsocks"><a href="#windows使用Shadowsocks" class="headerlink" title="windows使用Shadowsocks"></a>windows使用Shadowsocks</h3><p>windows点击下载：<a href="https://pan.baidu.com/s/19m0AfTkPDSRj0bfYrGpbIg" target="_blank" rel="external nofollow noopener noreferrer">Shadowsocks windows客户端</a><br>打开 Shadowsocks 客户端，输入ip地址，密码，端口，和加密方式。接着点击确定，右下角会有个小飞机按钮，右键–&gt;启动代理。<br><a name="androidshadowsocks"></a></p><h3 id="Android使用Shadowsocks"><a href="#Android使用Shadowsocks" class="headerlink" title="Android使用Shadowsocks"></a>Android使用Shadowsocks</h3><p>Android点击下载：<a href="https://pan.baidu.com/s/1coAkZn-GuYHu5eIKaHECxA" target="_blank" rel="external nofollow noopener noreferrer">Shadowsocks Android客户端</a><br>打开apk安装，接着打开APP，输入ip地址，密码，端口，和加密方式。即可科学上网。<br><a name="iphoneshadowsocks"></a></p><h3 id="iPhone使用Shadowsocks"><a href="#iPhone使用Shadowsocks" class="headerlink" title="iPhone使用Shadowsocks"></a>iPhone使用Shadowsocks</h3><p>iPhone要下载的app需要在appstore下载，但是需要用美区账号才能下载，而且这个APP需要钱。在这里提供一种解决方案，就是可以再搭建一个<a href="https://wistbean.github.io/ipsec,l2tp_vpn.html#%E4%BD%BF%E7%94%A8-IPsec-L2TP-%E8%84%9A%E6%9C%AC%E6%90%AD%E5%BB%BA" target="_blank" rel="external nofollow noopener noreferrer">IPsec/L2TP</a> VPN,专门给你的iPhone使用。<br><a name="mac"></a></p><h3 id="Mac配置"><a href="#Mac配置" class="headerlink" title="Mac配置"></a>Mac配置</h3><p>用的是Mac电脑，所以点击相关链接。东西都挂在github上，下载对应的zip文件，下载完成后安装并运行起来。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235178-7ccd25cd-8b34-4103-8cc8-204e84672cfe.png#align=left&display=inline&height=748&originHeight=748&originWidth=1302&size=0&status=done&style=none&width=1302" alt><br><br><br>点击图标，进入 服务器设置<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400239120-45698c54-ac3b-48b9-9c4d-9f3537938f87.png#align=left&display=inline&height=926&originHeight=926&originWidth=1302&size=0&status=done&style=none&width=1302" alt><br><br><br>主要有四个地方要填，服务器的地址，端口号，加密方法，密码。服务器地址即为之前 Main controls选项中的IP地址。端口号、加密方法、密码必须与之前 Shadowsocks Server 中的信息一一匹配，否则会连接失败。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585400235629-2861fc8f-5bfc-4610-993f-49064774e693.png#align=left&display=inline&height=1156&originHeight=1156&originWidth=1292&size=0&status=done&style=none&width=1292" alt><br><br><br>设置完成后点击确定，然后服务器选择这个配置，默认选中PAC自动模式，确保Shadowsocks状态为On，这时候打开谷歌试试~<br>接着就可以上外网了 😂</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;a name=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="工具" scheme="cpeixin.cn/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="shadowsock" scheme="cpeixin.cn/tags/shadowsock/"/>
    
  </entry>
  
  <entry>
    <title>比特币走势预测</title>
    <link href="cpeixin.cn/2019/04/05/%E6%AF%94%E7%89%B9%E5%B8%81%E8%B5%B0%E5%8A%BF%E9%A2%84%E6%B5%8B/"/>
    <id>cpeixin.cn/2019/04/05/%E6%AF%94%E7%89%B9%E5%B8%81%E8%B5%B0%E5%8A%BF%E9%A2%84%E6%B5%8B/</id>
    <published>2019-04-04T16:43:58.000Z</published>
    <updated>2020-04-22T15:26:53.858Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>我们之前介绍了数据挖掘算法中的分类、聚类、回归和关联分析算法，那么对于比特币走势的预测，采用哪种方法比较好呢？<br><br><br>可能有些人会认为采用回归分析会好一些，因为预测的结果是连续的数值类型。实际上，数据挖掘算法还有一种叫时间序列分析的算法，时间序列分析模型建立了观察结果与时间变化的关系，能帮我们预测未来一段时间内的结果变化情况。那么时间序列分析和回归分析有哪些区别呢？<br><br><br>首先，在选择模型前，我们需要确定结果与变量之间的关系。回归分析训练得到的是目标变量 y 与自变量 x（一个或多个）的相关性，然后通过新的自变量 x 来预测目标变量 y。而时间序列分析得到的是目标变量 y 与时间的相关性。<br><br><br>另外，回归分析擅长的是多变量与目标结果之间的分析，即便是单一变量，也往往与时间无关。而时间序列分析建立在时间变化的基础上，它会分析目标变量的趋势、周期、时期和不稳定因素等。这些趋势和周期都是在时间维度的基础上，我们要观察的重要特征。<br><br><br>那么针对今天要进行的预测比特币走势的项目，我们都需要掌握哪些目标呢？</p><ol><li>了解时间序列预测的概念，以及常用的模型算法，包括 AR、MA、ARMA、ARIMA 模型等；</li><li>掌握并使用 ARMA 模型工具，对一个时间序列数据进行建模和预测；</li><li>对比特币的历史数据进行时间序列建模，并预测未来 6 个月的走势。</li></ol><p><a name="cFXtt"></a></p><h3 id="时间序列预测"><a href="#时间序列预测" class="headerlink" title="时间序列预测"></a>时间序列预测</h3><p>关于时间序列，你可以把它理解为按照时间顺序组成的数字序列。实际上在中国古代的农业社会中，人们就将一年中不同时间节点和天气的规律总结了下来，形成了二十四节气，也就是从时间序列中观察天气和太阳的规律（只是当时没有时间序列模型和相应工具），从而使得农业得到迅速发展。</p><p>在现代社会，时间序列在金融、经济、商业领域拥有广泛的应用。在时间序列预测模型中，有一些经典的模型，包括 AR、MA、ARMA、ARIMA。我来给你简单介绍一下。</p><p>AR 的英文全称叫做 Auto Regressive，中文叫自回归模型。这个算法的思想比较简单，它认为过去若干时刻的点通过线性组合，再加上白噪声就可以预测未来某个时刻的点。在我们日常生活环境中就存在白噪声，在数据挖掘的过程中，你可以把它理解为一个期望为 0，方差为常数的纯随机过程。AR 模型还存在一个阶数，称为 AR（p）模型，也叫作 p 阶自回归模型。它指的是通过这个时刻点的前 p 个点，通过线性组合再加上白噪声来预测当前时刻点的值。</p><p>MA 的英文全称叫做 Moving Average，中文叫做滑动平均模型。它与 AR 模型大同小异，AR 模型是历史时序值的线性组合，MA 是通过历史白噪声进行线性组合来影响当前时刻点。AR 模型中的历史白噪声是通过影响历史时序值，从而间接影响到当前时刻点的预测值。同样 MA 模型也存在一个阶数，称为 MA(q) 模型，也叫作 q 阶移动平均模型。我们能看到 AR 和 MA 模型都存在阶数，在 AR 模型中，我们用 p 表示，在 MA 模型中我们用 q 表示，这两个模型大同小异，与 AR 模型不同的是 MA 模型是历史白噪声的线性组合。</p><p>ARMA 的英文全称是 Auto Regressive Moving Average，中文叫做自回归滑动平均模型，也就是 AR 模型和 MA 模型的混合。相比 AR 模型和 MA 模型，它有更准确的估计。同样 ARMA 模型存在 p 和 q 两个阶数，称为 ARMA(p,q) 模型。</p><p>ARIMA 的英文全称是 Auto Regressive Integrated Moving Average 模型，中文叫差分自回归滑动平均模型，也叫求合自回归滑动平均模型。相比于 ARMA，ARIMA 多了一个差分的过程，作用是对不平稳数据进行差分平稳，在差分平稳后再进行建模。ARIMA 的原理和ARMA 模型一样。相比于 ARMA(p,q) 的两个阶数，ARIMA 是一个三元组的阶数 (p,d,q)，称为 ARIMA(p,d,q) 模型。其中 d 是差分阶数。<br><br><br></p><p><a name="3RhDh"></a></p><h3 id="ARMA-模型工具"><a href="#ARMA-模型工具" class="headerlink" title="ARMA 模型工具"></a>ARMA 模型工具</h3><p>上面介绍的 AR，MA，ARMA，ARIMA 四种模型，你只需要了解基础概念即可，中间涉及到的一些数学公式这里不进行展开。在实际工作中，我们更多的是使用工具，我在这里主要讲解下如何使用 ARMA 模型工具。在使用 ARMA 工具前，你需要先引用相关工具包：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> statsmodels.tsa.arima_model <span class="keyword">import</span> ARMA</span><br></pre></td></tr></table></figure><p><br>然后通过 ARMA(endog,order,exog=None) 创建 ARMA 类，这里有一些主要的参数简单说明下：<br><br><br>endog：英文是 endogenous variable，代表内生变量，又叫非政策性变量，它是由模型决定的，不被政策左右，可以说是我们想要分析的变量，或者说是我们这次项目中需要用到的变量。<br><br><br>order：代表是 p 和 q 的值，也就是 ARMA 中的阶数。<br><br><br>exog：英文是 exogenous variables，代表外生变量。外生变量和内生变量一样是经济模型中的两个重要变量。相对于内生变量而言，外生变量又称作为政策性变量，在经济机制内受外部因素的影响，不是我们模型要研究的变量。<br><br><br>举个例子，如果我们想要创建 ARMA(7,0) 模型，可以写成：ARMA(data,(7,0))，其中 data 是我们想要观察的变量，(7,0) 代表 (p,q) 的阶数。创建好之后，我们可以通过 fit 函数进行拟合，通过 predict(start, end) 函数进行预测，其中 start 为预测的起始时间，end 为预测的终止时间。下面我们使用 ARMA 模型对一组时间序列做建模，代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="comment"># 用ARMA进行时间序列预测</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">from</span> statsmodels.tsa.arima_model <span class="keyword">import</span> ARMA</span><br><span class="line"><span class="keyword">from</span> statsmodels.graphics.api <span class="keyword">import</span> qqplot</span><br><span class="line"><span class="comment"># 创建数据</span></span><br><span class="line">data = [<span class="number">5922</span>, <span class="number">5308</span>, <span class="number">5546</span>, <span class="number">5975</span>, <span class="number">2704</span>, <span class="number">1767</span>, <span class="number">4111</span>, <span class="number">5542</span>, <span class="number">4726</span>, <span class="number">5866</span>, <span class="number">6183</span>, <span class="number">3199</span>, <span class="number">1471</span>, <span class="number">1325</span>, <span class="number">6618</span>, <span class="number">6644</span>, <span class="number">5337</span>, <span class="number">7064</span>, <span class="number">2912</span>, <span class="number">1456</span>, <span class="number">4705</span>, <span class="number">4579</span>, <span class="number">4990</span>, <span class="number">4331</span>, <span class="number">4481</span>, <span class="number">1813</span>, <span class="number">1258</span>, <span class="number">4383</span>, <span class="number">5451</span>, <span class="number">5169</span>, <span class="number">5362</span>, <span class="number">6259</span>, <span class="number">3743</span>, <span class="number">2268</span>, <span class="number">5397</span>, <span class="number">5821</span>, <span class="number">6115</span>, <span class="number">6631</span>, <span class="number">6474</span>, <span class="number">4134</span>, <span class="number">2728</span>, <span class="number">5753</span>, <span class="number">7130</span>, <span class="number">7860</span>, <span class="number">6991</span>, <span class="number">7499</span>, <span class="number">5301</span>, <span class="number">2808</span>, <span class="number">6755</span>, <span class="number">6658</span>, <span class="number">7644</span>, <span class="number">6472</span>, <span class="number">8680</span>, <span class="number">6366</span>, <span class="number">5252</span>, <span class="number">8223</span>, <span class="number">8181</span>, <span class="number">10548</span>, <span class="number">11823</span>, <span class="number">14640</span>, <span class="number">9873</span>, <span class="number">6613</span>, <span class="number">14415</span>, <span class="number">13204</span>, <span class="number">14982</span>, <span class="number">9690</span>, <span class="number">10693</span>, <span class="number">8276</span>, <span class="number">4519</span>, <span class="number">7865</span>, <span class="number">8137</span>, <span class="number">10022</span>, <span class="number">7646</span>, <span class="number">8749</span>, <span class="number">5246</span>, <span class="number">4736</span>, <span class="number">9705</span>, <span class="number">7501</span>, <span class="number">9587</span>, <span class="number">10078</span>, <span class="number">9732</span>, <span class="number">6986</span>, <span class="number">4385</span>, <span class="number">8451</span>, <span class="number">9815</span>, <span class="number">10894</span>, <span class="number">10287</span>, <span class="number">9666</span>, <span class="number">6072</span>, <span class="number">5418</span>]</span><br><span class="line">data=pd.Series(data)</span><br><span class="line">data_index = sm.tsa.datetools.dates_from_range(<span class="string">'1901'</span>,<span class="string">'1990'</span>)</span><br><span class="line"><span class="comment"># 绘制数据图</span></span><br><span class="line">data.index = pd.Index(data_index)</span><br><span class="line">data.plot(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 创建ARMA模型# 创建ARMA模型</span></span><br><span class="line">arma = ARMA(data,(<span class="number">7</span>,<span class="number">0</span>)).fit()</span><br><span class="line">print(<span class="string">'AIC: %0.4lf'</span> %arma.aic)</span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">predict_y = arma.predict(<span class="string">'1990'</span>, <span class="string">'2000'</span>)</span><br><span class="line"><span class="comment"># 预测结果绘制</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = data.ix[<span class="string">'1901'</span>:].plot(ax=ax)</span><br><span class="line">predict_y.plot(ax=ax)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1587566465755-51d3a226-d74c-47a7-83a2-3f19889b168c.png#align=left&display=inline&height=1153&margin=%5Bobject%20Object%5D&name=71c5fe77926ba65e4b4aca48c337c66a.png&originHeight=1153&originWidth=1726&size=295229&status=done&style=none&width=1726" alt="71c5fe77926ba65e4b4aca48c337c66a.png">)<img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1587566483385-5c01d718-1103-4b3b-be36-1f1bc4e0d11d.png#align=left&display=inline&height=1131&margin=%5Bobject%20Object%5D&name=082ff6d7e85e176b8fd5c38f528314fc.png&originHeight=1131&originWidth=1727&size=291062&status=done&style=none&width=1727" alt="082ff6d7e85e176b8fd5c38f528314fc.png"><br><br><br>我创建了 1901 年 -1990 年之间的时间序列数据 data，然后创建 ARMA(7,0) 模型，并传入时间序列数据 data，使用 fit 函数拟合，然后对 1990 年 -2000 年之间的数据进行预测，最后绘制预测结果。<br><br><br>你能看到 ARMA 工具的使用还是很方便的，只是我们需要 p 和 q 的取值。实际项目中，我们可以给 p 和 q 指定一个范围，让 ARMA 都运行一下，然后选择最适合的模型。<br><br><br>你可能会问，怎么判断一个模型是否适合？我们需要引入 AIC 准则，也叫作赤池消息准则，它是衡量统计模型拟合好坏的一个标准，数值越小代表模型拟合得越好。在这个例子中，你能看到 ARMA(7,0) 这个模型拟合出来的 AIC 是 1619.6323（并不一定是最优）。<br></p><p><a name="NqVK6"></a></p><h3 id="对比特币走势进行预测"><a href="#对比特币走势进行预测" class="headerlink" title="对比特币走势进行预测"></a>对比特币走势进行预测</h3><p><br>我们都知道比特币的走势除了和历史数据以外，还和很多外界因素相关，比如用户的关注度，各国的政策，币圈之间是否打架等等。当然这些外界的因素不是我们这节课需要考虑的对象。假设我们只考虑比特币以往的历史数据，用 ARMA 这个时间序列模型预测比特币的走势。比特币历史数据（从 2012-01-01 到 2018-10-31）可以从 GitHub 上下载：<a href="https://github.com/cystanford/bitcoin。" target="_blank" rel="external nofollow noopener noreferrer">https://github.com/cystanford/bitcoin。</a><br><br><br>你能看到数据一共包括了 8 个字段，代表的含义如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1587566670077-1f6dd13e-fd86-40c8-8be1-f125067a6e36.png#align=left&display=inline&height=288&margin=%5Bobject%20Object%5D&name=b0db4047723ec5e649240e2a87196a36%20%281%29.png&originHeight=288&originWidth=468&size=33146&status=done&style=none&width=468" alt="b0db4047723ec5e649240e2a87196a36 (1).png"><br>我们的目标是构造 ARMA 时间序列模型，预测比特币（平均）价格走势。p 和 q 参数具体选择多少呢？我们可以设置一个区间范围，然后选择 AIC 最低的 ARMA 模型。<br><br><br>首先我们需要加载数据。在准备阶段，我们需要先探索数据，采用数据可视化方式查看比特币的历史走势。按照不同的时间尺度（天，月，季度，年）可以将数据压缩，得到不同尺度的数据，然后做可视化呈现。<br><br><br>这 4 个时间尺度上，我们选择月作为预测模型的时间尺度，相应的，我们选择 Weighted_Price 这个字段的数值作为观察结果，在原始数据中，Weighted_Price 对应的是比特币每天的平均价格，当我们以“月”为单位进行压缩的时候，对应的 Weighted_Price 得到的就是当月的比特币平均价格。压缩代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_month = df.resample(<span class="string">'M'</span>).mean()</span><br></pre></td></tr></table></figure><p>最后在预测阶段创建 ARMA 时间序列模型。我们并不知道 p 和 q 取什么值时，模型最优，因此我们可以给它们设置一个区间范围，比如都是 range(0,3)，然后计算不同模型的 AIC 数值，选择最小的 AIC 数值对应的那个 ARMA 模型。最后用这个最优的 ARMA 模型预测未来 8 个月的比特币平均价格走势，并将结果做可视化呈现。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 比特币走势预测，使用时间序列ARMA</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> statsmodels.tsa.arima_model <span class="keyword">import</span> ARMA</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> product</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"><span class="comment"># 数据加载</span></span><br><span class="line">df = pd.read_csv(<span class="string">'./bitcoin_2012-01-01_to_2018-10-31.csv'</span>)</span><br><span class="line"><span class="comment"># 将时间作为df的索引</span></span><br><span class="line">df.Timestamp = pd.to_datetime(df.Timestamp)</span><br><span class="line">df.index = df.Timestamp</span><br><span class="line"><span class="comment"># 数据探索</span></span><br><span class="line">print(df.head())</span><br><span class="line"><span class="comment"># 按照月，季度，年来统计</span></span><br><span class="line">df_month = df.resample(<span class="string">'M'</span>).mean()</span><br><span class="line">df_Q = df.resample(<span class="string">'Q-DEC'</span>).mean()</span><br><span class="line">df_year = df.resample(<span class="string">'A-DEC'</span>).mean()</span><br><span class="line"><span class="comment"># 按照天，月，季度，年来显示比特币的走势</span></span><br><span class="line">fig = plt.figure(figsize=[<span class="number">15</span>, <span class="number">7</span>])</span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>]=[<span class="string">'SimHei'</span>] <span class="comment">#用来正常显示中文标签</span></span><br><span class="line">plt.suptitle(<span class="string">'比特币金额（美金）'</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.plot(df.Weighted_Price, <span class="string">'-'</span>, label=<span class="string">'按天'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.plot(df_month.Weighted_Price, <span class="string">'-'</span>, label=<span class="string">'按月'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(df_Q.Weighted_Price, <span class="string">'-'</span>, label=<span class="string">'按季度'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.plot(df_year.Weighted_Price, <span class="string">'-'</span>, label=<span class="string">'按年'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 设置参数范围</span></span><br><span class="line">ps = range(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">qs = range(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">parameters = product(ps, qs)</span><br><span class="line">parameters_list = list(parameters)</span><br><span class="line"><span class="comment"># 寻找最优ARMA模型参数，即best_aic最小</span></span><br><span class="line">results = []</span><br><span class="line">best_aic = float(<span class="string">"inf"</span>) <span class="comment"># 正无穷</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> parameters_list:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        model = ARMA(df_month.Weighted_Price,order=(param[<span class="number">0</span>], param[<span class="number">1</span>])).fit()</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        print(<span class="string">'参数错误:'</span>, param)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    aic = model.aic</span><br><span class="line">    <span class="keyword">if</span> aic &lt; best_aic:</span><br><span class="line">        best_model = model</span><br><span class="line">        best_aic = aic</span><br><span class="line">        best_param = param</span><br><span class="line">    results.append([param, model.aic])</span><br><span class="line"><span class="comment"># 输出最优模型</span></span><br><span class="line">result_table = pd.DataFrame(results)</span><br><span class="line">result_table.columns = [<span class="string">'parameters'</span>, <span class="string">'aic'</span>]</span><br><span class="line">print(<span class="string">'最优模型: '</span>, best_model.summary())</span><br><span class="line"><span class="comment"># 比特币预测</span></span><br><span class="line">df_month2 = df_month[[<span class="string">'Weighted_Price'</span>]]</span><br><span class="line">date_list = [datetime(<span class="number">2018</span>, <span class="number">11</span>, <span class="number">30</span>), datetime(<span class="number">2018</span>, <span class="number">12</span>, <span class="number">31</span>), datetime(<span class="number">2019</span>, <span class="number">1</span>, <span class="number">31</span>), datetime(<span class="number">2019</span>, <span class="number">2</span>, <span class="number">28</span>), datetime(<span class="number">2019</span>, <span class="number">3</span>, <span class="number">31</span>), </span><br><span class="line">             datetime(<span class="number">2019</span>, <span class="number">4</span>, <span class="number">30</span>), datetime(<span class="number">2019</span>, <span class="number">5</span>, <span class="number">31</span>), datetime(<span class="number">2019</span>, <span class="number">6</span>, <span class="number">30</span>)]</span><br><span class="line">future = pd.DataFrame(index=date_list, columns= df_month.columns)</span><br><span class="line">df_month2 = pd.concat([df_month2, future])</span><br><span class="line">df_month2[<span class="string">'forecast'</span>] = best_model.predict(start=<span class="number">0</span>, end=<span class="number">91</span>)</span><br><span class="line"><span class="comment"># 比特币预测结果显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">7</span>))</span><br><span class="line">df_month2.Weighted_Price.plot(label=<span class="string">'实际金额'</span>)</span><br><span class="line">df_month2.forecast.plot(color=<span class="string">'r'</span>, ls=<span class="string">'--'</span>, label=<span class="string">'预测金额'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">'比特币金额（月）'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'时间'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'美金'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1587568120533-48e72652-d6c8-48d7-89b5-e85444e01f0b.png#align=left&display=inline&height=387&margin=%5Bobject%20Object%5D&name=image.png&originHeight=896&originWidth=1726&size=185308&status=done&style=none&width=746" alt="image.png">)<img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1587568146325-8a757836-53be-48dc-bd78-db7c3ac4b303.png#align=left&display=inline&height=661&margin=%5Bobject%20Object%5D&name=image.png&originHeight=661&originWidth=1729&size=105845&status=done&style=none&width=1729" alt="image.png">)<img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1587568269473-039c43af-0ead-4c73-934f-240ea39180db.png#align=left&display=inline&height=932&margin=%5Bobject%20Object%5D&name=image.png&originHeight=932&originWidth=1729&size=516959&status=done&style=none&width=1729" alt="image.png"><br><br><br>我们通过 product 函数创建了 (p,q) 在 range(0,3) 范围内的所有可能组合，并对每个 ARMA(p,q) 模型进行了 AIC 数值计算，保存了 AIC 数值最小的模型参数。然后用这个模型对比特币的未来 8 个月进行了预测。<br><br><br>从结果中你能看到，在 2018 年 10 月之后 8 个月的时间里，比特币会触底到 4000 美金左右，实际上比特币在这个阶段确实降低到了 4000 元美金甚至更低。在时间尺度的选择上，我们选择了月，这样就对数据进行了降维，也节约了 ARMA 的模型训练时间。你能看到比特币金额（美金）这张图中，按月划分的比特币走势和按天划分的比特币走势差别不大，在减少了局部的波动的同时也能体现出比特币的趋势，这样就节约了 ARMA 的模型训练时间。<br></p><p><a name="3wkzY"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br>今天我给你讲了一个比特币趋势预测的实战项目。通过这个项目你应该能体会到，当我们对一个数值进行预测的时候，如果考虑的是多个变量和结果之间的关系，可以采用回归分析，如果考虑单个时间维度与结果的关系，可以使用时间序列分析。<br><br><br>根据比特币的历史数据，我们使用 ARMA 模型对比特币未来 8 个月的走势进行了预测，并对结果进行了可视化显示。你能看到 ARMA 工具还是很好用的，虽然比特币的走势受很多外在因素影响，比如政策环境。不过当我们掌握了这些历史数据，也不妨用时间序列模型来分析预测一下。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;我们之前介绍了数据挖掘算法中的分类、聚类、回归和关联分析算法，那么对于比特币走势的预测，采用哪种方法比较好呢？&lt;br&gt;&lt;br&gt;&lt;br&gt;可能有些人
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="时间序列" scheme="cpeixin.cn/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>信用卡诈骗分析</title>
    <link href="cpeixin.cn/2019/04/03/%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%AF%88%E9%AA%97%E5%88%86%E6%9E%90/"/>
    <id>cpeixin.cn/2019/04/03/%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%AF%88%E9%AA%97%E5%88%86%E6%9E%90/</id>
    <published>2019-04-02T16:43:58.000Z</published>
    <updated>2020-04-15T16:46:40.822Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>上一篇文章中，我们用随机森林以及之前讲过的 SVM、决策树和 KNN 分类器对信用卡违约数据进行了分析，这节课我们来研究下信用卡欺诈。<br><br><br>相比于信用卡违约的比例，信用卡欺诈的比例更小，但是危害极大。如何通过以往的交易数据分析出每笔交易是否正常，是否存在盗刷风险是我们这次项目的目标。<br><br><br>通过今天的学习，你需要掌握以下几个方面：</p><ul><li>了解逻辑回归分类，以及如何在 sklearn 中使用它；</li><li>信用卡欺诈属于二分类问题，欺诈交易在所有交易中的比例很小，对于这种数据不平衡的情况，到底采用什么样的模型评估标准会更准确；</li><li>完成信用卡欺诈分析的实战项目，并通过数据可视化对数据探索和模型结果评估进一步加强了解。<br><a name="wwZpI"></a><h3><a href="#" class="headerlink"></a></h3><a name="evkL5"></a><h3 id="构建逻辑回归分类器"><a href="#构建逻辑回归分类器" class="headerlink" title="构建逻辑回归分类器"></a>构建逻辑回归分类器</h3></li></ul><p><br>逻辑回归虽然不在我们讲解的十大经典数据挖掘算法里面，但也是常用的数据挖掘算法。逻辑回归，也叫作 logistic 回归。虽然名字中带有“回归”，但它实际上是分类方法，主要解决的是二分类问题，当然它也可以解决多分类问题，只是二分类更常见一些。<br><br><br>在逻辑回归中使用了 Logistic 函数，也称为 Sigmoid 函数。Sigmoid 函数是在深度学习中经常用到的函数之一，函数公式为：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586964265219-9919addd-92e8-42f4-8d14-fab4af3e5bb0.png#align=left&display=inline&height=204&margin=%5Bobject%20Object%5D&name=image.png&originHeight=204&originWidth=444&size=11021&status=done&style=none&width=444" alt="image.png"><br>函数的图形如下所示，类似 S 状：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586964264055-79ceda30-ba6d-492e-808c-de24a6c1299d.png#align=left&display=inline&height=206&margin=%5Bobject%20Object%5D&name=b7a5d39d91fda02b21669137a489743b.png&originHeight=206&originWidth=477&size=7332&status=done&style=none&width=477" alt="b7a5d39d91fda02b21669137a489743b.png"><br><br><br>你能看出 g(z) 的结果在 0-1 之间，当 z 越大的时候，g(z) 越大，当 z 趋近于无穷大的时候，g(z) 趋近于 1。同样当 z 趋近于无穷小的时候，g(z) 趋近于 0。同时，函数值以 0.5 为中心。<br><br><br>为什么逻辑回归算法是基于 Sigmoid 函数实现的呢？你可以这样理解：我们要实现一个二分类任务，0 即为不发生，1 即为发生。我们给定一些历史数据 X 和 y。其中 X 代表样本的 n 个特征，y 代表正例和负例，也就是 0 或 1 的取值。通过历史样本的学习，我们可以得到一个模型，当给定新的 X 的时候，可以预测出 y。这里我们得到的 y 是一个预测的概率，通常不是 0% 和 100%，而是中间的取值，那么我们就可以认为概率大于 50% 的时候，即为发生（正例），概率小于 50% 的时候，即为不发生（负例）。这样就完成了二分类的预测。<br><br><br>逻辑回归模型的求解这里不做介绍，我们来看下如何使用 sklearn 中的逻辑回归工具。在 sklearn 中，我们使用 LogisticRegression() 函数构建逻辑回归分类器，函数里有一些常用的构造参数：<br></p><ol><li>penalty：惩罚项，取值为 l1 或 l2，默认为 l2。当模型参数满足高斯分布的时候，使用 l2，当模型参数满足拉普拉斯分布的时候，使用 l1；</li><li>solver：代表的是逻辑回归损失函数的优化方法。有 5 个参数可选，分别为 liblinear、lbfgs、newton-cg、sag 和 saga。默认为 liblinear，适用于数据量小的数据集，当数据量大的时候可以选用 sag 或 saga 方法。</li><li>max_iter：算法收敛的最大迭代次数，默认为 10。</li><li>n_jobs：拟合和预测的时候 CPU 的核数，默认是 1，也可以是整数，如果是 -1 则代表 CPU 的核数。</li></ol><p><br>当我们创建好之后，就可以使用 fit 函数拟合，使用 predict 函数预测。<br><br><br></p><p><a name="gdmvF"></a></p><h3 id="模型评估指标"><a href="#模型评估指标" class="headerlink" title="模型评估指标"></a>模型评估指标</h3><p><br>我们之前对模型做评估时，通常采用的是准确率 (accuracy)，它指的是分类器正确分类的样本数与总体样本数之间的比例。这个指标对大部分的分类情况是有效的，不过当分类结果严重不平衡的时候，准确率很难反应模型的好坏。<br><br><br>举个例子，对于机场安检中恐怖分子的判断，就不能采用准确率对模型进行评估。我们知道恐怖分子的比例是极低的，因此当我们用准确率做判断时，如果准确率高达 99.999%，就说明这个模型一定好么？其实正因为现实生活中恐怖分子的比例极低，就算我们不能识别出一个恐怖分子，也会得到非常高的准确率。因为准确率的评判标准是正确分类的样本个数与总样本数之间的比例。因此非恐怖分子的比例会很高，就算我们识别不出来恐怖分子，正确分类的个数占总样本的比例也会很高，也就是准确率高。<br><br><br>实际上我们应该更关注恐怖分子的识别，这里先介绍下数据预测的四种情况：TP、FP、TN、FN。我们用第二个字母 P 或 N 代表预测为正例还是负例，P 为正，N 为负。第一个字母 T 或 F 代表的是预测结果是否正确，T 为正确，F 为错误。所以四种情况分别为：</p><ul><li>TP：预测为正，判断正确；</li><li>FP：预测为正，判断错误；</li><li>TN：预测为负，判断正确；</li><li>FN：预测为负，判断错误。</li></ul><p><br>我们知道样本总数 =TP+FP+TN+FN，预测正确的样本数为 TP+TN，因此准确率 Accuracy = (TP+TN)/(TP+TN+FN+FP)。<br><br><br>实际上，对于分类不平衡的情况，有两个指标非常重要，<strong>它们分别是精确度和召回率</strong>。<br><br><br>精确率 P = TP/ (TP+FP)，对应上面恐怖分子这个例子，在所有判断为恐怖分子的人数中，真正是恐怖分子的比例。<br><br><br>召回率 R = TP/ (TP+FN)，也称为查全率。代表的是恐怖分子被正确识别出来的个数与恐怖分子总数的比例。为什么要统计召回率和精确率这两个指标呢？假设我们只统计召回率，当召回率等于 100% 的时候，模型是否真的好呢？<br><br><br>举个例子，假设我们把机场所有的人都认为是恐怖分子，恐怖分子都会被正确识别，这个数字与恐怖分子的总数比例等于 100%，但是这个结果是没有意义的。如果我们认为机场里所有人都是恐怖分子的话，那么非恐怖分子（极高比例）都会认为是恐怖分子，误判率太高了，所以我们还需要统计精确率作为召回率的补充。实际上有一个指标综合了精确率和召回率，可以更好地评估模型的好坏。这个指标叫做 F1，用公式表示为：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586964834238-6a4ec2e1-306d-4057-9a97-7df5e831b85c.png#align=left&display=inline&height=182&margin=%5Bobject%20Object%5D&name=b122244eae9a74eded619d14c0bc12ce.png&originHeight=182&originWidth=398&size=11527&status=done&style=none&width=398" alt="b122244eae9a74eded619d14c0bc12ce.png"><br><br><br>F1 作为精确率 P 和召回率 R 的调和平均，数值越大代表模型的结果越好。<br><br><br></p><p><a name="jZ1Vb"></a></p><h3 id="信用卡欺诈分析"><a href="#信用卡欺诈分析" class="headerlink" title="信用卡欺诈分析"></a>信用卡欺诈分析</h3><p><br>我们来看一个信用卡欺诈分析的项目，这个数据集你可以从百度网盘（因为数据集大于 100M，所以采用了网盘）中下载：链接：<a href="https://pan.baidu.com/s/14F8WuX0ZJntdB_r1EC08HA" target="_blank" rel="external nofollow noopener noreferrer">https://pan.baidu.com/s/14F8WuX0ZJntdB_r1EC08HA</a> 提取码：58gp<br><br><br>数据集包括了 2013 年 9 月份两天时间内的信用卡交易数据，284807 笔交易中，一共有 492 笔是欺诈行为。输入数据一共包括了 28 个特征 V1，V2，……V28 对应的取值，以及交易时间 Time 和交易金额 Amount。为了保护数据隐私，我们不知道 V1 到 V28 这些特征代表的具体含义，只知道这 28 个特征值是通过 PCA 变换得到的结果。另外字段 Class 代表该笔交易的分类，Class=0 为正常（非欺诈），Class=1 代表欺诈。<br><br><br>我们的目标是针对这个数据集构建一个信用卡欺诈分析的分类器，采用的是逻辑回归。从数据中你能看到欺诈行为只占到了 492/284807=0.172%，数据分类结果的分布是非常不平衡的，因此我们不能使用准确率评估模型的好坏，而是需要统计 F1 值（综合精确率和召回率）。我们先梳理下整个项目的流程：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1586965086920-af9f8f64-ed51-45a0-99bc-b5d7dbe3d7fb.jpeg#align=left&display=inline&height=1079&margin=%5Bobject%20Object%5D&name=image.jpeg&originHeight=1079&originWidth=2350&size=262963&status=done&style=none&width=2350" alt="image.jpeg"><br></p><ol><li>加载数据；</li></ol><ol start="2"><li>准备阶段：我们需要探索数据，用数据可视化的方式查看分类结果的情况，以及随着时间的变化，欺诈交易和正常交易的分布情况。上面已经提到过，V1-V28 的特征值都经过 PCA 的变换，但是其余的两个字段，Time 和 Amount 还需要进行规范化。Time 字段和交易本身是否为欺诈交易无关，因此我们不作为特征选择，只需要对 Amount 做数据规范化就行了。同时数据集没有专门的测试集，使用 train_test_split 对数据集进行划分；</li></ol><ol start="3"><li>分类阶段：我们需要创建逻辑回归分类器，然后传入训练集数据进行训练，并传入测试集预测结果，将预测结果与测试集的结果进行比对。这里的模型评估指标用到了<strong>精确率、召回率和 F1 值</strong>。同时我们将精确率 - 召回率进行了可视化呈现。</li></ol><p><br>基于上面的流程，具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># 使用逻辑回归对信用卡欺诈进行分类</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, precision_recall_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 混淆矩阵可视化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_confusion_matrix</span><span class="params">(cm, classes, normalize = False, title = <span class="string">'Confusion matrix"'</span>, cmap = plt.cm.Blues)</span> :</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.imshow(cm, interpolation = <span class="string">'nearest'</span>, cmap = cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(len(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation = <span class="number">0</span>)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line"> </span><br><span class="line">    thresh = cm.max() / <span class="number">2.</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> itertools.product(range(cm.shape[<span class="number">0</span>]), range(cm.shape[<span class="number">1</span>])) :</span><br><span class="line">        plt.text(j, i, cm[i, j],</span><br><span class="line">                 horizontalalignment = <span class="string">'center'</span>,</span><br><span class="line">                 color = <span class="string">'white'</span> <span class="keyword">if</span> cm[i, j] &gt; thresh <span class="keyword">else</span> <span class="string">'black'</span>)</span><br><span class="line"> </span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(<span class="string">'True label'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Predicted label'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 显示模型评估结果</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_metrics</span><span class="params">()</span>:</span></span><br><span class="line">    tp = cm[<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">    fn = cm[<span class="number">1</span>,<span class="number">0</span>]</span><br><span class="line">    fp = cm[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">    tn = cm[<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">'精确率: &#123;:.3f&#125;'</span>.format(tp/(tp+fp)))</span><br><span class="line">    print(<span class="string">'召回率: &#123;:.3f&#125;'</span>.format(tp/(tp+fn)))</span><br><span class="line">    print(<span class="string">'F1值: &#123;:.3f&#125;'</span>.format(<span class="number">2</span>*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn))))))</span><br><span class="line"><span class="comment"># 绘制精确率-召回率曲线</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_precision_recall</span><span class="params">()</span>:</span></span><br><span class="line">    plt.step(recall, precision, color = <span class="string">'b'</span>, alpha = <span class="number">0.2</span>, where = <span class="string">'post'</span>)</span><br><span class="line">    plt.fill_between(recall, precision, step =<span class="string">'post'</span>, alpha = <span class="number">0.2</span>, color = <span class="string">'b'</span>)</span><br><span class="line">    plt.plot(recall, precision, linewidth=<span class="number">2</span>)</span><br><span class="line">    plt.xlim([<span class="number">0.0</span>,<span class="number">1</span>])</span><br><span class="line">    plt.ylim([<span class="number">0.0</span>,<span class="number">1.05</span>])</span><br><span class="line">    plt.xlabel(<span class="string">'召回率'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'精确率'</span>)</span><br><span class="line">    plt.title(<span class="string">'精确率-召回率 曲线'</span>)</span><br><span class="line">    plt.show();</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 数据加载</span></span><br><span class="line">data = pd.read_csv(<span class="string">'./creditcard.csv'</span>)</span><br><span class="line"><span class="comment"># 数据探索</span></span><br><span class="line">print(data.describe())</span><br><span class="line"><span class="comment"># 设置plt正确显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]</span><br><span class="line"><span class="comment"># 绘制类别分布</span></span><br><span class="line">plt.figure()</span><br><span class="line">ax = sns.countplot(x = <span class="string">'Class'</span>, data = data)</span><br><span class="line">plt.title(<span class="string">'类别分布'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 显示交易笔数，欺诈交易笔数</span></span><br><span class="line">num = len(data)</span><br><span class="line">num_fraud = len(data[data[<span class="string">'Class'</span>]==<span class="number">1</span>]) </span><br><span class="line">print(<span class="string">'总交易笔数: '</span>, num)</span><br><span class="line">print(<span class="string">'诈骗交易笔数：'</span>, num_fraud)</span><br><span class="line">print(<span class="string">'诈骗交易比例：&#123;:.6f&#125;'</span>.format(num_fraud/num))</span><br><span class="line"><span class="comment"># 欺诈和正常交易可视化</span></span><br><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">2</span>, <span class="number">1</span>, sharex=<span class="literal">True</span>, figsize=(<span class="number">15</span>,<span class="number">8</span>))</span><br><span class="line">bins = <span class="number">50</span></span><br><span class="line">ax1.hist(data.Time[data.Class == <span class="number">1</span>], bins = bins, color = <span class="string">'deeppink'</span>)</span><br><span class="line">ax1.set_title(<span class="string">'诈骗交易'</span>)</span><br><span class="line">ax2.hist(data.Time[data.Class == <span class="number">0</span>], bins = bins, color = <span class="string">'deepskyblue'</span>)</span><br><span class="line">ax2.set_title(<span class="string">'正常交易'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'时间'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'交易次数'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 对Amount进行数据规范化</span></span><br><span class="line">data[<span class="string">'Amount_Norm'</span>] = StandardScaler().fit_transform(data[<span class="string">'Amount'</span>].values.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 特征选择</span></span><br><span class="line">y = np.array(data.Class.tolist())</span><br><span class="line">data = data.drop([<span class="string">'Time'</span>,<span class="string">'Amount'</span>,<span class="string">'Class'</span>],axis=<span class="number">1</span>)</span><br><span class="line">X = np.array(data.as_matrix())</span><br><span class="line"><span class="comment"># 准备训练集和测试集</span></span><br><span class="line">train_x, test_x, train_y, test_y = train_test_split (X, y, test_size = <span class="number">0.1</span>, random_state = <span class="number">33</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 逻辑回归分类</span></span><br><span class="line">clf = LogisticRegression()</span><br><span class="line">clf.fit(train_x, train_y)</span><br><span class="line">predict_y = clf.predict(test_x)</span><br><span class="line"><span class="comment"># 预测样本的置信分数</span></span><br><span class="line">score_y = clf.decision_function(test_x)  </span><br><span class="line"><span class="comment"># 计算混淆矩阵，并显示</span></span><br><span class="line">cm = confusion_matrix(test_y, predict_y)</span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 显示混淆矩阵</span></span><br><span class="line">plot_confusion_matrix(cm, classes = class_names, title = <span class="string">'逻辑回归 混淆矩阵'</span>)</span><br><span class="line"><span class="comment"># 显示模型评估分数</span></span><br><span class="line">show_metrics()</span><br><span class="line"><span class="comment"># 计算精确率，召回率，阈值用于可视化</span></span><br><span class="line">precision, recall, thresholds = precision_recall_curve(test_y, score_y)</span><br><span class="line">plot_precision_recall()</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">                Time            V1      ...               Amount          Class</span><br><span class="line">count  <span class="number">284807.000000</span>  <span class="number">2.848070e+05</span>      ...        <span class="number">284807.000000</span>  <span class="number">284807.000000</span></span><br><span class="line">mean    <span class="number">94813.859575</span>  <span class="number">1.165980e-15</span>      ...            <span class="number">88.349619</span>       <span class="number">0.001727</span></span><br><span class="line">std     <span class="number">47488.145955</span>  <span class="number">1.958696e+00</span>      ...           <span class="number">250.120109</span>       <span class="number">0.041527</span></span><br><span class="line">min         <span class="number">0.000000</span> <span class="number">-5.640751e+01</span>      ...             <span class="number">0.000000</span>       <span class="number">0.000000</span></span><br><span class="line"><span class="number">25</span>%     <span class="number">54201.500000</span> <span class="number">-9.203734e-01</span>      ...             <span class="number">5.600000</span>       <span class="number">0.000000</span></span><br><span class="line"><span class="number">50</span>%     <span class="number">84692.000000</span>  <span class="number">1.810880e-02</span>      ...            <span class="number">22.000000</span>       <span class="number">0.000000</span></span><br><span class="line"><span class="number">75</span>%    <span class="number">139320.500000</span>  <span class="number">1.315642e+00</span>      ...            <span class="number">77.165000</span>       <span class="number">0.000000</span></span><br><span class="line">max    <span class="number">172792.000000</span>  <span class="number">2.454930e+00</span>      ...         <span class="number">25691.160000</span>       <span class="number">1.000000</span></span><br><span class="line"></span><br><span class="line">[<span class="number">8</span> rows x <span class="number">31</span> columns]</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586967850283-e9af3698-331c-4e3e-ae8f-d490803e2811.png#align=left&display=inline&height=1363&margin=%5Bobject%20Object%5D&name=5e98974d6c2e87168b40e5f751d00f61.png&originHeight=1363&originWidth=1728&size=89241&status=done&style=none&width=1728" alt="5e98974d6c2e87168b40e5f751d00f61.png"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">总交易笔数:  284807</span><br><span class="line">诈骗交易笔数： 492</span><br><span class="line">诈骗交易比例：0.001727</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586967935125-87c5538f-27a4-44d1-8a27-c67cb6cbde4d.png#align=left&display=inline&height=1458&margin=%5Bobject%20Object%5D&name=bfe65c34b74de661477d9b59d4db6a39.png&originHeight=1458&originWidth=1729&size=121793&status=done&style=none&width=1729" alt="bfe65c34b74de661477d9b59d4db6a39.png">)<img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586967952349-d6855347-0edd-4caa-819e-7c98e253769b.png#align=left&display=inline&height=1022&margin=%5Bobject%20Object%5D&name=c8a59cb4f3d94c91eb6648be1b0429d2.png&originHeight=1022&originWidth=1726&size=88131&status=done&style=none&width=1726" alt="c8a59cb4f3d94c91eb6648be1b0429d2.png"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">精确率: 0.841</span><br><span class="line">召回率: 0.617</span><br><span class="line">F1值: 0.712</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586967968745-3cf776d3-884d-4af6-a270-b33cefc550c9.png#align=left&display=inline&height=446&margin=%5Bobject%20Object%5D&name=28ccd0f8d609046b2bafb27fb1195269.png&originHeight=446&originWidth=567&size=16903&status=done&style=none&width=567" alt="28ccd0f8d609046b2bafb27fb1195269.png"><br>你能看出来欺诈交易的笔数为 492 笔，占所有交易的比例是很低的，即 0.001727，我们可以通过数据可视化的方式对欺诈交易和正常交易的分布进行呈现。另外通过可视化，我们也能看出精确率和召回率之间的关系，当精确率高的时候，召回率往往很低，召回率高的时候，精确率会比较低。<br><br><br>代码有一些模块需要说明下。我定义了 plot_confusion_matrix 函数对混淆矩阵进行可视化。什么是混淆矩阵呢？混淆矩阵也叫误差矩阵，实际上它就是 TP、FP、TN、FN 这四个数值的矩阵表示，帮助我们判断预测值和实际值相比，对了多少。从这个例子中，你能看出 TP=37，FP=7，FN=23。所以精确率 P=TP/(TP+FP)=37/(37+7)=0.841，召回率 R=TP/(TP+FN)=37/(37+23)=0.617。然后使用了 sklearn 中的 precision_recall_curve 函数，通过预测值和真实值来计算精确率 - 召回率曲线。<br><br><br>precision_recall_curve 函数会计算在不同概率阈值情况下的精确率和召回率。最后定义 plot_precision_recall 函数，绘制曲线。<br></p><p><a name="ig5Sr"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br>今天我给你讲了逻辑回归的概念和相关工具的使用，另外学习了在数据样本不平衡的情况下，如何评估模型。这里你需要了解精确率，召回率和 F1 的概念和计算方式。<br><br><br>最后在信用卡欺诈分析的项目中，我们使用了逻辑回归工具，并对混淆矩阵进行了计算，同时在模型结果评估中，使用了精确率、召回率和 F1 值，最后得到精确率 - 召回率曲线的可视化结果。从这个项目中你能看出来，不是所有的分类都是样本平衡的情况，针对正例比例极低的情况，比如信用卡欺诈、某些疾病的识别，或者是恐怖分子的判断等，都需要采用精确率 - 召回率来进行统计。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586968908701-9553e7eb-6051-4c47-86c4-3af7e07d490d.png#align=left&display=inline&height=356&margin=%5Bobject%20Object%5D&name=abee1a58b99814f1e0218778b98a6950.png&originHeight=824&originWidth=1729&size=318818&status=done&style=none&width=746" alt="abee1a58b99814f1e0218778b98a6950.png"><br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;上一篇文章中，我们用随机森林以及之前讲过的 SVM、决策树和 KNN 分类器对信用卡违约数据进行了分析，这节课我们来研究下信用卡欺诈。&lt;br&gt;&lt;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="逻辑回归" scheme="cpeixin.cn/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>信用卡风险评估</title>
    <link href="cpeixin.cn/2019/04/01/%E4%BF%A1%E7%94%A8%E5%8D%A1%E9%A3%8E%E9%99%A9%E8%AF%84%E4%BC%B0/"/>
    <id>cpeixin.cn/2019/04/01/%E4%BF%A1%E7%94%A8%E5%8D%A1%E9%A3%8E%E9%99%A9%E8%AF%84%E4%BC%B0/</id>
    <published>2019-03-31T17:21:02.000Z</published>
    <updated>2020-04-17T08:45:24.895Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>今天我来带你做一个数据挖掘的项目。在数据挖掘的过程中，我们经常会遇到一些问题，比如：如何选择各种分类器，到底选择哪个分类算法，是 SVM，决策树，还是 KNN？如何优化分类器的参数，以便得到更好的分类准确率？这两个问题，是数据挖掘核心的问题。<br><br><br>当然对于一个新的项目，我们还有其他的问题需要了解，比如掌握数据探索和数据可视化的方式，还需要对数据的完整性和质量做评估。这些内容我在之前的课程中都有讲到过。今天的学习主要围绕下面的三个目标，并通过它们完成信用卡违约率项目的实战<br><br><br>这三个目标分别是：</p><ul><li>创建各种分类器，包括已经掌握的 SVM、决策树、KNN 分类器，以及随机森林分类器；</li><li>掌握 GridSearchCV 工具，优化算法模型的参数；</li><li>使用 Pipeline 管道机制进行流水线作业。因为在做分类之前，我们还需要一些准备过程，比如数据规范化，或者数据降维等。</li></ul><p><a name="qVKos"></a></p><h3 id="构建随机森林分类器"><a href="#构建随机森林分类器" class="headerlink" title="构建随机森林分类器"></a>构建随机森林分类器</h3><p><br>在算法篇中，我主要讲了数据挖掘十大经典算法。实际工作中，你也可能会用到随机森林。随机森林的英文是 Random Forest，英文简写是 RF。它实际上是一个包含多个决策树的分类器，每一个子分类器都是一棵 CART 分类回归树。所以随机森林既可以做分类，又可以做回归。<br><br><br>当它做分类的时候，输出结果是每个子分类器的分类结果中最多的那个。你可以理解是每个分类器都做投票，取投票最多的那个结果。当它做回归的时候，输出结果是每棵 CART 树的回归结果的平均值。在 sklearn 中，我们使用 RandomForestClassifier() 构造随机森林模型，函数里有一些常用的构造参数：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586881198201-8f4e3d3f-b0d2-4657-ba91-0693591eab3b.png#align=left&display=inline&height=210&margin=%5Bobject%20Object%5D&name=352035fe3e92d412d652fd55c77f23f9.png&originHeight=210&originWidth=629&size=52416&status=done&style=none&width=629" alt="352035fe3e92d412d652fd55c77f23f9.png"><br>当我们创建好之后，就可以使用 fit 函数拟合，使用 predict 函数预测。<br></p><p><a name="nOoSM"></a></p><h3 id="使用-GridSearchCV-工具对模型参数进行调优"><a href="#使用-GridSearchCV-工具对模型参数进行调优" class="headerlink" title="使用 GridSearchCV 工具对模型参数进行调优"></a>使用 GridSearchCV 工具对模型参数进行调优</h3><p><br>在做分类算法的时候，我们需要经常调节网络参数（对应上面的构造参数），目的是得到更好的分类结果。实际上一个分类算法有很多参数，取值范围也比较广，那么该如何调优呢？<br><br><br>Python 给我们提供了一个很好用的工具 GridSearchCV，它是 Python 的参数自动搜索模块。<strong>我们只要告诉它想要调优的参数有哪些以及参数的取值范围，它就会把所有的情况都跑一遍，然后告诉我们哪个参数是最优的，结果如何。</strong><br><br><br>使用 GridSearchCV 模块需要先引用工具包，方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br></pre></td></tr></table></figure><p><br>然后我们使用 GridSearchCV(estimator, param_grid, cv=None, scoring=None) 构造参数的自动搜索模块，这里有一些主要的参数需要说明下：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586882395328-f0d75ba6-0707-4045-b367-5e902287ad6d.png#align=left&display=inline&height=183&margin=%5Bobject%20Object%5D&name=image.png&originHeight=183&originWidth=630&size=51879&status=done&style=none&width=630" alt="image.png"><br><br><br>构造完 GridSearchCV 之后，我们就可以使用 fit 函数拟合训练，使用 predict 函数预测，这时预测采用的是最优参数情况下的分类器。<br><br><br>这里举一个简单的例子，我们用 sklearn 自带的 IRIS 数据集，采用随机森林对 IRIS 数据分类。假设我们想知道 n_estimators 在 1-10 的范围内取哪个值的分类结果最好，可以编写代码：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 使用RandomForest对IRIS数据集进行分类</span></span><br><span class="line"><span class="comment"># 利用GridSearchCV寻找最优参数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line">rf = RandomForestClassifier()</span><br><span class="line">parameters = &#123;<span class="string">"n_estimators"</span>: range(<span class="number">1</span>,<span class="number">11</span>)&#125;</span><br><span class="line">iris = load_iris()</span><br><span class="line"><span class="comment"># 使用GridSearchCV进行参数调优</span></span><br><span class="line">clf = GridSearchCV(estimator=rf, param_grid=parameters)</span><br><span class="line"><span class="comment"># 对iris数据集进行分类</span></span><br><span class="line">clf.fit(iris.data, iris.target)</span><br><span class="line">print(<span class="string">"最优分数： %.4lf"</span> %clf.best_score_)</span><br><span class="line">print(<span class="string">"最优参数："</span>, clf.best_params_)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">运行结果如下：</span><br><span class="line">最优分数： <span class="number">0.9667</span></span><br><span class="line">最优参数： &#123;<span class="string">'n_estimators'</span>: <span class="number">6</span>&#125;</span><br></pre></td></tr></table></figure><p><br>你能看到当我们采用随机森林作为分类器的时候，最优准确率是 0.9667，当 n_estimators=6 的时候，是最优参数，也就是随机森林一共有 6 个子决策树。<br></p><p><a name="nK5Sl"></a></p><h3 id="使用-Pipeline-管道机制进行流水线作业"><a href="#使用-Pipeline-管道机制进行流水线作业" class="headerlink" title="使用 Pipeline 管道机制进行流水线作业"></a>使用 Pipeline 管道机制进行流水线作业</h3><p><br>做分类的时候往往都是有步骤的，比如先对数据进行规范化处理，你也可以用 PCA 方法（一种常用的降维方法）对数据降维，最后使用分类器分类。Python 有一种 Pipeline 管道机制。管道机制就是让我们把每一步都按顺序列下来，从而创建 Pipeline 流水线作业。每一步都采用 (‘名称’, 步骤) 的方式来表示。我们需要先采用 StandardScaler 方法对数据规范化，即采用数据规范化为均值为 0，方差为 1 的正态分布，然后采用 PCA 方法对数据进行降维，最后采用随机森林进行分类。具体代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">        (<span class="string">'scaler'</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">'pca'</span>, PCA()),</span><br><span class="line">        (<span class="string">'randomforestclassifier'</span>, RandomForestClassifier())</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>那么我们现在采用 Pipeline 管道机制，用随机森林对 IRIS 数据集做一下分类。先用 StandardScaler 方法对数据规范化，然后再用随机森林分类，编写代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 使用RandomForest对IRIS数据集进行分类</span></span><br><span class="line"><span class="comment"># 利用GridSearchCV寻找最优参数,使用Pipeline进行流水作业</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line">rf = RandomForestClassifier()</span><br><span class="line">parameters = &#123;<span class="string">"randomforestclassifier__n_estimators"</span>: range(<span class="number">1</span>,<span class="number">11</span>)&#125;</span><br><span class="line">iris = load_iris()</span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">        (<span class="string">'scaler'</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">'randomforestclassifier'</span>, rf)</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 使用GridSearchCV进行参数调优</span></span><br><span class="line">clf = GridSearchCV(estimator=pipeline, param_grid=parameters)</span><br><span class="line"><span class="comment"># 对iris数据集进行分类</span></span><br><span class="line">clf.fit(iris.data, iris.target)</span><br><span class="line">print(<span class="string">"最优分数： %.4lf"</span> %clf.best_score_)</span><br><span class="line">print(<span class="string">"最优参数："</span>, clf.best_params_)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">运行结果：</span><br><span class="line">最优分数： <span class="number">0.9667</span></span><br><span class="line">最优参数： &#123;<span class="string">'randomforestclassifier__n_estimators'</span>: <span class="number">9</span>&#125;</span><br></pre></td></tr></table></figure><p><br>你能看到是否采用数据规范化对结果还是有一些影响的，有了 GridSearchCV 和 Pipeline 这两个工具之后，我们在使用分类器的时候就会方便很多。<br></p><p><a name="3TqBP"></a></p><h3 id="对信用卡违约率进行分析"><a href="#对信用卡违约率进行分析" class="headerlink" title="对信用卡违约率进行分析"></a>对信用卡违约率进行分析</h3><p><br>我们现在来做一个信用卡违约率的项目，这个数据集你可以从 GitHub 上下载：<a href="https://github.com/cystanford/credit_default" target="_blank" rel="external nofollow noopener noreferrer">https://github.com/cystanford/credit_default</a>。<br><br><br>这个数据集是台湾某银行 2005 年 4 月到 9 月的信用卡数据，数据集一共包括 25 个字段，具体含义如下：<br><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1586883521178-d88ca06b-f952-481a-8f92-39bf0d5059a8.jpeg#align=left&display=inline&height=843&margin=%5Bobject%20Object%5D&name=1730fb3a809c99950739e7f50e1a6988.jpg&originHeight=843&originWidth=627&size=231191&status=done&style=none&width=627" alt="1730fb3a809c99950739e7f50e1a6988.jpg"><br>现在我们的目标是要针对这个数据集构建一个分析信用卡违约率的分类器。具体选择哪个分类器，以及分类器的参数如何优化，我们可以用 GridSearchCV 这个工具跑一遍。先梳理下整个项目的流程：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1586883546533-c7be28a5-fefc-4c95-a7f5-1b34d8dbc07e.jpeg#align=left&display=inline&height=1079&margin=%5Bobject%20Object%5D&name=929c96584cbc25972f63ef39101c96a5.jpg&originHeight=1079&originWidth=2350&size=262963&status=done&style=none&width=2350" alt="929c96584cbc25972f63ef39101c96a5.jpg"><br></p><ol><li>加载数据；</li><li>准备阶段：探索数据，采用数据可视化方式可以让我们对数据有更直观的了解，比如我们想要了解信用卡违约率和不违约率的人数。因为数据集没有专门的测试集，我们还需要使用 train_test_split 划分数据集。</li><li>分类阶段：之所以把数据规范化放到这个阶段，是因为我们可以使用 Pipeline 管道机制，将数据规范化设置为第一步，分类为第二步。因为我们不知道采用哪个分类器效果好，所以我们需要多用几个分类器，比如 SVM、决策树、随机森林和 KNN。然后通过 GridSearchCV 工具，找到每个分类器的最优参数和最优分数，最终找到最适合这个项目的分类器和该分类器的参数。</li></ol><p><br>基于上面的流程，具体代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造各种分类器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">classifiers = [</span><br><span class="line">    SVC(random_state = <span class="number">1</span>, kernel = <span class="string">'rbf'</span>),</span><br><span class="line">    DecisionTreeClassifier(random_state = <span class="number">1</span>, criterion = <span class="string">'gini'</span>),</span><br><span class="line">    RandomForestClassifier(random_state = <span class="number">1</span>, criterion = <span class="string">'gini'</span>),</span><br><span class="line">    KNeighborsClassifier(metric = <span class="string">'minkowski'</span>),</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 分类器名称</span></span><br><span class="line">classifier_names = [</span><br><span class="line">            <span class="string">'svc'</span>,</span><br><span class="line">            <span class="string">'decisiontreeclassifier'</span>,</span><br><span class="line">            <span class="string">'randomforestclassifier'</span>,</span><br><span class="line">            <span class="string">'kneighborsclassifier'</span>,</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 分类器参数</span></span><br><span class="line">classifier_param_grid = [</span><br><span class="line">            &#123;<span class="string">'svc__C'</span>:[<span class="number">1</span>], <span class="string">'svc__gamma'</span>:[<span class="number">0.01</span>]&#125;,</span><br><span class="line">            &#123;<span class="string">'decisiontreeclassifier__max_depth'</span>:[<span class="number">6</span>,<span class="number">9</span>,<span class="number">11</span>]&#125;,</span><br><span class="line">            &#123;<span class="string">'randomforestclassifier__n_estimators'</span>:[<span class="number">3</span>,<span class="number">5</span>,<span class="number">6</span>]&#125; ,</span><br><span class="line">            &#123;<span class="string">'kneighborsclassifier__n_neighbors'</span>:[<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>]&#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对具体的分类器进行GridSearchCV参数调优</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GridSearchCV_work</span><span class="params">(pipeline, train_x, train_y, test_x, test_y, param_grid, score = <span class="string">'accuracy'</span>)</span>:</span></span><br><span class="line">    response = &#123;&#125;</span><br><span class="line">    gridsearch = GridSearchCV(estimator = pipeline, param_grid = param_grid, scoring = score)</span><br><span class="line">    <span class="comment"># 寻找最优的参数 和最优的准确率分数</span></span><br><span class="line">    search = gridsearch.fit(train_x, train_y)</span><br><span class="line">    print(<span class="string">"GridSearch最优参数："</span>, search.best_params_)</span><br><span class="line">    print(<span class="string">"GridSearch最优分数： %0.4lf"</span> %search.best_score_)</span><br><span class="line">    predict_y = gridsearch.predict(test_x)</span><br><span class="line">    print(<span class="string">"准确率 %0.4lf"</span> %accuracy_score(test_y, predict_y))</span><br><span class="line">    response[<span class="string">'predict_y'</span>] = predict_y</span><br><span class="line">    response[<span class="string">'accuracy_score'</span>] = accuracy_score(test_y,predict_y)</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">()</span>:</span></span><br><span class="line">    data = pd.read_csv(<span class="string">'UCI_Credit_Card.csv'</span>)</span><br><span class="line">    <span class="comment"># 数据条数和字段数量</span></span><br><span class="line">    print(data.shape)</span><br><span class="line">    <span class="comment"># 数据探索</span></span><br><span class="line">    print(data.describe)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_data</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="comment"># 查看下一个月的违约率</span></span><br><span class="line">    next_month = data[<span class="string">'default.payment.next.month'</span>].value_counts()</span><br><span class="line"></span><br><span class="line">    print(next_month)</span><br><span class="line">    <span class="comment"># 统计违约率结果</span></span><br><span class="line">    df = pd.DataFrame(&#123;<span class="string">'default.payment.next.month'</span>: next_month.index, <span class="string">'values'</span>: next_month.values&#125;)</span><br><span class="line">    print(df)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 正常显示中文标签</span></span><br><span class="line">    <span class="comment"># plt.rcParams['font.sans-serif'] = ['FangSong']  # 用来正常显示中文标签</span></span><br><span class="line">    plt.rcParams[<span class="string">"font.family"</span>] = <span class="string">'Arial Unicode MS'</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">    plt.title(<span class="string">'信用卡违约率客户 (违约：1，守约：0)'</span>)</span><br><span class="line">    sns.set_color_codes(<span class="string">'pastel'</span>)</span><br><span class="line">    sns.barplot(x=<span class="string">'default.payment.next.month'</span>, y=<span class="string">"values"</span>, data=df)</span><br><span class="line">    locs, labels = plt.xticks()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_feature</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="comment"># 特征选择，去掉ID字段、最后一个结果字段即可</span></span><br><span class="line">    data.drop([<span class="string">'ID'</span>], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)  <span class="comment"># ID这个字段没有用</span></span><br><span class="line">    target = data[<span class="string">'default.payment.next.month'</span>].values</span><br><span class="line">    columns = data.columns.tolist()</span><br><span class="line">    columns.remove(<span class="string">'default.payment.next.month'</span>)</span><br><span class="line">    features = data[columns].values</span><br><span class="line">    <span class="keyword">return</span> features, target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    data = get_data()</span><br><span class="line">    show_data(data)</span><br><span class="line">    features, target = get_feature(data)</span><br><span class="line">    <span class="comment"># 30%作为测试集，其余作为训练集</span></span><br><span class="line">    train_x, test_x, train_y, test_y = train_test_split(features, target, test_size=<span class="number">0.30</span>, stratify = target, random_state = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> model, model_name, model_param_grid <span class="keyword">in</span> zip(classifiers, classifier_names, classifier_param_grid):</span><br><span class="line">        pipeline = Pipeline([</span><br><span class="line">            (<span class="string">'scaler'</span>, StandardScaler()),</span><br><span class="line">            (model_name, model)</span><br><span class="line">        ])</span><br><span class="line">        result = GridSearchCV_work(pipeline, train_x, train_y, test_x, test_y, model_param_grid, score=<span class="string">'accuracy'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">30000</span>, <span class="number">25</span>)</span><br><span class="line">&lt;bound method NDFrame.describe of           ID  LIMIT_BAL  SEX  ...  PAY_AMT5  PAY_AMT6  default.payment.next.month</span><br><span class="line"><span class="number">0</span>          <span class="number">1</span>    <span class="number">20000.0</span>    <span class="number">2</span>  ...       <span class="number">0.0</span>       <span class="number">0.0</span>                           <span class="number">1</span></span><br><span class="line"><span class="number">1</span>          <span class="number">2</span>   <span class="number">120000.0</span>    <span class="number">2</span>  ...       <span class="number">0.0</span>    <span class="number">2000.0</span>                           <span class="number">1</span></span><br><span class="line"><span class="number">2</span>          <span class="number">3</span>    <span class="number">90000.0</span>    <span class="number">2</span>  ...    <span class="number">1000.0</span>    <span class="number">5000.0</span>                           <span class="number">0</span></span><br><span class="line"><span class="number">3</span>          <span class="number">4</span>    <span class="number">50000.0</span>    <span class="number">2</span>  ...    <span class="number">1069.0</span>    <span class="number">1000.0</span>                           <span class="number">0</span></span><br><span class="line"><span class="number">4</span>          <span class="number">5</span>    <span class="number">50000.0</span>    <span class="number">1</span>  ...     <span class="number">689.0</span>     <span class="number">679.0</span>                           <span class="number">0</span></span><br><span class="line">      ...        ...  ...  ...       ...       ...                         ...</span><br><span class="line"><span class="number">29995</span>  <span class="number">29996</span>   <span class="number">220000.0</span>    <span class="number">1</span>  ...    <span class="number">5000.0</span>    <span class="number">1000.0</span>                           <span class="number">0</span></span><br><span class="line"><span class="number">29996</span>  <span class="number">29997</span>   <span class="number">150000.0</span>    <span class="number">1</span>  ...       <span class="number">0.0</span>       <span class="number">0.0</span>                           <span class="number">0</span></span><br><span class="line"><span class="number">29997</span>  <span class="number">29998</span>    <span class="number">30000.0</span>    <span class="number">1</span>  ...    <span class="number">2000.0</span>    <span class="number">3100.0</span>                           <span class="number">1</span></span><br><span class="line"><span class="number">29998</span>  <span class="number">29999</span>    <span class="number">80000.0</span>    <span class="number">1</span>  ...   <span class="number">52964.0</span>    <span class="number">1804.0</span>                           <span class="number">1</span></span><br><span class="line"><span class="number">29999</span>  <span class="number">30000</span>    <span class="number">50000.0</span>    <span class="number">1</span>  ...    <span class="number">1000.0</span>    <span class="number">1000.0</span>                           <span class="number">1</span></span><br><span class="line">[<span class="number">30000</span> rows x <span class="number">25</span> columns]&gt;</span><br><span class="line"><span class="number">0</span>    <span class="number">23364</span></span><br><span class="line"><span class="number">1</span>     <span class="number">6636</span></span><br><span class="line">Name: default.payment.next.month, dtype: int64</span><br><span class="line">   default.payment.next.month  values</span><br><span class="line"><span class="number">0</span>                           <span class="number">0</span>   <span class="number">23364</span></span><br><span class="line"><span class="number">1</span>                           <span class="number">1</span>    <span class="number">6636</span></span><br><span class="line">GridSearch最优参数： &#123;<span class="string">'svc__C'</span>: <span class="number">1</span>, <span class="string">'svc__gamma'</span>: <span class="number">0.01</span>&#125;</span><br><span class="line">GridSearch最优分数： <span class="number">0.8186</span></span><br><span class="line">准确率 <span class="number">0.8172</span></span><br><span class="line">GridSearch最优参数： &#123;<span class="string">'decisiontreeclassifier__max_depth'</span>: <span class="number">6</span>&#125;</span><br><span class="line">GridSearch最优分数： <span class="number">0.8208</span></span><br><span class="line">准确率 <span class="number">0.8113</span></span><br><span class="line">GridSearch最优参数： &#123;<span class="string">'randomforestclassifier__n_estimators'</span>: <span class="number">6</span>&#125;</span><br><span class="line">GridSearch最优分数： <span class="number">0.8004</span></span><br><span class="line">准确率 <span class="number">0.7994</span></span><br><span class="line">GridSearch最优参数： &#123;<span class="string">'kneighborsclassifier__n_neighbors'</span>: <span class="number">8</span>&#125;</span><br><span class="line">GridSearch最优分数： <span class="number">0.8040</span></span><br><span class="line">准确率 <span class="number">0.8036</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586884510276-5fe1de3d-a2b8-4c93-b940-372069fbed52.png#align=left&display=inline&height=1774&margin=%5Bobject%20Object%5D&name=187d0233d4fb5f07a9653e5ae4754372.png&originHeight=1774&originWidth=1729&size=124838&status=done&style=none&width=1729" alt="187d0233d4fb5f07a9653e5ae4754372.png"><br><br><br>从结果中，我们能看到 SVM 分类器的准确率最高，测试准确率为 0.8172。在决策树分类中，我设置了 3 种最大深度，当最大深度 =6 时结果最优，测试准确率为 0.8113；在随机森林分类中，我设置了 3 个决策树个数的取值，取值为 6 时结果最优，测试准确率为 0.7994；在 KNN 分类中，我设置了 3 个 n 的取值，取值为 8 时结果最优，测试准确率为 0.8036。<br></p><p><a name="cfCD6"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br>今天我给你讲了随机森林的概念及工具的使用，另外针对数据挖掘算法中经常采用的参数调优，也介绍了 GridSearchCV 工具这个利器。并将这两者结合起来，在信用卡违约分析这个项目中进行了使用。<br><br><br>很多时候，我们不知道该采用哪种分类算法更适合。即便是对于一种分类算法，也有很多参数可以调优，每个参数都有一定的取值范围。我们可以把想要采用的分类器，以及这些参数的取值范围都设置到数组里，然后使用 GridSearchCV 工具进行调优。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586884632239-1bcdafa2-dde8-4fe6-9acb-52e5dca88f2f.png#align=left&display=inline&height=1019&margin=%5Bobject%20Object%5D&name=14f9cddc17d6cceb0b8cbc4381c65216.png&originHeight=1019&originWidth=1728&size=401439&status=done&style=none&width=1728" alt="14f9cddc17d6cceb0b8cbc4381c65216.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;今天我来带你做一个数据挖掘的项目。在数据挖掘的过程中，我们经常会遇到一些问题，比如：如何选择各种分类器，到底选择哪个分类算法，是 SVM，决策树
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Random Forest" scheme="cpeixin.cn/tags/Random-Forest/"/>
    
  </entry>
  
  <entry>
    <title>数据分析 - PageRank 实战</title>
    <link href="cpeixin.cn/2019/03/13/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%20-%20PageRank-%E5%AE%9E%E6%88%98/"/>
    <id>cpeixin.cn/2019/03/13/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%20-%20PageRank-%E5%AE%9E%E6%88%98/</id>
    <published>2019-03-12T16:17:42.000Z</published>
    <updated>2020-04-06T16:19:44.167Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>上文讲了 PageRank 算法经常被用到网络关系的分析中，比如在社交网络中计算个人的影响力，计算论文的影响力或者网站的影响力等。<br><br><br>今天我们就来做一个关于 PageRank 算法的实战，在这之前，你需要思考三个问题：<br></p><ul><li>如何使用工具完成 PageRank 算法，包括使用工具创建网络图，设置节点、边、权重等，并通过创建好的网络图计算节点的 PR 值；</li><li>对于一个实际的项目，比如希拉里的 9306 封邮件（工具包中邮件的数量），如何使用 PageRank 算法挖掘出有影响力的节点，并且绘制网络图；</li><li>如何对创建好的网络图进行可视化，如果网络中的节点数较多，如何筛选重要的节点进行可视化，从而得到精简的网络关系图。</li></ul><p><a name="C1FCw"></a></p><h3 id="如何使用工具实现-PageRank-算法"><a href="#如何使用工具实现-PageRank-算法" class="headerlink" title="如何使用工具实现 PageRank 算法"></a>如何使用工具实现 PageRank 算法</h3><p><br>PageRank 算法工具在 sklearn 中并不存在，我们需要找到新的工具包。实际上有一个关于图论和网络建模的工具叫 NetworkX，它是用 Python 语言开发的工具，内置了常用的图与网络分析算法，可以方便我们进行网络数据分析。上节课，我举了一个网页权重的例子，假设一共有 4 个网页 A、B、C、D，它们之间的链接信息如图所示：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586188618330-36c3f9f2-d635-4069-9294-b9e7c9b4fdd3.png#align=left&display=inline&height=1171&name=47e5f21d16b15a98d4a32a73ebd477ea.png&originHeight=1171&originWidth=1711&size=1022493&status=done&style=none&width=1711" alt="47e5f21d16b15a98d4a32a73ebd477ea.png"><br><br><br>针对这个例子，我们看下用 NetworkX 如何计算 A、B、C、D 四个网页的 PR 值，具体代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="comment"># 创建有向图</span></span><br><span class="line">G = nx.DiGraph() </span><br><span class="line"><span class="comment"># 有向图之间边的关系</span></span><br><span class="line">edges = [(<span class="string">"A"</span>, <span class="string">"B"</span>), (<span class="string">"A"</span>, <span class="string">"C"</span>), (<span class="string">"A"</span>, <span class="string">"D"</span>), (<span class="string">"B"</span>, <span class="string">"A"</span>), (<span class="string">"B"</span>, <span class="string">"D"</span>), (<span class="string">"C"</span>, <span class="string">"A"</span>), (<span class="string">"D"</span>, <span class="string">"B"</span>), (<span class="string">"D"</span>, <span class="string">"C"</span>)]</span><br><span class="line"><span class="keyword">for</span> edge <span class="keyword">in</span> edges:</span><br><span class="line">    G.add_edge(edge[<span class="number">0</span>], edge[<span class="number">1</span>])</span><br><span class="line">pagerank_list = nx.pagerank(G, alpha=<span class="number">1</span>)</span><br><span class="line">print(<span class="string">"pagerank值是："</span>, pagerank_list)</span><br></pre></td></tr></table></figure><p><br>结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pagerank值是： &#123;&#39;A&#39;: 0.33333396911621094, &#39;B&#39;: 0.22222201029459634, &#39;C&#39;: 0.22222201029459634, &#39;D&#39;: 0.22222201029459634&#125;</span><br></pre></td></tr></table></figure><p><br>我们通过 NetworkX 创建了一个有向图之后，设置了节点之间的边，然后使用 PageRank 函数就可以求得节点的 PR 值，结果和上节课中我们人工模拟的结果一致。好了，运行完这个例子之后，我们来看下 NetworkX 工具都有哪些常用的操作。<br><br><br>1. 关于图的创建<br><br><br>图可以分为无向图和有向图，在 NetworkX 中分别采用不同的函数进行创建。无向图指的是不用节点之间的边的方向，使用 nx.Graph() 进行创建；有向图指的是节点之间的边是有方向的，使用 nx.DiGraph() 来创建。在上面这个例子中，存在 A→D 的边，但不存在 D→A 的边。<br><br><br>2. 关于节点的增加、删除和查询<br><br><br>如果想在网络中增加节点，可以使用 G.add_node(‘A’) 添加一个节点，也可以使用 G.add_nodes_from([‘B’,‘C’,‘D’,‘E’]) 添加节点集合。如果想要删除节点，可以使用 G.remove_node(node) 删除一个指定的节点，也可以使用 G.remove_nodes_from([‘B’,‘C’,‘D’,‘E’]) 删除集合中的节点。那么该如何查询节点呢？如果你想要得到图中所有的节点，就可以使用 G.nodes()，也可以用 G.number_of_nodes() 得到图中节点的个数。<br><br><br>3. 关于边的增加、删除、查询<br><br><br>增加边与添加节点的方式相同，使用 G.add_edge(“A”, “B”) 添加指定的“从 A 到 B”的边，也可以使用 add_edges_from 函数从边集合中添加。我们也可以做一个加权图，也就是说边是带有权重的，使用 add_weighted_edges_from 函数从带有权重的边的集合中添加。在这个函数的参数中接收的是 1 个或多个三元组[u,v,w]作为参数，u、v、w 分别代表起点、终点和权重。<br><br><br>另外，我们可以使用 remove_edge 函数和 remove_edges_from 函数删除指定边和从边集合中删除。<br><br><br>另外可以使用 edges() 函数访问图中所有的边，使用 number_of_edges() 函数得到图中边的个数。<br><br><br>以上是关于图的基本操作，如果我们创建了一个图，并且对节点和边进行了设置，就可以找到其中有影响力的节点，原理就是通过 PageRank 算法，使用 nx.pagerank(G) 这个函数，函数中的参数 G 代表创建好的图。<br></p><p><a name="FqpAI"></a></p><h3 id="如何用-PageRank-揭秘希拉里邮件中的人物关系"><a href="#如何用-PageRank-揭秘希拉里邮件中的人物关系" class="headerlink" title="如何用 PageRank 揭秘希拉里邮件中的人物关系"></a>如何用 PageRank 揭秘希拉里邮件中的人物关系</h3><p><br>了解了 NetworkX 工具的基础使用之后，我们来看一个实际的案例：希拉里邮件人物关系分析。希拉里邮件事件相信你也有耳闻，对这个数据的背景我们就不做介绍了。你可以从 GitHub 上下载这个数据集：<a href="https://github.com/cystanford/PageRank。" target="_blank" rel="external nofollow noopener noreferrer">https://github.com/cystanford/PageRank。</a><br><br><br>整个数据集由三个文件组成：Aliases.csv，Emails.csv 和 Persons.csv，其中 Emails 文件记录了所有公开邮件的内容，发送者和接收者的信息。Persons 这个文件统计了邮件中所有人物的姓名及对应的 ID。因为姓名存在别名的情况，为了将邮件中的人物进行统一，我们还需要用 Aliases 文件来查询别名和人物的对应关系。整个数据集包括了 9306 封邮件和 513 个人名，数据集还是比较大的。<br><br><br>不过这一次我们不需要对邮件的内容进行分析，只需要通过邮件中的发送者和接收者（对应 Emails.csv 文件中的 MetadataFrom 和 MetadataTo 字段）来绘制整个关系网络。因为涉及到的人物很多，因此我们需要通过 PageRank 算法计算每个人物在邮件关系网络中的权重，最后筛选出来最有价值的人物来进行关系网络图的绘制。<br><br><br>了解了数据集和项目背景之后，我们来设计到执行的流程步骤：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1586189558696-ade25b5c-0fb4-4bef-b867-8320c21e4c37.jpeg#align=left&display=inline&height=1106&name=image.jpeg&originHeight=1106&originWidth=2411&size=281079&status=done&style=none&width=2411" alt="image.jpeg"><br><br><br>首先我们需要加载数据源；<br><br><br>在准备阶段：我们需要对数据进行探索，在数据清洗过程中，因为邮件中存在别名的情况，因此我们需要统一人物名称。另外邮件的正文并不在我们考虑的范围内，只统计邮件中的发送者和接收者，因此<strong>我们筛选 MetadataFrom 和 MetadataTo 这两个字段作为特征</strong>。同时，发送者和接收者可能存在多次邮件往来，需要设置权重来统计两人邮件往来的次数。次数越多代表这个边（从发送者到接收者的边）的权重越高；<br><br><br>在挖掘阶段：我们主要是对已经设置好的网络图进行 PR 值的计算，但邮件中的人物有 500 多人，有些人的权重可能不高，我们需要筛选 PR 值高的人物，绘制出他们之间的往来关系。在可视化的过程中，我们可以通过节点的 PR 值来绘制节点的大小，PR 值越大，节点的绘制尺寸越大。<br><br><br>设置好流程之后，实现的代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 用 PageRank 挖掘希拉里邮件中的重要任务关系</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 数据加载</span></span><br><span class="line">emails = pd.read_csv(<span class="string">"./input/Emails.csv"</span>)</span><br><span class="line"><span class="comment"># 读取别名文件</span></span><br><span class="line">file = pd.read_csv(<span class="string">"./input/Aliases.csv"</span>)</span><br><span class="line">aliases = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> index, row <span class="keyword">in</span> file.iterrows():</span><br><span class="line">    aliases[row[<span class="string">'Alias'</span>]] = row[<span class="string">'PersonId'</span>]</span><br><span class="line"><span class="comment"># 读取人名文件</span></span><br><span class="line">file = pd.read_csv(<span class="string">"./input/Persons.csv"</span>)</span><br><span class="line">persons = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> index, row <span class="keyword">in</span> file.iterrows():</span><br><span class="line">    persons[row[<span class="string">'Id'</span>]] = row[<span class="string">'Name'</span>]</span><br><span class="line"><span class="comment"># 针对别名进行转换        </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unify_name</span><span class="params">(name)</span>:</span></span><br><span class="line">    <span class="comment"># 姓名统一小写</span></span><br><span class="line">    name = str(name).lower()</span><br><span class="line">    <span class="comment"># 去掉, 和 @后面的内容</span></span><br><span class="line">    name = name.replace(<span class="string">","</span>,<span class="string">""</span>).split(<span class="string">"@"</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 别名转换</span></span><br><span class="line">    <span class="keyword">if</span> name <span class="keyword">in</span> aliases.keys():</span><br><span class="line">        <span class="keyword">return</span> persons[aliases[name]]</span><br><span class="line">    <span class="keyword">return</span> name</span><br><span class="line"><span class="comment"># 画网络图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_graph</span><span class="params">(graph, layout=<span class="string">'spring_layout'</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 使用 Spring Layout 布局，类似中心放射状</span></span><br><span class="line">    <span class="keyword">if</span> layout == <span class="string">'circular_layout'</span>:</span><br><span class="line">        positions=nx.circular_layout(graph)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        positions=nx.spring_layout(graph)</span><br><span class="line">    <span class="comment"># 设置网络图中的节点大小，大小与 pagerank 值相关，因为 pagerank 值很小所以需要 *20000</span></span><br><span class="line">    nodesize = [x[<span class="string">'pagerank'</span>]*<span class="number">20000</span> <span class="keyword">for</span> v,x <span class="keyword">in</span> graph.nodes(data=<span class="literal">True</span>)]</span><br><span class="line">    <span class="comment"># 设置网络图中的边长度</span></span><br><span class="line">    edgesize = [np.sqrt(e[<span class="number">2</span>][<span class="string">'weight'</span>]) <span class="keyword">for</span> e <span class="keyword">in</span> graph.edges(data=<span class="literal">True</span>)]</span><br><span class="line">    <span class="comment"># 绘制节点</span></span><br><span class="line">    nx.draw_networkx_nodes(graph, positions, node_size=nodesize, alpha=<span class="number">0.4</span>)</span><br><span class="line">    <span class="comment"># 绘制边</span></span><br><span class="line">    nx.draw_networkx_edges(graph, positions, edge_size=edgesize, alpha=<span class="number">0.2</span>)</span><br><span class="line">    <span class="comment"># 绘制节点的 label</span></span><br><span class="line">    nx.draw_networkx_labels(graph, positions, font_size=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 输出希拉里邮件中的所有人物关系图</span></span><br><span class="line">    plt.show()</span><br><span class="line"><span class="comment"># 将寄件人和收件人的姓名进行规范化</span></span><br><span class="line">emails.MetadataFrom = emails.MetadataFrom.apply(unify_name)</span><br><span class="line">emails.MetadataTo = emails.MetadataTo.apply(unify_name)</span><br><span class="line"><span class="comment"># 设置遍的权重等于发邮件的次数</span></span><br><span class="line">edges_weights_temp = defaultdict(list)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> zip(emails.MetadataFrom, emails.MetadataTo, emails.RawText):</span><br><span class="line">    temp = (row[<span class="number">0</span>], row[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> temp <span class="keyword">not</span> <span class="keyword">in</span> edges_weights_temp:</span><br><span class="line">        edges_weights_temp[temp] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        edges_weights_temp[temp] = edges_weights_temp[temp] + <span class="number">1</span></span><br><span class="line"><span class="comment"># 转化格式 (from, to), weight =&gt; from, to, weight</span></span><br><span class="line">edges_weights = [(key[<span class="number">0</span>], key[<span class="number">1</span>], val) <span class="keyword">for</span> key, val <span class="keyword">in</span> edges_weights_temp.items()]</span><br><span class="line"><span class="comment"># 创建一个有向图</span></span><br><span class="line">graph = nx.DiGraph()</span><br><span class="line"><span class="comment"># 设置有向图中的路径及权重 (from, to, weight)</span></span><br><span class="line">graph.add_weighted_edges_from(edges_weights)</span><br><span class="line"><span class="comment"># 计算每个节点（人）的 PR 值，并作为节点的 pagerank 属性</span></span><br><span class="line">pagerank = nx.pagerank(graph)</span><br><span class="line"><span class="comment"># 将 pagerank 数值作为节点的属性</span></span><br><span class="line">nx.set_node_attributes(graph, name = <span class="string">'pagerank'</span>, values=pagerank)</span><br><span class="line"><span class="comment"># 画网络图</span></span><br><span class="line">show_graph(graph)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将完整的图谱进行精简</span></span><br><span class="line"><span class="comment"># 设置 PR 值的阈值，筛选大于阈值的重要核心节点</span></span><br><span class="line">pagerank_threshold = <span class="number">0.005</span></span><br><span class="line"><span class="comment"># 复制一份计算好的网络图</span></span><br><span class="line">small_graph = graph.copy()</span><br><span class="line"><span class="comment"># 剪掉 PR 值小于 pagerank_threshold 的节点</span></span><br><span class="line"><span class="keyword">for</span> n, p_rank <span class="keyword">in</span> graph.nodes(data=<span class="literal">True</span>):</span><br><span class="line">    <span class="keyword">if</span> p_rank[<span class="string">'pagerank'</span>] &lt; pagerank_threshold: </span><br><span class="line">        small_graph.remove_node(n)</span><br><span class="line"><span class="comment"># 画网络图,采用circular_layout布局让筛选出来的点组成一个圆</span></span><br><span class="line">show_graph(small_graph, <span class="string">'circular_layout'</span>)</span><br></pre></td></tr></table></figure><p><br>结果如下：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586189813449-f26ce964-a669-44e6-bf91-4a7ec9819042.png#align=left&display=inline&height=1028&name=419f7621392045f07bcd03f9e4c7c8b1.png&originHeight=1028&originWidth=1728&size=762127&status=done&style=none&width=1728" alt="419f7621392045f07bcd03f9e4c7c8b1.png"><br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586189816102-b524301a-85fe-46f5-b698-560a467920c9.png#align=left&display=inline&height=376&name=3f08f61360e8a82a23a16e44d2b973e1.png&originHeight=376&originWidth=519&size=71800&status=done&style=none&width=519" alt="3f08f61360e8a82a23a16e44d2b973e1.png"></p><p>针对代码中的几个模块我做个简单的说明：<br><br><br>1. 函数定义人物的名称需要统一，因此我设置了 unify_name 函数，同时设置了 show_graph 函数将网络图可视化。NetworkX 提供了多种可视化布局，这里我使用 spring_layout 布局，也就是呈中心放射状。<br><br><br>除了 spring_layout 外，NetworkX 还有另外三种可视化布局，circular_layout（在一个圆环上均匀分布节点），random_layout（随机分布节点 ），shell_layout（节点都在同心圆上）。<br><br><br>2. 计算边权重邮件的发送者和接收者的邮件往来可能不止一次，我们需要用两者之间邮件往来的次数计算这两者之间边的权重，所以我用 edges_weights_temp 数组存储权重。而上面介绍过在 NetworkX 中添加权重边（即使用 add_weighted_edges_from 函数）的时候，接受的是 u、v、w 的三元数组，因此我们还需要对格式进行转换，具体转换方式见代码。<br><br><br>3.PR 值计算及筛选我使用 nx.pagerank(graph) 计算了节点的 PR 值。由于节点数量很多，我们设置了 PR 值阈值，即 pagerank_threshold=0.005，然后遍历节点，删除小于 PR 值阈值的节点，形成新的图 small_graph，最后对 small_graph 进行可视化（对应运行结果的第二张图）。<br></p><p><a name="dJp3x"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br>我们通过矩阵乘法求得网页的权重，这我们使用 NetworkX 可以得到相同的结果。另外我带你用 PageRank 算法做了一次实战，我们将一个复杂的网络图，通过 PR 值的计算、筛选，最终得到了一张精简的网络图。<br><br><br>在这个过程中我们学习了 NetworkX 工具的使用，包括创建图、节点、边及 PR 值的计算。实际上掌握了 PageRank 的理论之后，在实战中往往就是一行代码的事。<br><br><br>但项目与理论不同，项目中涉及到的数据量比较大，你会花 80% 的时间（或 80% 的代码量）在预处理过程中，比如今天的项目中，我们对别名进行了统一，对边的权重进行计算，同时还需要把计算好的结果以可视化的方式呈现。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586189993701-5e8316c2-097d-4f14-b2d6-36b2ccdaef8b.png#align=left&display=inline&height=794&name=307055050e005ba5092028a074a5c142.png&originHeight=794&originWidth=1636&size=295905&status=done&style=none&width=1636" alt="307055050e005ba5092028a074a5c142.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;上文讲了 PageRank 算法经常被用到网络关系的分析中，比如在社交网络中计算个人的影响力，计算论文的影响力或者网站的影响力等。&lt;br&gt;&lt;br
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="PageRank" scheme="cpeixin.cn/tags/PageRank/"/>
    
  </entry>
  
  <entry>
    <title>PageRank 原理</title>
    <link href="cpeixin.cn/2019/03/10/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%20-%20PageRank-%E5%8E%9F%E7%90%86/"/>
    <id>cpeixin.cn/2019/03/10/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%20-%20PageRank-%E5%8E%9F%E7%90%86/</id>
    <published>2019-03-10T14:37:25.000Z</published>
    <updated>2020-04-06T16:19:48.787Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>互联网发展到现在，搜索引擎已经非常好用，基本上输入关键词，都能找到匹配的内容，质量还不错。但在 1998 年之前，搜索引擎的体验并不好。</p><p>早期的搜索引擎，会遇到下面的两类问题：返回结果质量不高：搜索结果不考虑网页的质量，而是通过时间顺序进行检索；容易被人钻空子：搜索引擎是基于检索词进行检索的，页面中检索词出现的频次越高，匹配度越高，这样就会出现网页作弊的情况。有些网页为了增加搜索引擎的排名，故意增加某个检索词的频率。</p><p>基于这些缺陷，当时 Google 的创始人拉里·佩奇提出了 PageRank 算法，目的就是要找到优质的网页，这样 Google 的排序结果不仅能找到用户想要的内容，而且还会从众多网页中筛选出权重高的呈现给用户。</p><p>Google 的两位创始人都是斯坦福大学的博士生，他们提出的 PageRank 算法受到了论文影响力因子的评价启发。当一篇论文被引用的次数越多，证明这篇论文的影响力越大。正是这个想法解决了当时网页检索质量不高的问题。</p><p><a name="MGtoH"></a></p><h3 id="PageRank-的简化模型"><a href="#PageRank-的简化模型" class="headerlink" title="PageRank 的简化模型"></a>PageRank 的简化模型</h3><p><br>我们先来看下 PageRank 是如何计算的。我假设一共有 4 个网页 A、B、C、D。它们之间的链接信息如图所示：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586100371985-4c557416-b288-4384-b68f-17a24156fe07.png#align=left&display=inline&height=1007&name=814d53ff8d73113631482e71b7c53636.png&originHeight=1007&originWidth=1472&size=798178&status=done&style=none&width=1472" alt="814d53ff8d73113631482e71b7c53636.png"><br><br><br>这里有两个概念你需要了解一下。出链指的是链接出去的链接。入链指的是链接进来的链接。<br><br><br>比如图中 A 有 2 个入链，3 个出链。简单来说，一个网页的影响力 = 所有入链集合的页面的加权影响力之和，用公式表示为：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586100660740-2e7a1dc6-6882-42ef-a1d0-53156095a1de.png#align=left&display=inline&height=88&name=70104ab44fa1d9d690f99dc328d8af0c.png&originHeight=88&originWidth=227&size=7483&status=done&style=none&width=227" alt="70104ab44fa1d9d690f99dc328d8af0c.png"><br><br><br>u 为待评估的页面，Bu 为页面 u 的入链集合。针对入链集合中的任意页面 v，<strong>它能给 u 带来的影响力是其自身的影响力 PR(v) 除以 v 页面的出链数量，即页面 v 把影响力 PR(v) 平均分配给了它的出链</strong>，这样统计所有能给 u 带来链接的页面 v，得到的总和就是网页 u 的影响力，即为 PR(u)。<br><br><br>所以你能看到，出链会给被链接的页面赋予影响力，当我们统计了一个网页链出去的数量，也就是统计了这个网页的跳转概率。<br><br><br>在这个例子中，你能看到 A 有三个出链分别链接到了 B、C、D 上。那么当用户访问 A 的时候，就有跳转到 B、C 或者 D 的可能性，跳转概率均为 1/3。B 有两个出链，链接到了 A 和 D 上，跳转概率为 1/2。这样，我们可以得到 A、B、C、D 这四个网页的转移矩阵 M：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586179570373-edfcd9e4-8221-4654-8f69-ffb5e07de5c9.png#align=left&display=inline&height=116&name=204b0934f166d6945a90185aa2c95dd4.png&originHeight=116&originWidth=209&size=8136&status=done&style=none&width=209" alt="204b0934f166d6945a90185aa2c95dd4.png"></p><p>转移矩阵解释：</p><ul><li>第一列是A的出链的概率</li></ul><p>A-&gt;A: 0 A-&gt;B: 1/3 A-&gt;C: 1/3 A-&gt;D: 1/3</p><ul><li>第二列是B的的出链的概率</li></ul><p>B-&gt;A: 1/2 B-&gt;B: 0 B-&gt;C:0 B-&gt;D: 1/2</p><ul><li>第三列是C的出链概率</li></ul><p>C-&gt;A:1 C-&gt;B:0 C-&gt;C:0 C-&gt;D: 0</p><ul><li>第四列是D的出链概率</li></ul><p>D-&gt;A: 0 D-&gt;B:1/2 D-&gt;C:1/2 D-&gt;D: 0<br><br><br>我们假设 A、B、C、D 四个页面的初始影响力都是相同的，即：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586179659116-45dbb2c1-a56f-4e97-a347-acafba778b62.png#align=left&display=inline&height=160&name=a8eb12b5242e082b5d2281300c326bb8.png&originHeight=160&originWidth=180&size=10192&status=done&style=none&width=180" alt="a8eb12b5242e082b5d2281300c326bb8.png"></p><p>当进行第一次转移之后，各页面的影响力 w1 变为：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586179679282-23fcc41a-d22b-4e2b-9337-5c724fbf055c.png#align=left&display=inline&height=112&name=fcbcdd8e96384f855b4f7c842627ff8c.png&originHeight=112&originWidth=385&size=9528&status=done&style=none&width=385" alt="fcbcdd8e96384f855b4f7c842627ff8c.png"><br><br><br>然后我们再用转移矩阵乘以 w1 得到 w2 结果，直到第 n 次迭代后 wn 影响力不再发生变化，可以收敛到 (0.3333，0.2222，0.2222，0.2222），也就是对应着 A、B、C、D 四个页面最终平衡状态下的影响力。<br><br><br>你能看出 A 页面相比于其他页面来说权重更大，也就是 PR 值更高。而 B、C、D 页面的 PR 值相等。<br><br><br>至此，我们模拟了一个简化的 PageRank 的计算过程，实际情况会比这个复杂，可能会面临两个问题：<br><br><br>1. 等级泄露（Rank Leak）：如果一个网页没有出链，就像是一个黑洞一样，吸收了其他网页的影响力而不释放，最终会导致其他网页的 PR 值为 0。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586183454358-44baf779-78bd-4887-a8d4-e35f79597b70.png#align=left&display=inline&height=997&name=77336108b0233638a35bfd7450438162.png&originHeight=997&originWidth=1190&size=619265&status=done&style=none&width=1190" alt="77336108b0233638a35bfd7450438162.png"><br><br><br>2. 等级沉没（Rank Sink）：如果一个网页只有出链，没有入链（如下图所示），计算的过程迭代下来，会导致这个网页的 PR 值为 0（也就是不存在公式中的 V）。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586183417549-557c2c16-58c3-4b46-a4d6-5de17f8beac7.png#align=left&display=inline&height=987&name=0d113854fb56116d79efe7f0e0374fe6.png&originHeight=987&originWidth=1203&size=608002&status=done&style=none&width=1203" alt="0d113854fb56116d79efe7f0e0374fe6.png"><br><br><br>针对等级泄露和等级沉没的情况，我们需要灵活处理。比如针对等级泄露的情况，我们可以把没有出链的节点，先从图中去掉，等计算完所有节点的 PR 值之后，再加上该节点进行计算。不过这种方法会导致新的等级泄露的节点的产生，所以工作量还是很大的。有没有一种方法，可以同时解决等级泄露和等级沉没这两个问题呢？<br><a name="MuxgP"></a></p><h3><a href="#" class="headerlink"></a></h3><p><a name="ntdmz"></a></p><h3 id="PageRank-的随机浏览模型"><a href="#PageRank-的随机浏览模型" class="headerlink" title="PageRank 的随机浏览模型"></a>PageRank 的随机浏览模型</h3><p><br>为了解决简化模型中存在的等级泄露和等级沉没的问题，拉里·佩奇提出了 PageRank 的随机浏览模型。他假设了这样一个场景：用户并不都是按照跳转链接的方式来上网，还有一种可能是不论当前处于哪个页面，都有概率访问到其他任意的页面，比如说用户就是要直接输入网址访问其他页面，虽然这个概率比较小。<br><br><br>所以他定义了阻尼因子 d，这个因子代表了用户按照跳转链接来上网的概率，通常可以取一个固定值 0.85，而 1-d=0.15 则代表了用户不是通过跳转链接的方式来访问网页的，比如直接输入网址。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586183366624-ed86e5ee-850a-4882-a5d6-85a3821149af.png#align=left&display=inline&height=312&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-04-06%20%E4%B8%8B%E5%8D%8810.13.02.png&originHeight=312&originWidth=1056&size=85657&status=done&style=none&width=1056" alt="屏幕快照 2020-04-06 下午10.13.02.png"><br><br><br>其中 N 为网页总数，这样我们又可以重新迭代网页的权重计算了，因为加入了阻尼因子 d，一定程度上解决了等级泄露和等级沉没的问题。通过数学定理（这里不进行讲解）也可以证明，最终 PageRank 随机浏览模型是可以收敛的，也就是可以得到一个稳定正常的 PR 值。<br></p><p><a name="AXqad"></a></p><h3 id="PageRank-在社交影响力评估中的应用"><a href="#PageRank-在社交影响力评估中的应用" class="headerlink" title="PageRank 在社交影响力评估中的应用"></a>PageRank 在社交影响力评估中的应用</h3><p><br>网页之间会形成一个网络，是我们的互联网，论文之间也存在着相互引用的关系，可以说我们所处的环境就是各种网络的集合。只要是有网络的地方，就存在出链和入链，就会有 PR 权重的计算，也就可以运用我们今天讲的 PageRank 算法。<br><br><br>我们可以把 PageRank 算法延展到社交网络领域中。比如在微博上，如果我们想要计算某个人的影响力，该怎么做呢？一个人的微博粉丝数并不一定等于他的实际影响力。如果按照 PageRank 算法，还需要看这些粉丝的质量如何。如果有很多明星或者大 V 关注，那么这个人的影响力一定很高。如果粉丝是通过购买僵尸粉得来的，那么即使粉丝数再多，影响力也不高。<br><br><br>同样，在工作场景中，比如说脉脉这个社交软件，它计算的就是个人在职场的影响力。如果你的工作关系是李开复、江南春这样的名人，那么你的职场影响力一定会很高。反之，如果你是个学生，在职场上被链入的关系比较少的话，职场影响力就会比较低。同样，如果你想要看一个公司的经营能力，也可以看这家公司都和哪些公司有合作。如果它合作的都是世界 500 强企业，那么这个公司在行业内一定是领导者，如果这个公司的客户都是小客户，即使数量比较多，业内影响力也不一定大。除非像淘宝一样，有海量的中小客户，最后大客户也会找上门来寻求合作。所以权重高的节点，往往会有一些权重同样很高的节点在进行合作。<br></p><p><a name="d8UW3"></a></p><h3 id="PageRank-给我们带来的启发"><a href="#PageRank-给我们带来的启发" class="headerlink" title="PageRank 给我们带来的启发"></a>PageRank 给我们带来的启发</h3><p><br>PageRank 可以说是 Google 搜索引擎重要的技术之一，在 1998 年帮助 Google 获得了搜索引擎的领先优势，现在 PageRank 已经比原来复杂很多，但它的思想依然能带给我们很多启发。<br><br><br>比如，如果你想要自己的媒体影响力有所提高，就尽量要混在大 V 圈中；如果想找到高职位的工作，就尽量结识公司高层，或者认识更多的猎头，因为猎头和很多高职位的人员都有链接关系。同样，PageRank 也可以帮我们识别链接农场。链接农场指的是网页为了链接而链接，填充了一些没有用的内容。这些页面相互链接或者指向了某一个网页，从而想要得到更高的权重。<br></p><p><a name="VwORv"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br>今天我给你讲了 PageRank 的算法原理，对简化的 PageRank 模型进行了模拟。针对简化模型中存在的<strong>等级泄露和等级沉没</strong>这两个问题，<strong>PageRank 的随机浏览模型引入了阻尼因子 d 来解决</strong>。同样，PageRank 有很广的应用领域，在许多网络结构中都有应用，比如计算一个人的微博影响力等。它也告诉我们，在社交网络中，链接的质量非常重要。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1586183943207-3b0721e5-5c04-41c8-a87c-419b8621d8c5.png#align=left&display=inline&height=924&name=f936296fed70f27ba23064ec14a7e37d.png&originHeight=924&originWidth=1727&size=377810&status=done&style=none&width=1727" alt="f936296fed70f27ba23064ec14a7e37d.png"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;互联网发展到现在，搜索引擎已经非常好用，基本上输入关键词，都能找到匹配的内容，质量还不错。但在 1998 年之前，搜索引擎的体验并不好。&lt;/p&gt;
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="PageRank" scheme="cpeixin.cn/tags/PageRank/"/>
    
  </entry>
  
  <entry>
    <title>数据分析-关联规则原理</title>
    <link href="cpeixin.cn/2019/03/02/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E5%8E%9F%E7%90%86/"/>
    <id>cpeixin.cn/2019/03/02/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E5%8E%9F%E7%90%86/</id>
    <published>2019-03-02T14:19:09.000Z</published>
    <updated>2020-04-05T14:30:54.004Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>关联规则这个概念，最早是由 Agrawal 等人在 1993 年提出的。在 1994 年 Agrawal 等人又提出了基于关联规则的 Apriori 算法，至今 Apriori 仍是关联规则挖掘的重要算法。<br><br><br><strong>关联规则挖掘</strong>可以让我们从数据集中发现项与项（item 与 item）之间的关系，它在我们的生活中有很多应用场景，“购物篮分析”就是一个常见的场景，这个场景可以从消费者交易记录中发掘商品与商品之间的关联关系，进而通过商品捆绑销售或者相关推荐的方式带来更多的销售量。所以说，关联规则挖掘是个非常有用的技术。<br><br><br>在今天的内容中，希望你能带着问题，和我一起来搞懂以下几个知识点：</p><ul><li>搞懂关联规则中的几个重要概念：支持度、置信度、提升度；</li><li>Apriori 算法的工作原理；</li><li>在实际工作中，我们该如何进行关联规则挖掘。</li></ul><p><a name="iGDgo"></a></p><h3 id="关联规则概念"><a href="#关联规则概念" class="headerlink" title="关联规则概念"></a>关联规则概念</h3><p>搞懂关联规则中的几个概念<br><br><br>我举一个超市购物的例子，下面是几名客户购买的商品列表：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585750069389-0cb13df9-8d19-442d-bb19-c3e5c3175230.png#align=left&display=inline&height=195&name=f7d0cc3c1a845bf790b344f62372941c.png&originHeight=195&originWidth=468&size=27163&status=done&style=none&width=468" alt="f7d0cc3c1a845bf790b344f62372941c.png"><br><br><br><br><br><strong>什么是支持度呢？</strong><br><br><br>支持度是个百分比，<strong>它指的是某个商品组合出现的次数与总次数之间的比例</strong>。<br><br><br>支持度越高，代表这个组合出现的频率越大。在这个例子中，我们能看到“牛奶”出现了 4 次，那么这 5 笔订单中“牛奶”的支持度就是 4/5=0.8。<br><br><br>同样<strong>“牛奶 + 面包”出现了 3 次，那么这 5 笔订单中“牛奶 + 面包”的支持度就是 3/5=0.6。</strong><br><br><br><strong>什么是置信度呢？</strong><br><br><br>它指的就是当你购买了商品 A，会有多大的概率购买商品 B，在上面这个例子中：<br><br><br>置信度（牛奶→啤酒）=2/4=0.5，代表如果你购买了牛奶，有多大的概率会购买啤酒？<br><br><br>置信度（啤酒→牛奶）=2/3=0.67，代表如果你购买了啤酒，有多大的概率会购买牛奶？<br><br><br>我们能看到，在 4 次购买了牛奶的情况下，有 2 次购买了啤酒，所以置信度 (牛奶→啤酒)=0.5，而在 3 次购买啤酒的情况下，有 2 次购买了牛奶，所以置信度（啤酒→牛奶）=0.67。<br><br><br>所以说置信度是个条件概念，<strong>就是说在 A 发生的情况下，B 发生的概率是多少。</strong><br><br><br><strong>什么是提升度呢？</strong><br><br><br>我们在做商品推荐的时候，<strong>重点考虑的是提升度</strong>，因为提升度代表的是“商品 A 的出现，对商品 B 的出现概率提升的”程度。<br><br><br>还是看上面的例子，如果我们单纯看置信度 (可乐→尿布)=1，也就是说可乐出现的时候，用户都会购买尿布，那么当用户购买可乐的时候，我们就需要推荐尿布么？<br><br><br>实际上，就算用户不购买可乐，也会直接购买尿布的，所以用户是否购买可乐，对尿布的提升作用并不大。<br><br><br>我们可以用下面的公式来计算商品 A 对商品 B 的提升度：<br><br><br><strong>提升度 (A→B)= 置信度 (A→B)/ 支持度 (B)</strong><br><br><br>这个公式是用来衡量 A 出现的情况下，是否会对 B 出现的概率有所提升。<br><br><br>所以提升度有三种可能：<br></p><ul><li>提升度 (A→B)&gt;1：代表有提升；</li><li>提升度 (A→B)=1：代表有没有提升，也没有下降；</li><li>提升度 (A→B)&lt;1：代表有下降。</li></ul><p><br><strong>提升度 (牛奶→啤酒)</strong><br><strong><img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1072113/1585752575464-518e8992-94d7-43e9-8ebd-5a11f913fb53.jpeg#align=left&display=inline&height=987&name=WechatIMG84.jpeg&originHeight=987&originWidth=1754&size=425247&status=done&style=none&width=1754" alt="WechatIMG84.jpeg"></strong><br><a name="j6KYP"></a></p><h3 id="Apriori-的工作原理"><a href="#Apriori-的工作原理" class="headerlink" title="Apriori 的工作原理"></a>Apriori 的工作原理</h3><p><br>明白了关联规则中支持度、置信度和提升度这几个重要概念，我们来看下 Apriori 算法是如何工作的。首先我们把上面案例中的商品用 ID 来代表，牛奶、面包、尿布、可乐、啤酒、鸡蛋的商品 ID 分别设置为 1-6，上面的数据表可以变为：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585752122553-ac9771fe-3eeb-4734-a9bb-b74262913f76.png#align=left&display=inline&height=196&name=e30fe11a21191259e6a93568461fa933.png&originHeight=196&originWidth=466&size=19390&status=done&style=none&width=466" alt="e30fe11a21191259e6a93568461fa933.png"><br><br><br>Apriori 算法其实就是查找<strong>频繁项集 (frequent itemset) **的过程，所以首先我们需要定义什么是频繁项集。</strong>频繁项集就是支持度大于等于最小支持度 (Min Support) 阈值的项集**，所以小于最小值支持度的项目就是非频繁项集，而大于等于最小支持度的项集就是频繁项集。<br><br><br>项集这个概念，英文叫做 itemset，它可以是单个的商品，也可以是商品的组合。<br><br><br>我们再来看下这个例子，假设我随机指定最小支持度是 50%，也就是 0.5。我们来看下 Apriori 算法是如何运算的。首先，我们先计算单个商品的支持度，也就是得到 K=1 项的支持度：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585752711588-43ac0c51-e9d4-40bc-9e1a-d1074ab82df6.png#align=left&display=inline&height=228&name=fff5ba49aff930bba71c98685be4fcde.png&originHeight=228&originWidth=467&size=18392&status=done&style=none&width=467" alt="fff5ba49aff930bba71c98685be4fcde.png"><br><br><br>因为最小支持度是 0.5，所以你能看到商品 4、6 是不符合最小支持度的，不属于频繁项集，于是经过筛选商品的频繁项集就变成：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585752793262-6a6d8b43-60c0-4be7-a89d-a2e7cc743eca.png#align=left&display=inline&height=164&name=ae108dc65c33e9ed9546a0d91bd881b6.png&originHeight=164&originWidth=464&size=15564&status=done&style=none&width=464" alt="ae108dc65c33e9ed9546a0d91bd881b6.png"><br><br><br>在这个基础上，我们将商品两两组合， 根据订单编号图，得到 k=2 项的支持度：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585752835552-c15c5f06-8c43-4cc9-946a-0ad834631594.png#align=left&display=inline&height=228&name=a51fd814ebd68304e3cb137630af3ea3.png&originHeight=228&originWidth=463&size=19667&status=done&style=none&width=463" alt="a51fd814ebd68304e3cb137630af3ea3.png"><br><br><br>我们再筛掉小于最小值支持度的商品组合，可以得到：</p><p><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585753001938-ae00db12-51a2-44d9-8496-a8eabfc8f046.png#align=left&display=inline&height=136&name=a087cd1bd2a9e033105de275834b79c8.png&originHeight=136&originWidth=472&size=15168&status=done&style=none&width=472" alt="a087cd1bd2a9e033105de275834b79c8.png"></p><p>我们再将商品进行 K=3 项的商品组合，可以得到：<br></p><table><thead><tr><th align="center">商品项集</th><th align="center">支持度</th></tr></thead><tbody><tr><td align="center">1，2，3</td><td align="center">3/5</td></tr><tr><td align="center">1，2，5</td><td align="center">1/5</td></tr><tr><td align="center">1，3，5</td><td align="center">2/5</td></tr><tr><td align="center">2，3，5</td><td align="center">2/5</td></tr></tbody></table><p><br>再筛掉小于最小值支持度的商品组合，可以得到：<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585753598894-55ee09c8-60e6-424c-9c09-21893fc841de.png#align=left&display=inline&height=75&name=d51fc9137a537d8cb96fa21707cab70f.png&originHeight=75&originWidth=469&size=12115&status=done&style=none&width=469" alt="d51fc9137a537d8cb96fa21707cab70f.png"></p><p>通过上面这个过程，我们可以得到 K=3 项的频繁项集{1,2,3}，也就是{牛奶、面包、尿布}的组合。<br><br><br>到这里，你已经和我模拟了一遍整个 Apriori 算法的流程，下面我来给你总结下 Apriori 算法的递归流程：</p><ul><li>K=1，计算 K 项集的支持度；</li><li>筛选掉小于最小支持度的项集；</li><li>如果项集为空，则对应 K-1 项集的结果为最终结果。</li></ul><p><br>否则 K=K+1，重复 1-3 步。<br></p><p><a name="gNxin"></a></p><h3 id="Apriori-的改进算法：FP-Growth-算法"><a href="#Apriori-的改进算法：FP-Growth-算法" class="headerlink" title="Apriori 的改进算法：FP-Growth 算法"></a>Apriori 的改进算法：FP-Growth 算法</h3><p><br>我们刚完成了 Apriori 算法的模拟，你能看到 Apriori 在计算的过程中有以下几个缺点：</p><ul><li>可能产生大量的候选集。因为采用排列组合的方式，把可能的项集都组合出来了；</li><li>每次计算都需要重新扫描数据集，来计算每个项集的支持度。</li></ul><p><br>所以 Apriori 算法会浪费很多计算空间和计算时间，为此人们提出了 FP-Growth 算法，它的特点是：创建了一棵 FP 树来存储频繁项集。在创建前对不满足最小支持度的项进行删除，减少了存储空间。<br><br><br>我稍后会讲解如何构造一棵 FP 树；整个生成过程只遍历数据集 2 次，大大减少了计算量。所以在实际工作中，我们常用 FP-Growth 来做频繁项集的挖掘，下面我给你简述下 FP-Growth 的原理。<br><br><br><strong>1. 创建项头表（item header table）</strong><br><br><br>创建项头表的作用是为 FP 构建及频繁项集挖掘提供索引。这一步的流程是先扫描一遍数据集，对于满足最小支持度的单个项（K=1 项集）按照支持度从高到低进行排序，这个过程中删除了不满足最小支持度的项。项头表包括了项目、支持度，以及该项在 FP 树中的链表。初始的时候链表为空。<br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585753828193-fb2cd719-a0ba-4ff8-ae47-a1321a8065fb.png#align=left&display=inline&height=166&name=69ce07c61a654faafb4f5114df1557f5.png&originHeight=166&originWidth=485&size=16312&status=done&style=none&width=485" alt="69ce07c61a654faafb4f5114df1557f5.png"><br><br><br><strong>2. 构造 FP 树</strong><br><br><br>FP 树的根节点记为 NULL 节点。整个流程是需要再次扫描数据集，对于每一条数据，按照支持度从高到低的顺序进行创建节点（也就是第一步中项头表中的排序结果），节点如果存在就将计数 count+1，如果不存在就进行创建。同时在创建的过程中，需要更新项头表的链表。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585754477615-f0cc1aeb-f303-4170-aa56-9102a1f3717c.png#align=left&display=inline&height=976&name=image.png&originHeight=976&originWidth=2198&size=1341075&status=done&style=none&width=2198" alt="image.png"><br><br><br><strong>3. 通过 FP 树挖掘频繁项集</strong><br><br><br>到这里，我们就得到了一个存储频繁项集的 FP 树，以及一个项头表。我们可以通过项头表来挖掘出每个频繁项集。具体的操作会用到一个概念，叫“条件模式基”，它指的是以要挖掘的节点为叶子节点，自底向上求出 FP 子树，然后将 FP 子树的祖先节点设置为叶子节点之和。我以“啤酒”的节点为例，从 FP 树中可以得到一棵 FP 子树，将祖先节点的支持度记为叶子节点之和，得到：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585754623125-7a63f4af-3a40-4030-b56e-4ef0c3263815.png#align=left&display=inline&height=1130&name=image.png&originHeight=1130&originWidth=1332&size=630041&status=done&style=none&width=1332" alt="image.png"><br><br><br>你能看出来，相比于原来的 FP 树，尿布和牛奶的频繁项集数减少了。这是因为我们求得的是以“啤酒”为节点的 FP 子树，也就是说，在频繁项集中一定要含有“啤酒”这个项。<br><br><br>你可以再看下原始的数据，其中订单 1{牛奶、面包、尿布}和订单 5{牛奶、面包、尿布、可乐}并不存在“啤酒”这个项，所以针对订单 1，尿布→牛奶→面包这个项集就会从 FP 树中去掉，针对订单 5 也包括了尿布→牛奶→面包这个项集也会从 FP 树中去掉，所以你能看到以“啤酒”为节点的 FP 子树，尿布、牛奶、面包项集上的计数比原来少了 2。<br><br><br>条件模式基不包括“啤酒”节点，而且祖先节点如果小于最小支持度就会被剪枝，所以“啤酒”的条件模式基为空。同理，我们可以求得“面包”的条件模式基为：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585754761520-d88566ff-b066-4d0e-be2f-9aabe0352757.png#align=left&display=inline&height=754&name=41026c8f25b64b01125c8b8d6a19a113.png&originHeight=754&originWidth=724&size=288803&status=done&style=none&width=724" alt="41026c8f25b64b01125c8b8d6a19a113.png"><br><br><br>所以可以求得面包的频繁项集为{尿布，面包}，{尿布，牛奶，面包}。同样，我们还可以求得牛奶，尿布的频繁项集，这里就不再计算展示。<br></p><p><a name="yN64E"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br>今天我给你讲了 Apriori 算法，它是在“购物篮分析”中常用的关联规则挖掘算法，在 Apriori 算法中你最主要是需要明白支持度、置信度、提升度这几个概念，以及 Apriori 迭代计算频繁项集的工作流程。<br><br><br>Apriori 算法在实际工作中需要对数据集扫描多次，会消耗大量的计算时间，所以在 2000 年 FP-Growth 算法被提出来，它只需要扫描两次数据集即可以完成关联规则的挖掘。<br><br><br>FP-Growth 算法最主要的贡献就是提出了 FP 树和项头表，通过 FP 树减少了频繁项集的存储以及计算时间。当然 Apriori 的改进算法除了 FP-Growth 算法以外，还有 CBA 算法、GSP 算法，这里就不进行介绍。<br><br><br>你能发现一种新理论的提出，往往是先从最原始的概念出发，提出一种新的方法。原始概念最接近人们模拟的过程，但往往会存在空间和时间复杂度过高的情况。所以后面其他人会对这个方法做改进型的创新，重点是在空间和时间复杂度上进行降维，比如采用新型的数据结构。你能看出树在存储和检索中是一个非常好用的数据结构。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585755090342-5e94e16e-33a2-4d60-b886-2c5908be24a5.png#align=left&display=inline&height=849&name=c7aee3b17269139ed3d5a6b82cc56735.png&originHeight=849&originWidth=1552&size=380704&status=done&style=none&width=1552" alt="c7aee3b17269139ed3d5a6b82cc56735.png"><br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;关联规则这个概念，最早是由 Agrawal 等人在 1993 年提出的。在 1994 年 Agrawal 等人又提出了基于关联规则的 Aprio
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Apriori" scheme="cpeixin.cn/tags/Apriori/"/>
    
  </entry>
  
  <entry>
    <title>数据分析-关联规则 实战</title>
    <link href="cpeixin.cn/2019/03/01/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99-%E5%AE%9E%E6%88%98/"/>
    <id>cpeixin.cn/2019/03/01/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99-%E5%AE%9E%E6%88%98/</id>
    <published>2019-03-01T14:19:27.000Z</published>
    <updated>2020-04-05T14:30:52.019Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --><p>昨天讲解了关联规则挖掘的原理。关联规则挖掘在生活中有很多使用场景，不仅是商品的捆绑销售，甚至在挑选演员决策上，你也能通过关联规则挖掘看出来某个导演选择演员的倾向。今天我来带你用 Apriori 算法做一个项目实战。<br><br><br>你需要掌握的是以下几点：<br></p><ul><li>熟悉上节课讲到的几个重要概念：支持度、置信度和提升度；</li><li>熟悉与掌握 Apriori 工具包的使用；</li><li>在实际问题中，灵活运用。包括数据集的准备等。</li></ul><p><a name="ZNoZJ"></a></p><h3 id="如何使用-Apriori"><a href="#如何使用-Apriori" class="headerlink" title="如何使用 Apriori"></a>如何使用 Apriori</h3><p><br>Apriori 虽然是十大算法之一，不过在 sklearn 工具包中并没有它，也没有 FP-Growth 算法。这里教你个方法，来选择 Python 中可以使用的工具包，你可以通过<a href="https://pypi.org/" target="_blank" rel="external nofollow noopener noreferrer">https://pypi.org/</a> 搜索工具包。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585838109422-3948da19-7f5e-439f-ae9f-53c4da519dd3.png#align=left&display=inline&height=767&name=image.png&originHeight=767&originWidth=1726&size=192193&status=done&style=none&width=1726" alt="image.png"><br><br><br>这个网站提供的工具包都是 Python 语言的，你能找到 8 个 Python 语言的 Apriori 工具包，具体选择哪个呢？建议你使用第二个工具包，即 efficient-apriori。后面我会讲到为什么推荐这个工具包。<br><br><br>首先你需要通过 pip install efficient-apriori 安装这个工具包。然后看下如何使用它，核心的代码就是这一行：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">itemsets, rules = apriori(data, min_support,  min_confidence)</span><br></pre></td></tr></table></figure><p><br>其中 data 是我们要提供的数据集，它是一个 list 数组类型。min_support 参数为最小支持度，在 efficient-apriori 工具包中用 0 到 1 的数值代表百分比，比如 0.5 代表最小支持度为 50%。min_confidence 是最小置信度，数值也代表百分比，比如 1 代表 100%。<br></p><blockquote><p>一般来说最小支持度常见的取值有0.5，0.1, 0.05。最小置信度常见的取值有1.0, 0.9, 0.8。可以通过尝试一些取值，然后观察关联结果的方式来调整最小值尺度和最小置信度的取值。</p></blockquote><p><br>关于支持度、置信度和提升度，我们再来简单回忆下。<br><br><br>支持度指的是某个商品组合出现的次数与总次数之间的比例。支持度越高，代表这个组合出现的概率越大。<br><br><br>置信度是一个条件概念，就是在 A 发生的情况下，B 发生的概率是多少。<br><br><br>提升度代表的是“商品 A 的出现，对商品 B 的出现概率提升了多少”。<br><br><br>接下来我们用这个工具包，跑一下上节课中讲到的超市购物的例子。下面是客户购买的商品列表：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585838224965-bc422cf1-7921-43d2-893c-46fff07a69a9.png#align=left&display=inline&height=202&name=image.png&originHeight=202&originWidth=476&size=27188&status=done&style=none&width=476" alt="image.png"><br><br><br>具体实现的代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> efficient_apriori <span class="keyword">import</span> apriori</span><br><span class="line"><span class="comment"># 设置数据集</span></span><br><span class="line">data = [(<span class="string">'牛奶'</span>,<span class="string">'面包'</span>,<span class="string">'尿布'</span>),</span><br><span class="line">           (<span class="string">'可乐'</span>,<span class="string">'面包'</span>, <span class="string">'尿布'</span>, <span class="string">'啤酒'</span>),</span><br><span class="line">           (<span class="string">'牛奶'</span>,<span class="string">'尿布'</span>, <span class="string">'啤酒'</span>, <span class="string">'鸡蛋'</span>),</span><br><span class="line">           (<span class="string">'面包'</span>, <span class="string">'牛奶'</span>, <span class="string">'尿布'</span>, <span class="string">'啤酒'</span>),</span><br><span class="line">           (<span class="string">'面包'</span>, <span class="string">'牛奶'</span>, <span class="string">'尿布'</span>, <span class="string">'可乐'</span>)]</span><br><span class="line"><span class="comment"># 挖掘频繁项集和频繁规则</span></span><br><span class="line">itemsets, rules = apriori(data, min_support=<span class="number">0.5</span>,  min_confidence=<span class="number">1</span>)</span><br><span class="line">print(itemsets)</span><br><span class="line">print(rules)</span><br></pre></td></tr></table></figure><p><br>结果：<br></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&#123;<span class="number">1</span>: &#123;(<span class="string">'啤酒'</span>,): <span class="number">3</span>, (<span class="string">'尿布'</span>,): <span class="number">5</span>, (<span class="string">'牛奶'</span>,): <span class="number">4</span>, (<span class="string">'面包'</span>,): <span class="number">4</span>&#125;, <span class="number">2</span>: &#123;(<span class="string">'啤酒'</span>, <span class="string">'尿布'</span>): <span class="number">3</span>, (<span class="string">'尿布'</span>, <span class="string">'牛奶'</span>): <span class="number">4</span>, (<span class="string">'尿布'</span>, <span class="string">'面包'</span>): <span class="number">4</span>, (<span class="string">'牛奶'</span>, <span class="string">'面包'</span>): <span class="number">3</span>&#125;, <span class="number">3</span>: &#123;(<span class="string">'尿布'</span>, <span class="string">'牛奶'</span>, <span class="string">'面包'</span>): <span class="number">3</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line">[&#123;啤酒&#125; -&gt; &#123;尿布&#125;, &#123;牛奶&#125; -&gt; &#123;尿布&#125;, &#123;面包&#125; -&gt; &#123;尿布&#125;, &#123;牛奶, 面包&#125; -&gt; &#123;尿布&#125;]</span><br></pre></td></tr></table></figure><p><br>你能从代码中看出来，data 是个 List 数组类型，其中每个值都可以是一个集合。实际上你也可以把 data 数组中的每个值设置为 List 数组类型，比如：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">data = [[<span class="string">'牛奶'</span>,<span class="string">'面包'</span>,<span class="string">'尿布'</span>],</span><br><span class="line">           [<span class="string">'可乐'</span>,<span class="string">'面包'</span>, <span class="string">'尿布'</span>, <span class="string">'啤酒'</span>],</span><br><span class="line">           [<span class="string">'牛奶'</span>,<span class="string">'尿布'</span>, <span class="string">'啤酒'</span>, <span class="string">'鸡蛋'</span>],</span><br><span class="line">           [<span class="string">'面包'</span>, <span class="string">'牛奶'</span>, <span class="string">'尿布'</span>, <span class="string">'啤酒'</span>],</span><br><span class="line">           [<span class="string">'面包'</span>, <span class="string">'牛奶'</span>, <span class="string">'尿布'</span>, <span class="string">'可乐'</span>]]</span><br></pre></td></tr></table></figure><p><br>两者的运行结果是一样的，efficient-apriori 工具包把每一条数据集里的项式都放到了一个集合中进行运算，并没有考虑它们之间的先后顺序。<strong>因为实际情况下，同一个购物篮中的物品也不需要考虑购买的先后顺序。而其他的 Apriori 算法可能会因为考虑了先后顺序，出现计算频繁项集结果不对的情况。所以这里采用的是 efficient-apriori 这个工具包。</strong><br>**<br><a name="ajpzD"></a></p><h3 id="挖掘-导演是如何选择演员"><a href="#挖掘-导演是如何选择演员" class="headerlink" title="挖掘-导演是如何选择演员"></a>挖掘-导演是如何选择演员</h3><p><br>在实际工作中，数据集是需要自己来准备的，比如今天我们要挖掘导演是如何选择演员的数据情况，但是并没有公开的数据集可以直接使用。因此我们需要使用之前讲到的 Python 爬虫进行数据采集。不同导演选择演员的规则是不同的，因此我们需要先指定导演。数据源我们选用豆瓣电影。先来梳理下采集的工作流程。首先我们先在<a href="https://movie.douban.com搜索框中输入导演姓名，比如“宁浩”。" target="_blank" rel="external nofollow noopener noreferrer">https://movie.douban.com搜索框中输入导演姓名，比如“宁浩”。</a><br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585838710307-db035b28-c32f-4010-bf42-fb3d28c527dc.png#align=left&display=inline&height=1150&name=image.png&originHeight=1150&originWidth=1728&size=524786&status=done&style=none&width=1728" alt="image.png"><br><br><br>页面会呈现出来导演之前的所有电影，然后对页面进行观察，你能观察到以下几个现象：</p><ol><li>页面默认是 15 条数据反馈，第一页会返回 16 条。因为第一条数据实际上这个导演的概览，你可以理解为是一条广告的插入，下面才是真正的返回结果。</li><li>每条数据的最后一行是电影的演出人员的信息，第一个人员是导演，其余为演员姓名。姓名之间用“/”分割。有了这些观察之后，我们就可以编写抓取程序了。</li></ol><p><br>在代码讲解中你能看出这两点观察的作用。抓取程序的目的是为了生成宁浩导演（你也可以抓取其他导演）的数据集，结果会保存在 csv 文件中。完整的抓取代码如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 下载某个导演的电影数据集</span></span><br><span class="line"><span class="keyword">from</span> efficient_apriori <span class="keyword">import</span> apriori</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">driver = webdriver.Chrome()</span><br><span class="line"><span class="comment"># 设置想要下载的导演 数据集</span></span><br><span class="line">director = <span class="string">u'宁浩'</span></span><br><span class="line"><span class="comment"># 写CSV文件</span></span><br><span class="line">file_name = <span class="string">'./'</span> + director + <span class="string">'.csv'</span></span><br><span class="line">base_url = <span class="string">'https://movie.douban.com/subject_search?search_text='</span>+director+<span class="string">'&amp;cat=1002&amp;start='</span></span><br><span class="line">out = open(file_name,<span class="string">'w'</span>, newline=<span class="string">''</span>, encoding=<span class="string">'utf-8-sig'</span>)</span><br><span class="line">csv_write = csv.writer(out, dialect=<span class="string">'excel'</span>)</span><br><span class="line">flags=[]</span><br><span class="line"><span class="comment"># 下载指定页面的数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(request_url)</span>:</span></span><br><span class="line">  driver.get(request_url)</span><br><span class="line">  time.sleep(<span class="number">1</span>)</span><br><span class="line">  html = driver.find_element_by_xpath(<span class="string">"//*"</span>).get_attribute(<span class="string">"outerHTML"</span>)</span><br><span class="line">  html = etree.HTML(html)</span><br><span class="line">  <span class="comment"># 设置电影名称，导演演员 的XPATH</span></span><br><span class="line">  movie_lists = html.xpath(<span class="string">"/html/body/div[@id='wrapper']/div[@id='root']/div[1]//div[@class='item-root']/div[@class='detail']/div[@class='title']/a[@class='title-text']"</span>)</span><br><span class="line">  name_lists = html.xpath(<span class="string">"/html/body/div[@id='wrapper']/div[@id='root']/div[1]//div[@class='item-root']/div[@class='detail']/div[@class='meta abstract_2']"</span>)</span><br><span class="line">  <span class="comment"># 获取返回的数据个数</span></span><br><span class="line">  num = len(movie_lists)</span><br><span class="line">  <span class="keyword">if</span> num &gt; <span class="number">15</span>: <span class="comment">#第一页会有16条数据</span></span><br><span class="line">    <span class="comment"># 默认第一个不是，所以需要去掉</span></span><br><span class="line">    movie_lists = movie_lists[<span class="number">1</span>:]</span><br><span class="line">    name_lists = name_lists[<span class="number">1</span>:]</span><br><span class="line">  <span class="keyword">for</span> (movie, name_list) <span class="keyword">in</span> zip(movie_lists, name_lists):</span><br><span class="line">    <span class="comment"># 会存在数据为空的情况</span></span><br><span class="line">    <span class="keyword">if</span> name_list.text <span class="keyword">is</span> <span class="literal">None</span>: </span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    <span class="comment"># 显示下演员名称</span></span><br><span class="line">    print(name_list.text)</span><br><span class="line">    names = name_list.text.split(<span class="string">'/'</span>)</span><br><span class="line">    <span class="comment"># 判断导演是否为指定的director</span></span><br><span class="line">    <span class="keyword">if</span> names[<span class="number">0</span>].strip() == director <span class="keyword">and</span> movie.text <span class="keyword">not</span> <span class="keyword">in</span> flags:</span><br><span class="line">      <span class="comment"># 将第一个字段设置为电影名称</span></span><br><span class="line">      names[<span class="number">0</span>] = movie.text</span><br><span class="line">      flags.append(movie.text)</span><br><span class="line">      csv_write.writerow(names)</span><br><span class="line">  print(<span class="string">'OK'</span>) <span class="comment"># 代表这页数据下载成功</span></span><br><span class="line">  print(num)</span><br><span class="line">  <span class="keyword">if</span> num &gt;= <span class="number">14</span>: <span class="comment">#有可能一页会有14个电影</span></span><br><span class="line">    <span class="comment"># 继续下一页</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 没有下一页</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始的ID为0，每页增加15</span></span><br><span class="line">start = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> start&lt;<span class="number">10000</span>: <span class="comment">#最多抽取1万部电影</span></span><br><span class="line">  request_url = base_url + str(start)</span><br><span class="line">  <span class="comment"># 下载数据，并返回是否有下一页</span></span><br><span class="line">  flag = download(request_url)</span><br><span class="line">  <span class="keyword">if</span> flag:</span><br><span class="line">    start = start + <span class="number">15</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">out.close()</span><br><span class="line">print(<span class="string">'finished'</span>)</span><br></pre></td></tr></table></figure><p><br>爬取的代码在这里就不赘述了，其中有一点就是这里用到了selenium模拟打开窗口爬取。<br><br><br>下面是爬取下来的数据：<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585838880690-4b759b67-2067-43c2-ae2c-a56d868a5553.png#align=left&display=inline&height=411&name=image.png&originHeight=411&originWidth=1729&size=161621&status=done&style=none&width=1729" alt="image.png"><br><br><br>我们用获取到的少量宁浩数据，来做一次关联规则分析：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> efficient_apriori <span class="keyword">import</span> apriori</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">director = <span class="string">u'宁浩'</span></span><br><span class="line">file_name = <span class="string">'./'</span>+director+<span class="string">'.csv'</span></span><br><span class="line">lists = csv.reader(open(file_name, <span class="string">'r'</span>, encoding=<span class="string">'utf-8-sig'</span>))</span><br><span class="line"><span class="comment"># 数据加载</span></span><br><span class="line">data = []</span><br><span class="line"><span class="keyword">for</span> names <span class="keyword">in</span> lists:</span><br><span class="line">     name_new = []</span><br><span class="line">     <span class="keyword">for</span> name <span class="keyword">in</span> names:</span><br><span class="line">           <span class="comment"># 去掉演员数据中的空格</span></span><br><span class="line">           name_new.append(name.strip())</span><br><span class="line">     data.append(name_new[<span class="number">1</span>:])</span><br><span class="line"><span class="comment"># 挖掘频繁项集和关联规则</span></span><br><span class="line">itemsets, rules = apriori(data, min_support=<span class="number">0.5</span>,  min_confidence=<span class="number">1</span>)</span><br><span class="line">print(itemsets)</span><br><span class="line">print(rules)</span><br></pre></td></tr></table></figure><p><br>代码中使用的 apriori 方法和开头中用 Apriori 获取购物篮规律的方法类似，比如代码中都设定了最小支持度和最小置信系数，这样我们可以找到支持度大于 50%，置信系数为 1 的频繁项集和关联规则。这是最后的运行结果：<br></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="number">1</span>: &#123;(<span class="string">'徐峥'</span>,): <span class="number">5</span>, (<span class="string">'黄渤'</span>,): <span class="number">6</span>&#125;, <span class="number">2</span>: &#123;(<span class="string">'徐峥'</span>, <span class="string">'黄渤'</span>): <span class="number">5</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line">[&#123;徐峥&#125; -&gt; &#123;黄渤&#125;]</span><br></pre></td></tr></table></figure><p><br>你能看出来，宁浩导演喜欢用徐峥和黄渤，并且有徐峥的情况下，一般都会用黄渤。你也可以用上面的代码来挖掘下其他导演选择演员的规律。<br></p><p><a name="TXA7M"></a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><br><strong>Apriori 算法的核心就是理解频繁项集和关联规则</strong>。<br><br><br>在算法运算的过程中，还要重点掌握对支持度、置信度和提升度的理解。<br><br><br>在工具使用上，你可以使用 efficient-apriori 这个工具包，它会把每一条数据中的项（item）放到一个集合（篮子）里来处理，不考虑项（item）之间的先后顺序。<br><br><br>在实际运用中你还需要灵活处理，比如导演如何选择演员这个案例，虽然工具的使用会很方便，但重要的还是数据挖掘前的准备过程，也就是获取某个导演的电影数据集。<br><br><br><img src="https://cdn.nlark.com/yuque/0/2020/png/1072113/1585839157353-5f4a763c-6e42-4c05-a9ec-50d9cabb3684.png#align=left&display=inline&height=509&name=282c25e8651b3e0b675be7267d13629d.png&originHeight=509&originWidth=1727&size=206986&status=done&style=none&width=1727" alt="282c25e8651b3e0b675be7267d13629d.png"><br><br><br></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Wed Apr 29 2020 20:09:40 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;昨天讲解了关联规则挖掘的原理。关联规则挖掘在生活中有很多使用场景，不仅是商品的捆绑销售，甚至在挑选演员决策上，你也能通过关联规则挖掘看出来某个导
      
    
    </summary>
    
    
      <category term="机器学习" scheme="cpeixin.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Apriori" scheme="cpeixin.cn/tags/Apriori/"/>
    
  </entry>
  
</feed>
